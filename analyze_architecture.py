#!/usr/bin/env python3
"""
é¡¹ç›®æ¶æ„åˆ†æå·¥å…·
æå–æ‰€æœ‰ API ç«¯ç‚¹ã€å‡½æ•°å®šä¹‰ã€å‚æ•°å’Œè°ƒç”¨å…³ç³»
ç”Ÿæˆå¯è§†åŒ–æ¶æ„å›¾
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Any, Set
from collections import defaultdict

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent
BACKEND_ROOT = PROJECT_ROOT / 'backend_python'
FRONTEND_ROOT = PROJECT_ROOT

# å­˜å‚¨ç»“æ„
api_endpoints = []
function_definitions = []
class_definitions = []
import_relationships = defaultdict(set)
call_relationships = defaultdict(set)
data_models = []

def extract_api_endpoints_from_views(file_path: Path) -> List[Dict]:
    """ä» views.py æå– API ç«¯ç‚¹"""
    endpoints = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åŒ¹é… Flask è·¯ç”±è£…é¥°å™¨
        pattern = r'@\w+\.route\([\'"]([^\'"]+)[\'"].*?methods=\[([^\]]+)\]'
        matches = re.findall(pattern, content, re.DOTALL)
        
        for route, methods in matches:
            methods_list = [m.strip().strip("'\"") for m in methods.split(',')]
            endpoints.append({
                'path': route,
                'methods': methods_list,
                'file': str(file_path.relative_to(PROJECT_ROOT))
            })
        
        # åŒ¹é… blueprint è·¯ç”±
        pattern2 = r'@\w+_bp\.route\([\'"]([^\'"]+)[\'"]'
        matches2 = re.findall(pattern2, content)
        
        for route in matches2:
            if not any(ep['path'] == route for ep in endpoints):
                endpoints.append({
                    'path': route,
                    'methods': ['GET', 'POST'],
                    'file': str(file_path.relative_to(PROJECT_ROOT))
                })
    except Exception as e:
        print(f"Error extracting endpoints from {file_path}: {e}")
    
    return endpoints

def extract_function_definitions(file_path: Path) -> List[Dict]:
    """æå–å‡½æ•°å®šä¹‰å’Œå‚æ•°"""
    functions = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åŒ¹é… Python å‡½æ•°å®šä¹‰
        pattern = r'def\s+(\w+)\s*\(([^)]*)\)\s*(?:->\s*([^\n:]+))?:'
        matches = re.finditer(pattern, content)
        
        for match in matches:
            func_name = match.group(1)
            params_str = match.group(2)
            return_type = match.group(3).strip() if match.group(3) else None
            
            # è§£æå‚æ•°
            params = []
            if params_str.strip():
                param_list = params_str.split(',')
                for param in param_list:
                    param = param.strip()
                    if param and param != 'self' and param != 'cls':
                        # æå–å‚æ•°åå’Œç±»å‹
                        if ':' in param:
                            param_name, param_type = param.split(':', 1)
                            params.append({
                                'name': param_name.strip(),
                                'type': param_type.strip().split('=')[0].strip()
                            })
                        else:
                            param_name = param.split('=')[0].strip()
                            if param_name:
                                params.append({
                                    'name': param_name,
                                    'type': 'Any'
                                })
            
            functions.append({
                'name': func_name,
                'params': params,
                'return_type': return_type,
                'file': str(file_path.relative_to(PROJECT_ROOT)),
                'line': content[:match.start()].count('\n') + 1
            })
    except Exception as e:
        print(f"Error extracting functions from {file_path}: {e}")
    
    return functions

def extract_class_definitions(file_path: Path) -> List[Dict]:
    """æå–ç±»å®šä¹‰"""
    classes = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åŒ¹é… Python ç±»å®šä¹‰
        pattern = r'class\s+(\w+)(?:\s*\(\s*([^\)]*)\s*\))?:'
        matches = re.finditer(pattern, content)
        
        for match in matches:
            class_name = match.group(1)
            parents = match.group(2).strip() if match.group(2) else ''
            
            classes.append({
                'name': class_name,
                'parents': [p.strip() for p in parents.split(',') if p.strip()],
                'file': str(file_path.relative_to(PROJECT_ROOT)),
                'line': content[:match.start()].count('\n') + 1
            })
    except Exception as e:
        print(f"Error extracting classes from {file_path}: {e}")
    
    return classes

def extract_import_relationships(file_path: Path) -> Dict[str, Set[str]]:
    """æå–å¯¼å…¥å…³ç³»"""
    imports = defaultdict(set)
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åŒ¹é… import è¯­å¥
        patterns = [
            r'from\s+([\w.]+)\s+import\s+(?:\(([^)]+)\)|([^\n]+))',
            r'import\s+([\w.]+)'
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, content)
            for match in matches:
                if match.group(1):
                    module = match.group(1)
                    imports[str(file_path.stem)].add(module)
    except Exception as e:
        print(f"Error extracting imports from {file_path}: {e}")
    
    return imports

def extract_data_models(file_path: Path) -> List[Dict]:
    """æå–æ•°æ®æ¨¡å‹ï¼ˆdataclass, Pydantic ç­‰ï¼‰"""
    models = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åŒ¹é… dataclass
        pattern = r'@dataclass\s+class\s+(\w+).*?:(.*?)(?=\n@|\nclass|\Z)'
        matches = re.finditer(pattern, content, re.DOTALL)
        
        for match in matches:
            model_name = match.group(1)
            fields_str = match.group(2)
            
            fields = []
            if fields_str:
                field_pattern = r'(\w+)\s*:\s*([^\n]+)'
                field_matches = re.finditer(field_pattern, fields_str)
                for field_match in field_matches:
                    fields.append({
                        'name': field_match.group(1),
                        'type': field_match.group(2).strip()
                    })
            
            models.append({
                'name': model_name,
                'type': 'dataclass',
                'fields': fields,
                'file': str(file_path.relative_to(PROJECT_ROOT))
            })
    except Exception as e:
        print(f"Error extracting models from {file_path}: {e}")
    
    return models

def scan_backend_directory():
    """æ‰«æåç«¯ç›®å½•"""
    print("ğŸ” æ‰«æåç«¯ç›®å½•...")
    
    backend_dirs = [
        BACKEND_ROOT / 'wechat_backend',
        BACKEND_ROOT / 'wechat_backend' / 'ai_adapters',
        BACKEND_ROOT / 'wechat_backend' / 'views',
        BACKEND_ROOT / 'wechat_backend' / 'database',
        BACKEND_ROOT / 'src',
        BACKEND_ROOT / 'src' / 'api',
        BACKEND_ROOT / 'src' / 'services',
        BACKEND_ROOT / 'src' / 'models',
    ]
    
    for directory in backend_dirs:
        if not directory.exists():
            continue
            
        for file_path in directory.glob('*.py'):
            if file_path.name.startswith('__'):
                continue
            
            print(f"  ğŸ“„ åˆ†æï¼š{file_path.relative_to(PROJECT_ROOT)}")
            
            # æå– API ç«¯ç‚¹
            if 'views' in str(file_path) or file_path.name == 'views.py':
                api_endpoints.extend(extract_api_endpoints_from_views(file_path))
            
            # æå–å‡½æ•°å®šä¹‰
            function_definitions.extend(extract_function_definitions(file_path))
            
            # æå–ç±»å®šä¹‰
            class_definitions.extend(extract_class_definitions(file_path))
            
            # æå–å¯¼å…¥å…³ç³»
            imports = extract_import_relationships(file_path)
            for module, imported in imports.items():
                import_relationships[module].update(imported)
            
            # æå–æ•°æ®æ¨¡å‹
            data_models.extend(extract_data_models(file_path))

def scan_frontend_directory():
    """æ‰«æå‰ç«¯ç›®å½•"""
    print("ğŸ” æ‰«æå‰ç«¯ç›®å½•...")
    
    frontend_dirs = [
        FRONTEND_ROOT / 'services',
        FRONTEND_ROOT / 'pages' / 'index',
        FRONTEND_ROOT / 'api',
        FRONTEND_ROOT / 'utils',
    ]
    
    for directory in frontend_dirs:
        if not directory.exists():
            continue
            
        for file_path in directory.glob('*.js'):
            print(f"  ğŸ“„ åˆ†æï¼š{file_path.relative_to(PROJECT_ROOT)}")
            
            # æå–å‡½æ•°å®šä¹‰
            function_definitions.extend(extract_function_definitions(file_path))

def generate_architecture_report():
    """ç”Ÿæˆæ¶æ„æŠ¥å‘Š"""
    print("\nğŸ“Š ç”Ÿæˆæ¶æ„æŠ¥å‘Š...")
    
    report = {
        'summary': {
            'total_api_endpoints': len(api_endpoints),
            'total_functions': len(function_definitions),
            'total_classes': len(class_definitions),
            'total_data_models': len(data_models),
            'total_import_relationships': len(import_relationships)
        },
        'api_endpoints': api_endpoints[:50],  # é™åˆ¶æ•°é‡
        'core_functions': [f for f in function_definitions if not f['name'].startswith('_')][:100],
        'core_classes': class_definitions[:50],
        'data_models': data_models[:50],
        'import_graph': {k: list(v)[:10] for k, v in list(import_relationships.items())[:30]}
    }
    
    return report

def generate_mermaid_diagram(report: Dict) -> str:
    """ç”Ÿæˆ Mermaid æ¶æ„å›¾"""
    mermaid = ["# é¡¹ç›®æ¶æ„æ€»è§ˆ\n\n```mermaid", "graph TB"]
    
    # æ·»åŠ æ ·å¼å®šä¹‰
    mermaid.append("    classDef api fill:#e1f5ff,stroke:#0066cc")
    mermaid.append("    classDef service fill:#fff4e1,stroke:#ff9900")
    mermaid.append("    classDef model fill:#f0e1ff,stroke:#9900cc")
    mermaid.append("    classDef frontend fill:#e1ffe1,stroke:#00cc00")
    mermaid.append("    classDef backend fill:#ffe1e1,stroke:#cc0000")
    
    # å‰ç«¯æ¨¡å—
    mermaid.append("\n    subgraph Frontend[å‰ç«¯ - å¾®ä¿¡å°ç¨‹åº]")
    mermaid.append("        Pages[pages/ - é¡µé¢å±‚]")
    mermaid.append("        Services[services/ - æœåŠ¡å±‚]")
    mermaid.append("        API[api/ - API è°ƒç”¨]")
    mermaid.append("        Utils[utils/ - å·¥å…·å‡½æ•°]")
    mermaid.append("    end")
    
    # åç«¯æ¨¡å—
    mermaid.append("\n    subgraph Backend[åç«¯ - Flask API]")
    mermaid.append("        Views[views.py - API è·¯ç”±å±‚]")
    mermaid.append("        Adapters[ai_adapters/ - AI é€‚é…å™¨]")
    mermaid.append("        Services[services/ - ä¸šåŠ¡æœåŠ¡]")
    mermaid.append("        Models[models/ - æ•°æ®æ¨¡å‹]")
    mermaid.append("        Database[database/ - æ•°æ®åº“]")
    mermaid.append("    end")
    
    # å¤–éƒ¨æœåŠ¡
    mermaid.append("\n    subgraph External[å¤–éƒ¨æœåŠ¡]")
    mermaid.append("        Doubao[è±†åŒ… AI API]")
    mermaid.append("        DeepSeek[DeepSeek API]")
    mermaid.append("        Qwen[é€šä¹‰åƒé—® API]")
    mermaid.append("        WeChat[å¾®ä¿¡å°ç¨‹åº API]")
    mermaid.append("    end")
    
    # è¿æ¥å…³ç³»
    mermaid.append("\n    %% å‰ç«¯è°ƒç”¨å…³ç³»")
    mermaid.append("    Pages --> Services")
    mermaid.append("    Services --> API")
    mermaid.append("    API -->|HTTP/HTTPS| Views")
    
    mermaid.append("\n    %% åç«¯å†…éƒ¨è°ƒç”¨")
    mermaid.append("    Views --> Adapters")
    mermaid.append("    Views --> Services")
    mermaid.append("    Services --> Models")
    mermaid.append("    Models --> Database")
    
    mermaid.append("\n    %% åç«¯è°ƒç”¨å¤–éƒ¨æœåŠ¡")
    mermaid.append("    Adapters --> Doubao")
    mermaid.append("    Adapters --> DeepSeek")
    mermaid.append("    Adapters --> Qwen")
    
    mermaid.append("\n    %% æ ·å¼åº”ç”¨")
    mermaid.append("    class Pages,Services,API,Utils frontend")
    mermaid.append("    class Views,Adapters,Services,Models,Database backend")
    mermaid.append("    class Doubao,DeepSeek,Qwen,WeChat service")
    
    mermaid.append("```")
    
    return "\n".join(mermaid)

def generate_data_flow_diagram() -> str:
    """ç”Ÿæˆæ•°æ®æµå›¾"""
    mermaid = ["\n## è¯Šæ–­åŠŸèƒ½æ•°æ®æµ\n\n```mermaid", "sequenceDiagram"]
    
    mermaid.append("    participant User as ç”¨æˆ·")
    mermaid.append("    participant Frontend as å‰ç«¯å°ç¨‹åº")
    mermaid.append("    participant API as åç«¯ API")
    mermaid.append("    participant NxM as NxM å¼•æ“")
    mermaid.append("    participant Adapter as AI é€‚é…å™¨")
    mermaid.append("    participant AI as AI å¹³å°")
    mermaid.append("    participant DB as æ•°æ®åº“")
    
    mermaid.append("\n    User->>Frontend: è¾“å…¥å“ç‰Œåç§°")
    mermaid.append("    Frontend->>Frontend: é€‰æ‹© AI æ¨¡å‹")
    mermaid.append("    Frontend->>API: POST /api/perform-brand-test")
    mermaid.append("    API->>API: éªŒè¯è¾“å…¥å‚æ•°")
    mermaid.append("    API->>API: ç”Ÿæˆ execution_id")
    mermaid.append("    API->>NxM: å¯åŠ¨å¼‚æ­¥ä»»åŠ¡")
    mermaid.append("    API-->>Frontend: è¿”å› execution_id")
    
    mermaid.append("\n    loop è½®è¯¢çŠ¶æ€ (800ms)")
    mermaid.append("        Frontend->>API: GET /test/status/{execution_id}")
    mermaid.append("        API-->>Frontend: è¿”å›è¿›åº¦çŠ¶æ€")
    mermaid.append("    end")
    
    mermaid.append("\n    NxM->>NxM: è§£æé—®é¢˜æ¨¡æ¿")
    mermaid.append("    NxM->>Adapter: åˆ›å»º AI å®¢æˆ·ç«¯")
    mermaid.append("    Adapter->>Adapter: æ„å»º Prompt")
    mermaid.append("    Note over Adapter: brand_name, competitors, question")
    mermaid.append("    Adapter->>AI: å‘é€ API è¯·æ±‚")
    mermaid.append("    AI-->>Adapter: è¿”å› AI å“åº”")
    mermaid.append("    Adapter->>Adapter: è§£æ GEO JSON")
    mermaid.append("    Adapter->>NxM: è¿”å›ç»“æœ")
    
    mermaid.append("\n    NxM->>DB: ä¿å­˜æµ‹è¯•ç»“æœ")
    mermaid.append("    NxM->>API: æ›´æ–° execution_store")
    mermaid.append("    API-->>Frontend: è¿”å›å®ŒæˆçŠ¶æ€")
    mermaid.append("    Frontend->>Frontend: è·³è½¬ç»“æœé¡µ")
    
    mermaid.append("```")
    
    return "\n".join(mermaid)

def generate_parameter_flow_diagram() -> str:
    """ç”Ÿæˆå‚æ•°ä¼ é€’æµç¨‹å›¾"""
    mermaid = ["\n## æ ¸å¿ƒå‚æ•°ä¼ é€’æµç¨‹\n\n```mermaid", "graph LR"]
    
    mermaid.append("    subgraph FrontendParams[å‰ç«¯å‚æ•°]")
    mermaid.append("        FP1[brandName: å“ç‰Œåç§°]")
    mermaid.append("        FP2[competitorBrands: ç«å“åˆ—è¡¨]")
    mermaid.append("        FP3[selectedModels: AI æ¨¡å‹]")
    mermaid.append("        FP4[customQuestions: è‡ªå®šä¹‰é—®é¢˜]")
    mermaid.append("    end")
    
    mermaid.append("\n    subgraph APIParams[API å‚æ•°]")
    mermaid.append("        AP1[brand_list: Array]")
    mermaid.append("        AP2[selectedModels: Array]")
    mermaid.append("        AP3[custom_question: String]")
    mermaid.append("    end")
    
    mermaid.append("\n    subgraph NxMParams[NxM å¼•æ“å‚æ•°]")
    mermaid.append("        NP1[main_brand: String]")
    mermaid.append("        NP2[competitor_brands: Array]")
    mermaid.append("        NP3[selected_models: Array]")
    mermaid.append("        NP4[raw_questions: Array]")
    mermaid.append("    end")
    
    mermaid.append("\n    subgraph TemplateParams[æ¨¡æ¿å‚æ•°]")
    mermaid.append("        TP1[brand_name: String âœ…]")
    mermaid.append("        TP2[competitors: String âœ…]")
    mermaid.append("        TP3[question: String âœ…]")
    mermaid.append("    end")
    
    mermaid.append("\n    FP1 --> AP1")
    mermaid.append("    FP2 --> AP1")
    mermaid.append("    FP3 --> AP2")
    mermaid.append("    FP4 --> AP3")
    
    mermaid.append("    AP1 --> NP1")
    mermaid.append("    AP1 --> NP2")
    mermaid.append("    AP2 --> NP3")
    mermaid.append("    AP3 --> NP4")
    
    mermaid.append("    NP1 --> TP1")
    mermaid.append("    NP2 --> TP2")
    mermaid.append("    NP4 --> TP3")
    
    mermaid.append("\n    classDef frontend fill:#e1ffe1,stroke:#00cc00")
    mermaid.append("    classDef api fill:#e1f5ff,stroke:#0066cc")
    mermaid.append("    classDef nxm fill:#fff4e1,stroke:#ff9900")
    mermaid.append("    classDef template fill:#f0e1ff,stroke:#9900cc")
    
    mermaid.append("    class FP1,FP2,FP3,FP4 frontend")
    mermaid.append("    class AP1,AP2,AP3 api")
    mermaid.append("    class NP1,NP2,NP3,NP4 nxm")
    mermaid.append("    class TP1,TP2,TP3 template")
    
    mermaid.append("```")
    
    return "\n".join(mermaid)

def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("é¡¹ç›®æ¶æ„åˆ†æå·¥å…·")
    print("="*70)
    print()
    
    # æ‰«æåç«¯
    scan_backend_directory()
    
    # æ‰«æå‰ç«¯
    scan_frontend_directory()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = generate_architecture_report()
    
    # ä¿å­˜ JSON æŠ¥å‘Š
    report_file = PROJECT_ROOT / 'docs' / 'architecture_analysis.json'
    report_file.parent.mkdir(parents=True, exist_ok=True)
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    print(f"âœ… JSON æŠ¥å‘Šå·²ä¿å­˜ï¼š{report_file}")
    
    # ç”Ÿæˆ Mermaid å›¾è¡¨
    mermaid_content = []
    mermaid_content.append("# é¡¹ç›®æ¶æ„å¯è§†åŒ–æ€»è§ˆ\n")
    mermaid_content.append(f"**ç”Ÿæˆæ—¶é—´**: {__import__('datetime').datetime.now().isoformat()}\n")
    mermaid_content.append(f"**æ–‡ä»¶ç»Ÿè®¡**: {report['summary']}\n")
    mermaid_content.append(generate_mermaid_diagram(report))
    mermaid_content.append(generate_data_flow_diagram())
    mermaid_content.append(generate_parameter_flow_diagram())
    
    # ä¿å­˜ Markdown æŠ¥å‘Š
    md_file = PROJECT_ROOT / 'docs' / '2026-02-23_é¡¹ç›®æ¶æ„å¯è§†åŒ–æ€»è§ˆ.md'
    with open(md_file, 'w', encoding='utf-8') as f:
        f.write("\n".join(mermaid_content))
    print(f"âœ… Markdown æŠ¥å‘Šå·²ä¿å­˜ï¼š{md_file}")
    
    # æ‰“å°æ‘˜è¦
    print("\n" + "="*70)
    print("æ¶æ„åˆ†ææ‘˜è¦")
    print("="*70)
    print(f"API ç«¯ç‚¹æ•°é‡ï¼š{report['summary']['total_api_endpoints']}")
    print(f"å‡½æ•°å®šä¹‰æ•°é‡ï¼š{report['summary']['total_functions']}")
    print(f"ç±»å®šä¹‰æ•°é‡ï¼š{report['summary']['total_classes']}")
    print(f"æ•°æ®æ¨¡å‹æ•°é‡ï¼š{report['summary']['total_data_models']}")
    print(f"å¯¼å…¥å…³ç³»æ•°é‡ï¼š{report['summary']['total_import_relationships']}")
    print()

if __name__ == '__main__':
    main()
