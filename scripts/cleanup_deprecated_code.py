#!/usr/bin/env python3
"""
P2-3 æ— ç”¨ä»£ç æ¸…ç†è„šæœ¬

ç”¨é€”:
1. æ¸…ç†åºŸå¼ƒçš„æ•°æ®åº“è¡¨ (test_records, old_brand_results ç­‰)
2. æ¸…ç†æ— ç”¨çš„è°ƒè¯•æ–‡ä»¶
3. æ¸…ç†æ³¨é‡Šæ‰çš„ä»£ç å—
4. ç”Ÿæˆæ¸…ç†æŠ¥å‘Š

æ‰§è¡Œæ–¹å¼:
    python scripts/cleanup_deprecated_code.py

@author: ç³»ç»Ÿæ¶æ„ç»„
@date: 2026-02-28
@version: 2.0.0
"""

import sqlite3
import os
import sys
import json
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
backend_path = os.path.join(
    os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
    'backend_python'
)
if backend_path not in sys.path:
    sys.path.insert(0, backend_path)

from wechat_backend.logging_config import api_logger

# æ•°æ®åº“è·¯å¾„
DATABASE_PATH = os.path.join(
    os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
    'backend_python',
    'database.db'
)

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent


class DeprecatedCodeCleaner:
    """æ— ç”¨ä»£ç æ¸…ç†å™¨"""

    def __init__(self, db_path: str = DATABASE_PATH):
        """
        åˆå§‹åŒ–æ¸…ç†å™¨

        å‚æ•°:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        self.db_path = db_path
        self.stats = {
            'deprecated_tables_dropped': 0,
            'debug_files_removed': 0,
            'commented_code_files_cleaned': 0,
            'total_freed_bytes': 0,
            'errors': 0
        }
        self.report = {
            'deprecated_tables': [],
            'debug_files': [],
            'commented_code_files': [],
            'actions_taken': []
        }

    def get_connection(self) -> sqlite3.Connection:
        """è·å–æ•°æ®åº“è¿æ¥"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        return conn

    def find_deprecated_tables(self) -> List[str]:
        """
        æŸ¥æ‰¾åºŸå¼ƒçš„æ•°æ®åº“è¡¨

        è¿”å›:
            åºŸå¼ƒè¡¨åç§°åˆ—è¡¨
        """
        api_logger.info("[P2-3] å¼€å§‹æŸ¥æ‰¾åºŸå¼ƒçš„æ•°æ®åº“è¡¨...")

        conn = self.get_connection()
        cursor = conn.cursor()

        try:
            # è·å–æ‰€æœ‰è¡¨å
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            all_tables = [row[0] for row in cursor.fetchall()]

            # å®šä¹‰åºŸå¼ƒè¡¨æ¨¡å¼
            deprecated_patterns = [
                r'^test_records$',           # æ—§çš„å“ç‰Œæµ‹è¯•è®°å½•è¡¨
                r'^old_brand_results$',      # æ—§çš„å“ç‰Œç»“æœè¡¨
                r'^test_record$',            # å•æ•°å½¢å¼
                r'^brand_result$',           # æ—§çš„å“ç‰Œç»“æœè¡¨
                r'^temp_.*$',                # ä¸´æ—¶è¡¨
                r'^bak_.*$',                 # å¤‡ä»½è¡¨
                r'^.*_backup$',              # å¤‡ä»½è¡¨
                r'^.*_old$',                 # æ—§è¡¨
                r'^.*_v1$',                  # ç‰ˆæœ¬ 1 è¡¨
                r'^.*_v2$',                  # ç‰ˆæœ¬ 2 è¡¨
            ]

            deprecated_tables = []
            for table in all_tables:
                # è·³è¿‡æ­£å¼çš„è¡¨
                if table in [
                    'diagnosis_reports',
                    'diagnosis_results',
                    'diagnosis_analysis',
                    'task_statuses',
                    'deep_intelligence_results',
                    'brand_test_results',
                    'users',
                    'ai_call_logs',
                    'circuit_breaker_states',
                    'audit_logs',
                    'sqlite_sequence',
                    'cache_entries',
                    'dead_letter_queue'
                ]:
                    continue

                # æ£€æŸ¥æ˜¯å¦åŒ¹é…åºŸå¼ƒæ¨¡å¼
                for pattern in deprecated_patterns:
                    if re.match(pattern, table, re.IGNORECASE):
                        deprecated_tables.append(table)
                        api_logger.info(f"[P2-3] å‘ç°åºŸå¼ƒè¡¨ï¼š{table}")
                        break

            self.report['deprecated_tables'] = deprecated_tables
            api_logger.info(f"[P2-3] å…±å‘ç° {len(deprecated_tables)} ä¸ªåºŸå¼ƒè¡¨")

            return deprecated_tables

        except Exception as e:
            api_logger.error(f"[P2-3] æŸ¥æ‰¾åºŸå¼ƒè¡¨å¤±è´¥ï¼š{e}")
            self.stats['errors'] += 1
            return []
        finally:
            conn.close()

    def drop_deprecated_tables(self, tables: List[str] = None, dry_run: bool = True) -> int:
        """
        åˆ é™¤åºŸå¼ƒçš„æ•°æ®åº“è¡¨

        å‚æ•°:
            tables: è¡¨ååˆ—è¡¨ï¼ˆå¯é€‰ï¼Œä¸ä¼ åˆ™ä½¿ç”¨ find_deprecated_tables çš„ç»“æœï¼‰
            dry_run: æ˜¯å¦ä»…æ¨¡æ‹Ÿæ‰§è¡Œï¼ˆä¸å®é™…åˆ é™¤ï¼‰

        è¿”å›:
            åˆ é™¤çš„è¡¨æ•°
        """
        api_logger.info(f"[P2-3] å¼€å§‹åˆ é™¤åºŸå¼ƒçš„æ•°æ®åº“è¡¨{'(æ¨¡æ‹Ÿ)' if dry_run else '...'}")

        if tables is None:
            tables = self.find_deprecated_tables()

        if not tables:
            api_logger.info("[P2-3] æ²¡æœ‰åºŸå¼ƒè¡¨éœ€è¦åˆ é™¤")
            return 0

        conn = self.get_connection()
        cursor = conn.cursor()

        dropped_count = 0

        try:
            for table in tables:
                try:
                    if dry_run:
                        api_logger.info(f"[P2-3] [DRY RUN] å°†åˆ é™¤åºŸå¼ƒè¡¨ï¼š{table}")
                        dropped_count += 1
                    else:
                        # å…ˆåˆ é™¤ç›¸å…³ç´¢å¼•
                        cursor.execute(
                            "SELECT name FROM sqlite_master WHERE type='index' AND tbl_name=?",
                            (table,)
                        )
                        indexes = [row[0] for row in cursor.fetchall()]
                        for index in indexes:
                            cursor.execute(f"DROP INDEX IF EXISTS {index}")

                        # åˆ é™¤è¡¨
                        cursor.execute(f"DROP TABLE IF EXISTS {table}")
                        dropped_count += 1
                        api_logger.info(f"[P2-3] âœ… åˆ é™¤åºŸå¼ƒè¡¨ï¼š{table}")

                        self.report['actions_taken'].append(f"Deleted table: {table}")

                except Exception as e:
                    api_logger.error(f"[P2-3] åˆ é™¤è¡¨ {table} å¤±è´¥ï¼š{e}")
                    self.stats['errors'] += 1

            if not dry_run:
                conn.commit()
                self.stats['deprecated_tables_dropped'] = dropped_count

            api_logger.info(f"[P2-3] {'âœ… æ¨¡æ‹Ÿ' if dry_run else 'å®Œæˆ'}åˆ é™¤åºŸå¼ƒè¡¨ï¼š{dropped_count} ä¸ª")
            return dropped_count

        except Exception as e:
            conn.rollback()
            api_logger.error(f"[P2-3] åˆ é™¤åºŸå¼ƒè¡¨å¤±è´¥ï¼š{e}")
            self.stats['errors'] += 1
            return 0
        finally:
            conn.close()

    def find_debug_files(self) -> List[Path]:
        """
        æŸ¥æ‰¾è°ƒè¯•æ–‡ä»¶

        è¿”å›:
            è°ƒè¯•æ–‡ä»¶åˆ—è¡¨
        """
        api_logger.info("[P2-3] å¼€å§‹æŸ¥æ‰¾è°ƒè¯•æ–‡ä»¶...")

        debug_patterns = [
            '*_debug.py',
            '*_debug_*.py',
            'debug_*.py',
            '*_test_simple.py',
            '*_simple_test.py',
            '*_backup.py',
            '*_bak.py',
            '*.bak',
            '*.tmp',
        ]

        debug_files = []
        backend_dir = Path(backend_path)

        for pattern in debug_patterns:
            for file_path in backend_dir.rglob(pattern):
                # æ’é™¤ tests ç›®å½•ä¸‹çš„æµ‹è¯•æ–‡ä»¶ï¼ˆè¿™æ˜¯æ­£å¸¸çš„æµ‹è¯•ä»£ç ï¼‰
                if 'tests' in str(file_path.parts):
                    continue

                # æ’é™¤ migrations ç›®å½•
                if 'migrations' in str(file_path.parts):
                    continue

                # æ’é™¤ qwen-code ç›®å½•ï¼ˆç¬¬ä¸‰æ–¹ä»£ç ï¼‰
                if 'qwen-code' in str(file_path.parts):
                    continue

                # æ’é™¤ gco_validator ç›®å½•ï¼ˆç‹¬ç«‹æ¨¡å—ï¼‰
                if 'gco_validator' in str(file_path.parts):
                    continue

                debug_files.append(file_path)
                api_logger.debug(f"[P2-3] å‘ç°è°ƒè¯•æ–‡ä»¶ï¼š{file_path}")

        self.report['debug_files'] = [str(f) for f in debug_files]
        api_logger.info(f"[P2-3] å…±å‘ç° {len(debug_files)} ä¸ªè°ƒè¯•æ–‡ä»¶")

        return debug_files

    def find_commented_code_files(self) -> List[Tuple[Path, int]]:
        """
        æŸ¥æ‰¾åŒ…å«å¤§æ®µæ³¨é‡Šä»£ç çš„æ–‡ä»¶

        è¿”å›:
            (æ–‡ä»¶è·¯å¾„ï¼Œæ³¨é‡Šä»£ç è¡Œæ•°) åˆ—è¡¨
        """
        api_logger.info("[P2-3] å¼€å§‹æŸ¥æ‰¾åŒ…å«å¤§æ®µæ³¨é‡Šä»£ç çš„æ–‡ä»¶...")

        commented_files = []
        backend_dir = Path(backend_path)

        # åªæ‰«æ Python æ–‡ä»¶
        for file_path in backend_dir.rglob('*.py'):
            # æ’é™¤ testsã€migrationsã€qwen-codeã€gco_validator ç›®å½•
            if any(exclude in str(file_path.parts) for exclude in ['tests', 'migrations', 'qwen-code', 'gco_validator']):
                continue

            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()

                commented_code_lines = 0
                in_multiline_comment = False

                for line in lines:
                    stripped = line.strip()

                    # æ£€æŸ¥å¤šè¡Œæ³¨é‡Š
                    if stripped.startswith('"""') or stripped.startswith("'''"):
                        # å•è¡Œå¤šè¡Œæ³¨é‡Š
                        if stripped.count('"""') == 2 or stripped.count("'''") == 2:
                            continue
                        in_multiline_comment = not in_multiline_comment
                        commented_code_lines += 1
                    elif in_multiline_comment:
                        commented_code_lines += 1
                        if stripped.endswith('"""') or stripped.endswith("'''"):
                            in_multiline_comment = False
                    elif stripped.startswith('#') and len(stripped) > 1:
                        # æ£€æŸ¥æ˜¯å¦åƒä»£ç ï¼ˆåŒ…å«å…³é”®å­—ï¼‰
                        if self._looks_like_code(stripped[1:].strip()):
                            commented_code_lines += 1

                # å¦‚æœæ³¨é‡Šä»£ç è¶…è¿‡ 10 è¡Œï¼ŒæŠ¥å‘Š
                if commented_code_lines > 10:
                    commented_files.append((file_path, commented_code_lines))
                    api_logger.debug(f"[P2-3] {file_path}: {commented_code_lines} è¡Œæ³¨é‡Šä»£ç ")

            except Exception as e:
                api_logger.debug(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

        self.report['commented_code_files'] = [
            {'file': str(f), 'lines': c} for f, c in commented_files
        ]
        api_logger.info(f"[P2-3] å…±å‘ç° {len(commented_files)} ä¸ªæ–‡ä»¶åŒ…å«å¤§æ®µæ³¨é‡Šä»£ç ")

        return commented_files

    def _looks_like_code(self, line: str) -> bool:
        """
        åˆ¤æ–­è¡Œæ˜¯å¦åƒä»£ç 

        å‚æ•°:
            line: ä»£ç è¡Œ

        è¿”å›:
            æ˜¯å¦åƒä»£ç 
        """
        code_patterns = [
            r'def\s+\w+',          # Python å‡½æ•°å®šä¹‰
            r'class\s+\w+',        # ç±»å®šä¹‰
            r'async\s+def\s+\w+',  # å¼‚æ­¥å‡½æ•°å®šä¹‰
            r'if\s+.+:',           # æ¡ä»¶è¯­å¥
            r'for\s+.+:',          # å¾ªç¯
            r'while\s+.+:',        # å¾ªç¯
            r'return\s+',          # è¿”å›
            r'raise\s+',           # æŠ›å‡ºå¼‚å¸¸
            r'import\s+',          # å¯¼å…¥
            r'from\s+\w+.*import', # Python å¯¼å…¥
            r'with\s+.+:',         # ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            r'try:',               # å¼‚å¸¸å¤„ç†
            r'except',             # å¼‚å¸¸å¤„ç†
            r'@\w+',               # è£…é¥°å™¨
        ]

        for pattern in code_patterns:
            if re.search(pattern, line):
                return True

        return False

    def get_database_size(self) -> int:
        """è·å–æ•°æ®åº“æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰"""
        try:
            return os.path.getsize(self.db_path)
        except OSError:
            return 0

    def run_cleanup(self, dry_run: bool = True, remove_debug_files: bool = False) -> Dict[str, Any]:
        """
        è¿è¡Œæ¸…ç†

        å‚æ•°:
            dry_run: æ˜¯å¦ä»…æ¨¡æ‹Ÿæ‰§è¡Œ
            remove_debug_files: æ˜¯å¦åˆ é™¤è°ƒè¯•æ–‡ä»¶

        è¿”å›:
            æ¸…ç†ç»Ÿè®¡ä¿¡æ¯
        """
        api_logger.info("=" * 60)
        api_logger.info("[P2-3] å¼€å§‹æ— ç”¨ä»£ç æ¸…ç†")
        if dry_run:
            api_logger.info("[P2-3] æ¨¡å¼ï¼šæ¨¡æ‹Ÿæ‰§è¡Œ (dry-run)")
        api_logger.info("=" * 60)

        # è®°å½•æ¸…ç†å‰æ•°æ®åº“å¤§å°
        size_before = self.get_database_size()
        api_logger.info(f"[P2-3] æ¸…ç†å‰æ•°æ®åº“å¤§å°ï¼š{size_before / 1024 / 1024:.2f} MB")

        # æ­¥éª¤ 1: æŸ¥æ‰¾å¹¶åˆ é™¤åºŸå¼ƒè¡¨
        deprecated_tables = self.find_deprecated_tables()
        if deprecated_tables:
            self.drop_deprecated_tables(deprecated_tables, dry_run=dry_run)

        # æ­¥éª¤ 2: æŸ¥æ‰¾è°ƒè¯•æ–‡ä»¶
        debug_files = self.find_debug_files()

        # æ­¥éª¤ 3: æŸ¥æ‰¾æ³¨é‡Šä»£ç 
        commented_files = self.find_commented_code_files()

        # è®°å½•æ¸…ç†åæ•°æ®åº“å¤§å°
        size_after = self.get_database_size()
        freed_bytes = size_before - size_after
        self.stats['total_freed_bytes'] = freed_bytes

        # ç”Ÿæˆæ¸…ç†æŠ¥å‘Š
        report_path = PROJECT_ROOT / 'cleanup_p2_3_report.json'
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.report, f, indent=2, ensure_ascii=False)
        api_logger.info(f"[P2-3] æ¸…ç†æŠ¥å‘Šå·²ä¿å­˜è‡³ï¼š{report_path}")

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        api_logger.info("=" * 60)
        api_logger.info("[P2-3] æ¸…ç†ç»Ÿè®¡")
        api_logger.info("=" * 60)
        api_logger.info(f"åºŸå¼ƒè¡¨æ•°é‡ï¼š{len(deprecated_tables)}")
        api_logger.info(f"è°ƒè¯•æ–‡ä»¶æ•°ï¼š{len(debug_files)}")
        api_logger.info(f"åŒ…å«æ³¨é‡Šä»£ç çš„æ–‡ä»¶æ•°ï¼š{len(commented_files)}")
        if freed_bytes > 0:
            api_logger.info(f"é‡Šæ”¾ç©ºé—´ï¼š{freed_bytes / 1024 / 1024:.2f} MB")
        api_logger.info(f"é”™è¯¯æ•°ï¼š{self.stats['errors']}")
        api_logger.info("=" * 60)

        return self.stats

    def print_summary(self):
        """æ‰“å°æ¸…ç†æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("P2-3 æ— ç”¨ä»£ç æ¸…ç†æ‘˜è¦")
        print("=" * 60)
        print()

        if self.report['deprecated_tables']:
            print("ğŸ“¦ åºŸå¼ƒæ•°æ®åº“è¡¨:")
            for table in self.report['deprecated_tables']:
                print(f"   - {table}")
            print()

        if self.report['debug_files']:
            print("ğŸ”§ è°ƒè¯•æ–‡ä»¶:")
            for file in self.report['debug_files'][:10]:  # åªæ˜¾ç¤ºå‰ 10 ä¸ª
                print(f"   - {file}")
            if len(self.report['debug_files']) > 10:
                print(f"   ... è¿˜æœ‰ {len(self.report['debug_files']) - 10} ä¸ªæ–‡ä»¶")
            print()

        if self.report['commented_code_files']:
            print("ğŸ“ åŒ…å«å¤§æ®µæ³¨é‡Šä»£ç çš„æ–‡ä»¶:")
            for item in self.report['commented_code_files'][:5]:  # åªæ˜¾ç¤ºå‰ 5 ä¸ª
                print(f"   - {item['file']} ({item['lines']} è¡Œ)")
            if len(self.report['commented_code_files']) > 5:
                print(f"   ... è¿˜æœ‰ {len(self.report['commented_code_files']) - 5} ä¸ªæ–‡ä»¶")
            print()

        print("=" * 60)
        print("è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³ï¼šcleanup_p2_3_report.json")
        print("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 60)
    print("P2-3 æ— ç”¨ä»£ç æ¸…ç†å·¥å…·")
    print("=" * 60)
    print()

    # åˆ›å»ºæ¸…ç†å™¨
    cleaner = DeprecatedCodeCleaner()

    # æ‰§è¡Œæ¸…ç†ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰
    print("æ‰§è¡Œæ¨¡æ‹Ÿæ¸…ç†...")
    stats = cleaner.run_cleanup(dry_run=True, remove_debug_files=False)

    # æ‰“å°æ‘˜è¦
    cleaner.print_summary()

    # ç›´æ¥æ‰§è¡Œå®é™…æ¸…ç†ï¼ˆä»…åˆ é™¤åºŸå¼ƒè¡¨ï¼‰
    print()
    print("æ‰§è¡Œå®é™…æ¸…ç†ï¼ˆä»…åˆ é™¤åºŸå¼ƒæ•°æ®åº“è¡¨ï¼‰...")
    stats = cleaner.run_cleanup(dry_run=False, remove_debug_files=False)

    print()
    print("=" * 60)
    print("P2-3 æ¸…ç†å®Œæˆï¼")
    print("=" * 60)


if __name__ == '__main__':
    main()
