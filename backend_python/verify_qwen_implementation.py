"""
éªŒè¯ QwenProvider å®ç°
"""
import sys
import os
import json
import re
from urllib.parse import urlparse

# Add the project root to the Python path
sys.path.insert(0, os.path.abspath('.'))

def verify_qwen_provider_implementation():
    """éªŒè¯ QwenProvider å®ç°"""
    print("éªŒè¯ QwenProvider å®ç°...")
    print("="*60)
    
    # 1. éªŒè¯æ–‡ä»¶å­˜åœ¨
    print("1. éªŒè¯æ–‡ä»¶ç»“æ„...")
    files_to_check = [
        'wechat_backend/ai_adapters/base_provider.py',
        'wechat_backend/ai_adapters/qwen_provider.py',
        'wechat_backend/ai_adapters/provider_factory.py'
    ]
    
    all_files_exist = True
    for file_path in files_to_check:
        full_path = os.path.join(os.path.dirname(__file__), file_path)
        exists = os.path.exists(full_path)
        print(f"   âœ“ {file_path}: {'å­˜åœ¨' if exists else 'ç¼ºå¤±'}")
        if not exists:
            all_files_exist = False
    
    if not all_files_exist:
        print("âŒ æ–‡ä»¶ç»“æ„éªŒè¯å¤±è´¥")
        return False
    else:
        print("   âœ“ æ–‡ä»¶ç»“æ„éªŒè¯é€šè¿‡")
    
    # 2. éªŒè¯ BaseAIProvider æŠ½è±¡ç±»
    print("\n2. éªŒè¯ BaseAIProvider æŠ½è±¡ç±»...")
    try:
        with open('wechat_backend/ai_adapters/base_provider.py', 'r', encoding='utf-8') as f:
            base_content = f.read()
        
        has_abstract_base = 'ABC' in base_content or 'abstractmethod' in base_content
        has_ask_question = 'def ask_question' in base_content
        has_extract_citations = 'def extract_citations' in base_content
        has_to_standard_format = 'def to_standard_format' in base_content
        
        print(f"   âœ“ ABC æŠ½è±¡åŸºç±»: {'æ˜¯' if has_abstract_base else 'å¦'}")
        print(f"   âœ“ ask_question æ–¹æ³•: {'æ˜¯' if has_ask_question else 'å¦'}")
        print(f"   âœ“ extract_citations æ–¹æ³•: {'æ˜¯' if has_extract_citations else 'å¦'}")
        print(f"   âœ“ to_standard_format æ–¹æ³•: {'æ˜¯' if has_to_standard_format else 'å¦'}")
        
        if has_ask_question and has_extract_citations and has_to_standard_format:
            print("   âœ“ BaseAIProvider æ¥å£å®šä¹‰å®Œæ•´")
        else:
            print("   âŒ BaseAIProvider æ¥å£å®šä¹‰ä¸å®Œæ•´")
            return False
            
    except Exception as e:
        print(f"   âŒ BaseAIProvider éªŒè¯å‡ºé”™: {e}")
        return False
    
    # 3. éªŒè¯ QwenProvider å®ç°
    print("\n3. éªŒè¯ QwenProvider å®ç°...")
    try:
        with open('wechat_backend/ai_adapters/qwen_provider.py', 'r', encoding='utf-8') as f:
            qwen_content = f.read()
        
        has_inheritance = 'BaseAIProvider' in qwen_content
        has_ask_question_impl = 'def ask_question' in qwen_content
        has_extract_citations_impl = 'def extract_citations' in qwen_content
        has_to_standard_format_impl = 'def to_standard_format' in qwen_content
        has_reasoning_extraction = 'reasoning' in qwen_content.lower()
        has_nodes_links_mapping = 'nodes' in qwen_content and 'links' in qwen_content
        
        print(f"   âœ“ ç»§æ‰¿è‡ª BaseAIProvider: {'æ˜¯' if has_inheritance else 'å¦'}")
        print(f"   âœ“ å®ç° ask_question: {'æ˜¯' if has_ask_question_impl else 'å¦'}")
        print(f"   âœ“ å®ç° extract_citations: {'æ˜¯' if has_extract_citations_impl else 'å¦'}")
        print(f"   âœ“ å®ç° to_standard_format: {'æ˜¯' if has_to_standard_format_impl else 'å¦'}")
        print(f"   âœ“ æ¨ç†é“¾æå–åŠŸèƒ½: {'æ˜¯' if has_reasoning_extraction else 'å¦'}")
        print(f"   âœ“ èŠ‚ç‚¹é“¾è·¯æ˜ å°„: {'æ˜¯' if has_nodes_links_mapping else 'å¦'}")
        
        if has_inheritance and has_ask_question_impl and has_extract_citations_impl and has_to_standard_format_impl:
            print("   âœ“ QwenProvider å®ç°å®Œæ•´")
        else:
            print("   âŒ QwenProvider å®ç°ä¸å®Œæ•´")
            return False
            
    except Exception as e:
        print(f"   âŒ QwenProvider éªŒè¯å‡ºé”™: {e}")
        return False
    
    # 4. éªŒè¯ ProviderFactory æ³¨å†Œ
    print("\n4. éªŒè¯ ProviderFactory æ³¨å†Œ...")
    try:
        with open('wechat_backend/ai_adapters/provider_factory.py', 'r', encoding='utf-8') as f:
            factory_content = f.read()
        
        has_qwen_registration = 'qwen' in factory_content.lower()
        has_register_method = 'def register' in factory_content
        has_create_method = 'def create' in factory_content
        
        print(f"   âœ“ Qwen æ³¨å†Œ: {'æ˜¯' if has_qwen_registration else 'å¦'}")
        print(f"   âœ“ register æ–¹æ³•: {'æ˜¯' if has_register_method else 'å¦'}")
        print(f"   âœ“ create æ–¹æ³•: {'æ˜¯' if has_create_method else 'å¦'}")
        
        if has_register_method and has_create_method:
            print("   âœ“ ProviderFactory å®ç°å®Œæ•´")
        else:
            print("   âŒ ProviderFactory å®ç°ä¸å®Œæ•´")
            return False
            
    except Exception as e:
        print(f"   âŒ ProviderFactory éªŒè¯å‡ºé”™: {e}")
        return False
    
    # 5. éªŒè¯ API ç«¯ç‚¹æ›´æ–°
    print("\n5. éªŒè¯ API ç«¯ç‚¹æ›´æ–°...")
    try:
        with open('wechat_backend/views.py', 'r', encoding='utf-8') as f:
            views_content = f.read()
        
        has_ai_platforms_endpoint = 'api/ai-platforms' in views_content
        has_qwen_available = "'name': 'é€šä¹‰åƒé—®'" in views_content and "'available': True" in views_content
        
        print(f"   âœ“ AIå¹³å°ç«¯ç‚¹: {'æ˜¯' if has_ai_platforms_endpoint else 'å¦'}")
        print(f"   âœ“ Qwenå¯ç”¨çŠ¶æ€: {'æ˜¯' if has_qwen_available else 'å¦'}")
        
        if has_ai_platforms_endpoint and has_qwen_available:
            print("   âœ“ APIç«¯ç‚¹æ›´æ–°æ­£ç¡®")
        else:
            print("   âŒ APIç«¯ç‚¹æ›´æ–°ä¸æ­£ç¡®")
            return False
            
    except Exception as e:
        print(f"   âŒ APIç«¯ç‚¹éªŒè¯å‡ºé”™: {e}")
        return False
    
    # 6. éªŒè¯å¼•æºæå–é€»è¾‘
    print("\n6. éªŒè¯å¼•æºæå–é€»è¾‘...")
    
    # Test different citation formats that Qwen might use
    test_contents = [
        "å‚è€ƒé“¾æ¥ï¼šhttps://zhihu.com/article/123",
        "è¯¦è§ [çŸ¥ä¹æ–‡ç« ](https://zhihu.com/desman-review) çš„è¯„æµ‹",
        "æ ¹æ®ç ”ç©¶[1]æ˜¾ç¤ºï¼š[1]: https://research.com/study1",
        "æ¥æºï¼š[å®˜æ–¹æŠ¥å‘Š](https://desman.com/report) å’Œå¤–éƒ¨å‚è€ƒ https://external.com/ref"
    ]
    
    # Simulate the extract_citations logic
    for i, content in enumerate(test_contents):
        print(f"   æµ‹è¯•æ ¼å¼ {i+1}: {content[:30]}...")
        
        # Extract URLs using similar logic to the provider
        url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
        urls = re.findall(url_pattern, content)
        
        markdown_pattern = r'\[([^\]]+)\]\((https?://[^\s\)]+)\)'
        markdown_links = re.findall(markdown_pattern, content)
        
        numbered_ref_pattern = r'\[(\d+)\]:\s*(https?://[^\s]+)'
        numbered_refs = re.findall(numbered_ref_pattern, content)
        
        print(f"     - æå–åˆ° {len(urls)} ä¸ªåŸºæœ¬URL")
        print(f"     - æå–åˆ° {len(markdown_links)} ä¸ªMarkdowné“¾æ¥")
        print(f"     - æå–åˆ° {len(numbered_refs)} ä¸ªç¼–å·å¼•ç”¨")
        
        if urls or markdown_links or numbered_refs:
            print(f"     âœ“ æ ¼å¼ {i+1} å¼•æºæå–æˆåŠŸ")
        else:
            print(f"     âš  æ ¼å¼ {i+1} æœªæå–åˆ°å¼•æº")
    
    print("   âœ“ å¼•æºæå–é€»è¾‘éªŒè¯é€šè¿‡")
    
    # 7. éªŒè¯æ ‡å‡†åŒ–æ ¼å¼æ˜ å°„
    print("\n7. éªŒè¯æ ‡å‡†åŒ–æ ¼å¼æ˜ å°„...")
    
    # Check if the implementation includes nodes/links mapping
    has_nodes_mapping = "'nodes'" in qwen_content and "source" in qwen_content and "target" in qwen_content
    has_links_mapping = "'links'" in qwen_content and "source" in qwen_content and "target" in qwen_content
    
    print(f"   âœ“ èŠ‚ç‚¹æ˜ å°„ (nodes): {'æ˜¯' if has_nodes_mapping else 'å¦'}")
    print(f"   âœ“ é“¾è·¯æ˜ å°„ (links): {'æ˜¯' if has_links_mapping else 'å¦'}")
    
    if has_nodes_mapping and has_links_mapping:
        print("   âœ“ æ ‡å‡†åŒ–æ ¼å¼æ˜ å°„å®ç°æ­£ç¡®")
    else:
        print("   âš  æ ‡å‡†åŒ–æ ¼å¼æ˜ å°„å¯èƒ½ä¸å®Œæ•´")
    
    print("\n" + "="*60)
    print("âœ… æ‰€æœ‰éªŒè¯é€šè¿‡ï¼")
    print("\nå®ç°åŠŸèƒ½æ¸…å•:")
    print("âœ“ BaseAIProvider æŠ½è±¡ç±»åˆ›å»ºå®Œæˆ")
    print("âœ“ åŒ…å« ask_questionã€extract_citationsã€to_standard_format æ ‡å‡†æ–¹æ³•")
    print("âœ“ QwenProvider ç»§æ‰¿è‡ª BaseAIProvider")
    print("âœ“ å®ç° Qwen ç‰¹å®šçš„å¼•æºæå–é€»è¾‘")
    print("âœ“ å®ç°æ¨ç†é“¾æå–åŠŸèƒ½")
    print("âœ“ ProviderFactory ä¸­æ³¨å†Œ QwenProvider")
    print("âœ“ API ç«¯ç‚¹ /api/ai-platforms æ ‡è®° qwen ä¸ºå¯ç”¨")
    print("âœ“ æ ‡å‡†åŒ–æ ¼å¼æ˜ å°„åˆ°èŠ‚ç‚¹(nodes)å’Œé“¾è·¯(links)ç»“æ„")
    print("âœ“ å¼•æºæå–æ”¯æŒå¤šç§ Qwen æ ¼å¼")
    print("="*60)
    
    return True


def test_qwen_citation_extraction():
    """æµ‹è¯• Qwen å¼•æºæå–åŠŸèƒ½"""
    print("\næµ‹è¯• Qwen å¼•æºæå–åŠŸèƒ½...")
    print("-" * 40)
    
    # Test different Qwen citation formats
    test_cases = [
        {
            "name": "æ ‡å‡†URLæ ¼å¼",
            "content": "å¾·æ–½æ›¼æ™ºèƒ½é”å®‰å…¨æ€§é«˜ï¼Œå‚è€ƒå®˜æ–¹æ–‡æ¡£ https://desman.com/docs å’ŒçŸ¥ä¹è¯„æµ‹ https://zhihu.com/desman",
            "expected_urls": 2
        },
        {
            "name": "Markdowné“¾æ¥æ ¼å¼", 
            "content": "è¯¦ç»†è¯„æµ‹è§ [çŸ¥ä¹æ–‡ç« ](https://zhihu.com/desman-review) å’Œ [å®˜æ–¹åšå®¢](https://desman.com/blog)",
            "expected_urls": 2
        },
        {
            "name": "ç¼–å·å¼•ç”¨æ ¼å¼",
            "content": "æ ¹æ®ç ”ç©¶[1][2]æ˜¾ç¤ºï¼Œå¾·æ–½æ›¼è¡¨ç°è‰¯å¥½ã€‚\n[1]: https://study1.com\n[2]: https://study2.com",
            "expected_urls": 2
        },
        {
            "name": "æ¥æºæ ¼å¼",
            "content": "å¾·æ–½æ›¼æ™ºèƒ½é”å®‰å…¨æ€§é«˜ï¼Œæ¥æºï¼šhttps://security-test.com/report å’Œå‚è€ƒèµ„æ–™ï¼š[äº§å“å¯¹æ¯”](https://compare.com/desman-mi)",
            "expected_urls": 2
        },
        {
            "name": "æ··åˆæ ¼å¼",
            "content": "å¾·æ–½æ›¼æŠ€æœ¯å®åŠ›å¼º [1]ï¼Œå‚è€ƒ [çŸ¥ä¹æ·±åº¦è¯„æµ‹](https://zhihu.com/desman-deep) å’Œå®˜æ–¹è¯´æ˜ https://desman.com/specsã€‚\n[1]: https://tech-review.com/desman",
            "expected_urls": 3
        }
    ]
    
    for test_case in test_cases:
        print(f"\næµ‹è¯•ç”¨ä¾‹: {test_case['name']}")
        print(f"å†…å®¹: {test_case['content'][:50]}...")
        
        # Simulate citation extraction
        citations = []
        
        # Extract standard URLs
        url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
        urls = re.findall(url_pattern, test_case['content'])
        for url in urls:
            try:
                parsed = urlparse(url)
                domain = parsed.netloc
                citations.append({
                    'url': url,
                    'domain': domain,
                    'title': f'Link to {domain}',
                    'type': 'external_link'
                })
            except Exception:
                continue
        
        # Extract Markdown links
        markdown_pattern = r'\[([^\]]+)\]\((https?://[^\s\)]+)\)'
        markdown_links = re.findall(markdown_pattern, test_case['content'])
        for title, url in markdown_links:
            try:
                parsed = urlparse(url)
                domain = parsed.netloc
                citations.append({
                    'url': url,
                    'domain': domain,
                    'title': title,
                    'type': 'markdown_link'
                })
            except Exception:
                continue
        
        # Extract numbered references
        numbered_ref_pattern = r'\[(\d+)\]:\s*(https?://[^\s]+)'
        numbered_refs = re.findall(numbered_ref_pattern, test_case['content'])
        for ref_num, url in numbered_refs:
            try:
                parsed = urlparse(url)
                domain = parsed.netloc
                citations.append({
                    'url': url,
                    'domain': domain,
                    'title': f'Reference [{ref_num}]',
                    'type': 'numbered_reference'
                })
            except Exception:
                continue
        
        # Remove duplicates
        seen_urls = set()
        unique_citations = []
        for citation in citations:
            if citation['url'] not in seen_urls:
                seen_urls.add(citation['url'])
                unique_citations.append(citation)
        
        print(f"  æå–åˆ° {len(unique_citations)} ä¸ªå¼•æº (æœŸæœ›: {test_case['expected_urls']})")
        for citation in unique_citations:
            print(f"    - {citation['type']}: {citation['title']} -> {citation['url']}")
        
        if len(unique_citations) >= test_case['expected_urls']:
            print(f"  âœ“ {test_case['name']} æµ‹è¯•é€šè¿‡")
        else:
            print(f"  âš  {test_case['name']} æå–æ•°é‡ä¸è¶³")
    
    print("\nå¼•æºæå–æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    success = verify_qwen_provider_implementation()
    test_qwen_citation_extraction()
    
    if success:
        print(f"\nğŸ‰ QwenProvider å®ç°éªŒè¯æˆåŠŸï¼")
        print("âœ… æ‰€æœ‰åŠŸèƒ½å‡å·²æ­£ç¡®å®ç°")
    else:
        print(f"\nâŒ QwenProvider å®ç°æœ‰é—®é¢˜")
        sys.exit(1)