# å“ç‰Œè¯Šæ–­ç³»ç»Ÿ - ä»£ç æ”¹é€ æ–¹æ¡ˆ

**æ–‡æ¡£ç¼–å·**: PLAN-20260225-001  
**ç¼–åˆ¶äºº**: é¦–å¸­æ¶æ„å¸ˆ å¼ å·¥  
**æ—¥æœŸ**: 2026-02-25  
**ç‰ˆæœ¬**: 1.0  
**çŠ¶æ€**: å¾…è¯„å®¡  

---

## ä¸€ã€ç°æœ‰ä»£ç å®¡è®¡æŠ¥å‘Š

### 1.1 ä»£ç æ¶æ„æ€»è§ˆ

```
backend_python/
â”œâ”€â”€ wechat_backend/
â”‚   â”œâ”€â”€ views/
â”‚   â”‚   â””â”€â”€ diagnosis_views.py        # æŠ¥å‘Šç”Ÿæˆå…¥å£ (2665 è¡Œ)
â”‚   â”œâ”€â”€ nxm_execution_engine.py       # æ‰§è¡Œå¼•æ“ (800 è¡Œ)
â”‚   â”œâ”€â”€ nxm_scheduler.py              # ä»»åŠ¡è°ƒåº¦ (161 è¡Œ)
â”‚   â”œâ”€â”€ nxm_result_aggregator.py      # ç»“æœèšåˆ (300 è¡Œ)
â”‚   â”œâ”€â”€ ai_adapters/
â”‚   â”‚   â”œâ”€â”€ base_adapter.py           # åŸºç¡€é€‚é…å™¨
â”‚   â”‚   â”œâ”€â”€ doubao_adapter.py         # è±†åŒ…é€‚é…å™¨
â”‚   â”‚   â””â”€â”€ doubao_priority_adapter.py # è±†åŒ…ä¼˜å…ˆçº§é€‚é…å™¨
â”‚   â”œâ”€â”€ fault_tolerant_executor.py    # å®¹é”™æ‰§è¡Œå™¨ (æ–°å»º)
â”‚   â”œâ”€â”€ repositories/                 # æ•°æ®ä»“åº“ (æ–°å»º)
â”‚   â”‚   â”œâ”€â”€ report_snapshot_repository.py
â”‚   â”‚   â””â”€â”€ dimension_result_repository.py
â”‚   â”œâ”€â”€ diagnosis_report_repository.py  # è¯Šæ–­æŠ¥å‘Šä»“åº“ (æ—§)
â”‚   â””â”€â”€ diagnosis_report_storage.py     # è¯Šæ–­æŠ¥å‘Šå­˜å‚¨ (æ—§)
â””â”€â”€ tests/
    â””â”€â”€ test_brand_diagnosis_system.py  # ç»¼åˆæµ‹è¯• (æ–°å»º)
```

### 1.2 æ ¸å¿ƒæµç¨‹åˆ†æ

#### æŠ¥å‘Šç”Ÿæˆå…¥å£
**æ–‡ä»¶**: `diagnosis_views.py:91-370`  
**å‡½æ•°**: `perform_brand_test()`

```python
# å½“å‰å®ç°ï¼ˆç®€åŒ–ï¼‰
@wechat_bp.route('/api/perform-brand-test', methods=['POST'])
def perform_brand_test():
    # 1. å‚æ•°éªŒè¯
    data = request.get_json()
    brand_list = data.get('brandList', [])
    selected_models = data.get('selectedModels', [])
    custom_questions = data.get('customQuestions', [])
    
    # 2. ç”Ÿæˆ execution_id
    execution_id = str(uuid.uuid4())
    
    # 3. åˆå§‹åŒ–å†…å­˜å­˜å‚¨
    execution_store[execution_id] = {
        'progress': 0,
        'status': 'initializing',
        'results': []
    }
    
    # 4. å¯åŠ¨å¼‚æ­¥çº¿ç¨‹
    thread = Thread(target=run_async_test)
    thread.start()
    
    # 5. ç«‹å³è¿”å›
    return jsonify({'status': 'success', 'execution_id': execution_id})
```

**é—®é¢˜è¯†åˆ«**:
| é—®é¢˜ | å½±å“ | ä¸¥é‡åº¦ |
|------|------|--------|
| execution_store çº¯å†…å­˜å­˜å‚¨ | æœåŠ¡é‡å¯æ•°æ®ä¸¢å¤± | ğŸ”´ é«˜ |
| æœªåˆ›å»º diagnosis_reports è®°å½• | è¿›åº¦æ— æ³•æŒä¹…åŒ– | ğŸ”´ é«˜ |
| å¼‚æ­¥çº¿ç¨‹æ— å¼‚å¸¸å¤„ç† | å¤±è´¥æ— æ—¥å¿— | ğŸŸ¡ ä¸­ |

#### æ‰§è¡Œå¼•æ“
**æ–‡ä»¶**: `nxm_execution_engine.py:100-200`  
**å‡½æ•°**: `execute_nxm_test()`

```python
# å½“å‰å®ç°ï¼ˆç®€åŒ–ï¼‰
def execute_nxm_test(execution_id, main_brand, competitor_brands, ...):
    scheduler = create_scheduler(execution_id, execution_store)
    
    # éå†å“ç‰Œ Ã— é—®é¢˜ Ã— æ¨¡å‹
    for brand in all_brands:
        for q_idx, question in enumerate(raw_questions):
            for model_info in selected_models:
                # åˆ›å»º AI å®¢æˆ·ç«¯
                client = AIAdapterFactory.create(model_name)
                
                # åŒæ­¥è°ƒç”¨ AIï¼ˆæœ‰é—®é¢˜ï¼‰
                loop = asyncio.new_event_loop()
                response = loop.run_until_complete(
                    asyncio.wait_for(
                        loop.run_in_executor(None, lambda: client.generate_response(...)),
                        timeout=timeout
                    )
                )
                
                # è§£æ GEO æ•°æ®
                geo_data, parse_error = parse_geo_with_validation(response, ...)
                
                # æ·»åŠ ç»“æœ
                results.append(geo_data)
```

**é—®é¢˜è¯†åˆ«**:
| é—®é¢˜ | å½±å“ | ä¸¥é‡åº¦ |
|------|------|--------|
| `generate_response` æ–¹æ³•ä¸å­˜åœ¨ | AI è°ƒç”¨ 100% å¤±è´¥ | ğŸ”´ è‡´å‘½ |
| æ—  try-catch åŒ…è£¹ | å•ä¸ªå¤±è´¥ä¸­æ–­æ•´ä½“ | ğŸ”´ é«˜ |
| ç»“æœæœªæŒä¹…åŒ– | è¿›åº¦æŸ¥è¯¢å¤±æ•ˆ | ğŸ”´ é«˜ |
| æœªä½¿ç”¨ FaultTolerantExecutor | æ— å®¹é”™æœºåˆ¶ | ğŸŸ¡ ä¸­ |

#### æ•°æ®å­˜å‚¨
**æ–‡ä»¶**: `diagnosis_report_repository.py`  
**å‡½æ•°**: `save_test_record()`

```python
# å½“å‰å®ç°
def save_test_record(user_openid, brand_name, ...):
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO test_records (...)
            VALUES (?, ?, ?, ...)
        ''', (...))
        return cursor.lastrowid
```

**é—®é¢˜è¯†åˆ«**:
| é—®é¢˜ | å½±å“ | ä¸¥é‡åº¦ |
|------|------|--------|
| åªå­˜ test_records è¡¨ | æ— å¿«ç…§å­˜å‚¨ | ğŸ”´ é«˜ |
| æ—  report_snapshots è¡¨ | å†å²ä¸€è‡´æ€§æ— ä¿éšœ | ğŸ”´ é«˜ |
| æ—  dimension_results è¡¨ | ç»´åº¦ç»“æœä¸¢å¤± | ğŸŸ¡ ä¸­ |

### 1.3 è„†å¼±ç‚¹æ ‡è®°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç°æœ‰ä»£ç è„†å¼±ç‚¹åœ°å›¾                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[1] diagnosis_views.py:272 - execution_store çº¯å†…å­˜
    â”‚ âŒ æœåŠ¡é‡å¯æ•°æ®ä¸¢å¤±
    â–¼
[2] diagnosis_views.py:316 - execute_nxm_test è°ƒç”¨
    â”‚ âŒ æ— æŒä¹…åŒ–
    â–¼
[3] nxm_execution_engine.py:174 - client.generate_response()
    â”‚ âŒ æ–¹æ³•ä¸å­˜åœ¨ï¼Œ100% å¤±è´¥
    â”‚ âŒ æ—  try-catch
    â–¼
[4] nxm_execution_engine.py:195 - parse_geo_with_validation
    â”‚ âš ï¸ è§£æå¤±è´¥æ— é™çº§
    â–¼
[5] nxm_execution_engine.py:240 - results.append
    â”‚ âŒ ä»…å†…å­˜å­˜å‚¨ï¼Œæœªå†™æ•°æ®åº“
    â–¼
[6] æ—  snapshot ä¿å­˜é€»è¾‘
    â”‚ âŒ å†å²æŠ¥å‘Šæ— å¿«ç…§
```

---

## äºŒã€æ”¹é€ æ–¹æ¡ˆè®¾è®¡

### 2.1 æ”¹é€ åŸåˆ™

1. **ç²¾å‡†æ‰‹æœ¯** - åªä¿®æ”¹å¿…è¦ä»£ç ï¼Œä¿ç•™å¯ç”¨éƒ¨åˆ†
2. **æ¸è¿›å¼æ”¹é€ ** - åˆ†é˜¶æ®µå®æ–½ï¼Œæ¯æ­¥å¯å›é€€
3. **å‘åå…¼å®¹** - å…¼å®¹æ—§æ•°æ®ç»“æ„
4. **é›¶å®•æœº** - æ”¹é€ è¿‡ç¨‹ä¸å½±å“ç°æœ‰ç”¨æˆ·

### 2.2 æ”¹é€ ç‚¹æ¸…å•

| ç¼–å· | æ”¹é€ ç‚¹ | æ–‡ä»¶ | è¡Œå· | æ”¹é€ æ–¹å¼ | é£é™©ç­‰çº§ |
|------|--------|------|------|---------|---------|
| M001 | ä¿®å¤ AI è°ƒç”¨æ–¹æ³• | nxm_execution_engine.py | 174 | generate_responseâ†’send_prompt | ğŸŸ¢ ä½ |
| M002 | æ·»åŠ å®¹é”™åŒ…è£¹ | nxm_execution_engine.py | 160-200 | å¼•å…¥ FaultTolerantExecutor | ğŸŸ¡ ä¸­ |
| M003 | å®æ—¶æŒä¹…åŒ– | nxm_execution_engine.py | 240 | æ·»åŠ  save_dimension_result | ğŸŸ¡ ä¸­ |
| M004 | å¿«ç…§å­˜å‚¨ | diagnosis_views.py | 370 | æ·»åŠ  save_report_snapshot | ğŸŸ¡ ä¸­ |
| M005 | æ•°æ®åº“è¡¨åˆ›å»º | repositories/ | - | æ‰§è¡Œè¿ç§»è„šæœ¬ | ğŸŸ¢ ä½ |
| M006 | å‰ç«¯é”™è¯¯ UI | å°ç¨‹åºç«¯ | - | æ–°å¢é”™è¯¯å±•ç¤ºç»„ä»¶ | ğŸŸ¡ ä¸­ |

### 2.3 è¯¦ç»†æ”¹é€ æ–¹æ¡ˆ

#### ã€M001ã€‘ä¿®å¤ AI è°ƒç”¨æ–¹æ³•

**æ–‡ä»¶**: `wechat_backend/nxm_execution_engine.py`  
**è¡Œå·**: 174  
**æ”¹é€ å‰**:
```python
response = loop.run_until_complete(
    asyncio.wait_for(
        asyncio.get_event_loop().run_in_executor(
            None,
            lambda: client.generate_response(prompt=prompt, api_key=api_key)
        ),
        timeout=timeout
    )
)
```

**æ”¹é€ å**:
```python
# ä¿®å¤ï¼šä½¿ç”¨ send_prompt æ–¹æ³•è€Œé generate_response
response = loop.run_until_complete(
    asyncio.wait_for(
        asyncio.get_event_loop().run_in_executor(
            None,
            lambda: client.send_prompt(prompt=prompt)  # âœ… ä¿®æ”¹
        ),
        timeout=timeout
    )
)
```

**å½±å“èŒƒå›´**: æ‰€æœ‰ AI è°ƒç”¨  
**æµ‹è¯•éªŒè¯**: å•å…ƒæµ‹è¯•éªŒè¯ send_prompt è°ƒç”¨

---

#### ã€M002ã€‘æ·»åŠ å®¹é”™åŒ…è£¹

**æ–‡ä»¶**: `wechat_backend/nxm_execution_engine.py`  
**è¡Œå·**: 160-200  
**æ”¹é€ å‰**:
```python
try:
    # åŒæ­¥è°ƒç”¨ AI
    loop = asyncio.new_event_loop()
    response = loop.run_until_complete(...)
    
    # è§£æ GEO æ•°æ®
    geo_data, parse_error = parse_geo_with_validation(response, ...)
    
except Exception as e:
    # å¼‚å¸¸ç›´æ¥æŠ›å‡ºï¼Œä¸­æ–­æµç¨‹
    raise
```

**æ”¹é€ å**:
```python
# å¼•å…¥å®¹é”™æ‰§è¡Œå™¨
from wechat_backend.fault_tolerant_executor import FaultTolerantExecutor

ft_executor = FaultTolerantExecutor(timeout_seconds=timeout)

# ä½¿ç”¨å®¹é”™åŒ…è£¹
result = await ft_executor.execute_with_fallback(
    task_func=lambda: client.send_prompt(prompt=prompt),
    task_name=f"{brand}-{model_name}",
    source=model_name
)

if result.status == "success":
    geo_data, parse_error = parse_geo_with_validation(result.data, ...)
    results.append(geo_data)
else:
    # âœ… å¤±è´¥ä¸ä¸­æ–­ï¼Œè®°å½•é”™è¯¯ç»§ç»­ä¸‹ä¸€ä¸ª
    results.append({
        "brand": brand,
        "model": model_name,
        "status": "failed",
        "error_message": result.error_message,
        "data": None
    })
```

**å½±å“èŒƒå›´**: NxM æ‰§è¡Œæµç¨‹  
**æµ‹è¯•éªŒè¯**: æ¨¡æ‹Ÿ AI å¤±è´¥ï¼ŒéªŒè¯æµç¨‹ç»§ç»­

---

#### ã€M003ã€‘å®æ—¶æŒä¹…åŒ–

**æ–‡ä»¶**: `wechat_backend/nxm_execution_engine.py`  
**è¡Œå·**: 240  
**æ”¹é€ å‰**:
```python
# ä»…æ·»åŠ åˆ°å†…å­˜
results.append(geo_data)
scheduler.update_progress(completed, total_tasks, 'ai_fetching')
```

**æ”¹é€ å**:
```python
from wechat_backend.repositories import save_dimension_result, save_task_status

# æ·»åŠ åˆ°å†…å­˜
results.append(geo_data)

# âœ… å®æ—¶æŒä¹…åŒ–ç»´åº¦ç»“æœ
save_dimension_result(
    execution_id=execution_id,
    dimension_name=f"{brand}-{model_name}",
    dimension_type="ai_analysis",
    source=model_name,
    status=geo_data.get("status", "success"),
    score=geo_data.get("rank"),
    data=geo_data,
    error_message=geo_data.get("_error")
)

# âœ… å®æ—¶æ›´æ–°è¿›åº¦
save_task_status(
    task_id=execution_id,
    stage='ai_fetching',
    progress=int((completed / total_tasks) * 100),
    status_text=f'å·²å®Œæˆ {completed}/{total_tasks}'
)

scheduler.update_progress(completed, total_tasks, 'ai_fetching')
```

**å½±å“èŒƒå›´**: ç»“æœå­˜å‚¨  
**æµ‹è¯•éªŒè¯**: éªŒè¯æ•°æ®åº“æœ‰è®°å½•

---

#### ã€M004ã€‘å¿«ç…§å­˜å‚¨

**æ–‡ä»¶**: `wechat_python/views/diagnosis_views.py`  
**è¡Œå·**: 370ï¼ˆrun_async_test å‡½æ•°æœ«å°¾ï¼‰  
**æ”¹é€ å‰**:
```python
def run_async_test():
    try:
        # æ‰§è¡Œ NxM æµ‹è¯•
        result = execute_nxm_test(...)
        
        # æ— å¿«ç…§ä¿å­˜
    except Exception as e:
        execution_store[execution_id]['status'] = 'failed'
```

**æ”¹é€ å**:
```python
from wechat_backend.repositories import save_report_snapshot

def run_async_test():
    try:
        # æ‰§è¡Œ NxM æµ‹è¯•
        result = execute_nxm_test(...)
        
        # âœ… æ„å»ºå®Œæ•´æŠ¥å‘Š
        report_data = {
            "reportId": execution_id,
            "userId": user_id,
            "brandName": main_brand,
            "generateTime": datetime.now().isoformat(),
            "reportVersion": "v2.0",
            "reportData": {
                "overallScore": calculate_overall_score(result),
                "overallStatus": result.get('status', 'completed'),
                "dimensions": result.get('results', [])
            }
        }
        
        # âœ… ä¿å­˜å¿«ç…§
        save_report_snapshot(
            execution_id=execution_id,
            user_id=user_id,
            report_data=report_data
        )
        
        # âœ… æ›´æ–° diagnosis_reports çŠ¶æ€
        update_diagnosis_status(execution_id, 'completed')
        
    except Exception as e:
        execution_store[execution_id]['status'] = 'failed'
        # âœ… å³ä½¿å¤±è´¥ä¹Ÿä¿å­˜é”™è¯¯æŠ¥å‘Š
        save_report_snapshot(
            execution_id=execution_id,
            user_id=user_id,
            report_data={"error": str(e), "status": "failed"}
        )
```

**å½±å“èŒƒå›´**: æŠ¥å‘Šå®Œæˆå¤„ç†  
**æµ‹è¯•éªŒè¯**: éªŒè¯å¿«ç…§è¡¨æœ‰è®°å½•

---

#### ã€M005ã€‘æ•°æ®åº“è¡¨åˆ›å»º

**æ–‡ä»¶**: `backend_python/database.db`  
**æ“ä½œ**: æ‰§è¡Œè¿ç§»è„šæœ¬

```sql
-- åˆ›å»º report_snapshots è¡¨
CREATE TABLE IF NOT EXISTS report_snapshots (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    execution_id TEXT UNIQUE NOT NULL,
    user_id TEXT NOT NULL,
    report_data TEXT NOT NULL,
    report_hash TEXT NOT NULL,
    size_kb INTEGER NOT NULL,
    storage_timestamp TEXT NOT NULL,
    report_version TEXT DEFAULT 'v1.0'
);

-- åˆ›å»º dimension_results è¡¨
CREATE TABLE IF NOT EXISTS dimension_results (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    execution_id TEXT NOT NULL,
    dimension_name TEXT NOT NULL,
    dimension_type TEXT NOT NULL,
    source TEXT NOT NULL,
    status TEXT NOT NULL,
    score REAL,
    data TEXT,
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_snapshot_execution_id ON report_snapshots(execution_id);
CREATE INDEX IF NOT EXISTS idx_snapshot_user_id ON report_snapshots(user_id);
CREATE INDEX IF NOT EXISTS idx_dimension_execution_id ON dimension_results(execution_id);
```

**å½±å“èŒƒå›´**: æ•°æ®åº“ç»“æ„  
**æµ‹è¯•éªŒè¯**: éªŒè¯è¡¨å­˜åœ¨

---

#### ã€M006ã€‘å‰ç«¯é”™è¯¯ UI

**æ–‡ä»¶**: å°ç¨‹åºç«¯ `pages/report-detail/index.wxml`  
**æ”¹é€ å‰**:
```html
<view class="dimension-card">
  <text>{{dimension.name}}</text>
  <text>å¾—åˆ†ï¼š{{dimension.score}}</text>
</view>
```

**æ”¹é€ å**:
```html
<view class="dimension-card {{dimension.status === 'failed' ? 'failed' : ''}}">
  <view class="dimension-header">
    <text class="dimension-name">{{dimension.name}}</text>
    <text wx:if="{{dimension.status === 'failed'}}" class="badge-warning">æ•°æ®æš‚ç¼º</text>
  </view>
  
  <view wx:if="{{dimension.status === 'success'}}">
    <text>å¾—åˆ†ï¼š{{dimension.score}}</text>
    <!-- åŸæœ‰å†…å®¹ -->
  </view>
  
  <view wx:else class="error-box">
    <text class="error-icon">âš ï¸</text>
    <text class="error-message">{{dimension.error_message}}</text>
    <button class="retry-btn" bindtap="retryDimension" data-dimension="{{dimension}}">é‡æ–°è·å–</button>
  </view>
</view>
```

**å½±å“èŒƒå›´**: å‰ç«¯å±•ç¤º  
**æµ‹è¯•éªŒè¯**: UI éªŒæ”¶

---

## ä¸‰ã€ä»£ç å¤ç”¨ç‡è¯„ä¼°

| æ¨¡å— | å¤ç”¨æ–¹å¼ | å¤ç”¨ç‡ | è¯´æ˜ |
|------|---------|--------|------|
| diagnosis_views.py | ä¿ç•™å…¥å£ï¼Œä¿®æ”¹å†…éƒ¨é€»è¾‘ | 70% | è·¯ç”±å’Œå‚æ•°éªŒè¯ä¿ç•™ |
| nxm_execution_engine.py | ä¿ç•™æ¡†æ¶ï¼Œä¿®æ”¹è°ƒç”¨æ–¹å¼ | 50% | å¾ªç¯ç»“æ„ä¿ç•™ï¼ŒAI è°ƒç”¨ä¿®æ”¹ |
| nxm_scheduler.py | å®Œå…¨ä¿ç•™ | 100% | è°ƒåº¦é€»è¾‘æ— éœ€ä¿®æ”¹ |
| nxm_result_aggregator.py | ä¿ç•™è§£æé€»è¾‘ | 80% | æ·»åŠ é”™è¯¯å¤„ç† |
| ai_adapters/* | å®Œå…¨ä¿ç•™ | 100% | é€‚é…å™¨æ— éœ€ä¿®æ”¹ |
| fault_tolerant_executor.py | æ–°å¢ | 0% | æ–°å¢å®¹é”™æ¨¡å— |
| repositories/* | æ–°å¢ | 0% | æ–°å¢æ•°æ®ä»“åº“ |

**æ€»ä½“å¤ç”¨ç‡**: ~70%

---

## å››ã€é£é™©ä¸ç¼“è§£

| é£é™© | å½±å“ | æ¦‚ç‡ | ç¼“è§£æªæ–½ |
|------|------|------|---------|
| M001 ä¿®æ”¹å½±å“å…¶ä»–é€‚é…å™¨ | å…¶ä»–å¹³å°è°ƒç”¨å¤±è´¥ | ä½ | å•å…ƒæµ‹è¯•å…¨è¦†ç›– |
| M002 å®¹é”™åŒ…è£¹æ€§èƒ½ä¸‹é™ | æ‰§è¡Œæ—¶é—´å¢åŠ  | ä¸­ | å‹æµ‹éªŒè¯ |
| M003 æ•°æ®åº“å†™å…¥é¢‘ç¹ | æ•°æ®åº“æ€§èƒ½ç“¶é¢ˆ | ä¸­ | æ·»åŠ æ‰¹é‡å†™å…¥ä¼˜åŒ– |
| M004 å¿«ç…§å­˜å‚¨å¤±è´¥ | æŠ¥å‘Šæ— æ³•æŸ¥è¯¢ | ä½ | é™çº§åˆ°æ–‡ä»¶å­˜å‚¨ |
| M005 è¡¨åˆ›å»ºå†²çª | æ•°æ®åº“è¿ç§»å¤±è´¥ | ä½ | IF NOT EXISTS ä¿æŠ¤ |
| M006 å‰ç«¯å…¼å®¹æ€§é—®é¢˜ | æ—§ç‰ˆå°ç¨‹åºæŠ¥é”™ | ä¸­ | æ¡ä»¶æ¸²æŸ“ä¿æŠ¤ |

---

## äº”ã€å®æ–½è®¡åˆ’

| é˜¶æ®µ | ä»»åŠ¡ | è´Ÿè´£äºº | é¢„è®¡æ—¶é—´ | äº¤ä»˜ç‰© |
|------|------|--------|---------|--------|
| **Day 1** | ä»£ç å®¡è®¡ | å¼ å·¥ | 4 å°æ—¶ | æœ¬æ–‡æ¡£ |
| **Day 1** | æ–¹æ¡ˆè¯„å®¡ | å…¨ä½“ | 2 å°æ—¶ | è¯„å®¡æ„è§ |
| **Day 2** | M001-M003 å®æ–½ | æå·¥ | 6 å°æ—¶ | ä¿®æ”¹åä»£ç  |
| **Day 2** | M004-M005 å®æ–½ | æå·¥ | 4 å°æ—¶ | æ•°æ®åº“è¿ç§» |
| **Day 3** | M006 å®æ–½ | ç‹å·¥ | 8 å°æ—¶ | å‰ç«¯ç»„ä»¶ |
| **Day 4** | æµ‹è¯•éªŒè¯ | èµµå·¥ | 8 å°æ—¶ | æµ‹è¯•æŠ¥å‘Š |
| **Day 5** | ç°åº¦å‘å¸ƒ | å­™å·¥ | 4 å°æ—¶ | å‘å¸ƒæŠ¥å‘Š |

---

## å…­ã€éªŒæ”¶æ ‡å‡†

### 6.1 åŠŸèƒ½éªŒæ”¶

- [ ] æ­£å¸¸æµç¨‹ï¼šæ‰€æœ‰ API æ­£å¸¸ï¼ŒæŠ¥å‘Šå®Œæ•´ç”Ÿæˆ
- [ ] éƒ¨åˆ†å¤±è´¥ï¼šå•ä¸ª API å¤±è´¥ï¼Œå…¶ä»–æ¨¡å—æ­£å¸¸å±•ç¤º
- [ ] å…¨éƒ¨å¤±è´¥ï¼šæ˜¾ç¤ºå‹å¥½æç¤ºï¼Œä¸æŠ¥é”™ 500
- [ ] å†å²æŸ¥è¯¢ï¼šå†å²æŠ¥å‘Šä¸ç”Ÿæˆæ—¶å®Œå…¨ä¸€è‡´

### 6.2 æŠ€æœ¯éªŒæ”¶

- [ ] ä»£ç  Review é€šè¿‡ï¼ˆå¼ å·¥ç­¾å­—ï¼‰
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%
- [ ] å‹æµ‹ï¼š100 å¹¶å‘ä¸‹æˆåŠŸç‡ > 95%
- [ ] ç›‘æ§å‘Šè­¦é…ç½®å®Œæˆ

### 6.3 ç”¨æˆ·ä½“éªŒéªŒæ”¶

- [ ] é”™è¯¯æç¤ºå‹å¥½ï¼Œæ— æŠ€æœ¯æœ¯è¯­
- [ ] é¡µé¢ä¸ç™½å±ï¼Œå¸ƒå±€ä¸ç ´å
- [ ] æ”¯æŒå¤±è´¥æ¨¡å—é‡è¯•

---

**ç¼–åˆ¶äºº**: å¼ å·¥  
**å®¡æ ¸äºº**: å¾…å¡«å†™  
**æ‰¹å‡†äºº**: å¾…å¡«å†™  
**æ—¥æœŸ**: 2026-02-25
