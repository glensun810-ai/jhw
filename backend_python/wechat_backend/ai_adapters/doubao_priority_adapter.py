"""
è±†åŒ… AI ä¼˜å…ˆçº§é€‚é…å™¨
æ”¯æŒå¤šæ¨¡å‹ä¼˜å…ˆçº§è‡ªåŠ¨é€‰æ‹©ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ¨¡å‹

P0-DOUBAO-2 ä¿®å¤ï¼šé…é¢è€—å°½æ¨¡å‹ç¼“å­˜
- ä½¿ç”¨ç±»çº§åˆ«ç¼“å­˜ exhausted_models_cache åœ¨å†…å­˜ä¸­ç¼“å­˜ 429 çŠ¶æ€
- å½“å‰æ‰§è¡Œæ‰¹æ¬¡å†…ä¸å†åå¤å°è¯•å·²æ¬ è´¹çš„æ¨¡å‹
- ç¼“å­˜è‡ªåŠ¨è¿‡æœŸï¼ˆ10 åˆ†é’Ÿï¼‰ï¼Œé¿å…é•¿æœŸå½±å“
"""

import os
import time
from typing import Optional, List, Dict, Any, Set
from wechat_backend.ai_adapters.doubao_adapter import DoubaoAdapter
from wechat_backend.ai_adapters.base_adapter import AIClient, AIResponse, AIPlatformType, AIErrorType
from wechat_backend.logging_config import api_logger
from wechat_backend.config_manager import ConfigurationManager as PlatformConfigManager
from legacy_config import Config


class DoubaoPriorityAdapter(AIClient):
    """
    è±†åŒ… AI ä¼˜å…ˆçº§é€‚é…å™¨
    æŒ‰ä¼˜å…ˆçº§é¡ºåºå°è¯•å¤šä¸ªæ¨¡å‹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ¨¡å‹
    
    é…é¢è€—å°½æ¨¡å‹ç¼“å­˜æœºåˆ¶ï¼š
    - exhausted_models_cache: ç±»çº§åˆ«ç¼“å­˜ï¼Œå­˜å‚¨æ‰€æœ‰å®ä¾‹å…±äº«çš„é…é¢è€—å°½æ¨¡å‹
    - exhausted_timestamps: è®°å½•æ¯ä¸ªæ¨¡å‹è¢«æ ‡è®°ä¸ºè€—å°½çš„æ—¶é—´æˆ³
    - CACHE_TTL: ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 10 åˆ†é’Ÿ
    """

    # ==================== P0-DOUBAO-2 ä¿®å¤ï¼šé…é¢è€—å°½æ¨¡å‹ç¼“å­˜ ====================
    # ç±»çº§åˆ«ç¼“å­˜ï¼Œæ‰€æœ‰å®ä¾‹å…±äº«
    exhausted_models_cache: Set[str] = set()  # é…é¢è€—å°½çš„æ¨¡å‹é›†åˆ
    exhausted_timestamps: Dict[str, float] = {}  # æ¨¡å‹è€—å°½æ—¶é—´æˆ³
    CACHE_TTL: int = 600  # ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 10 åˆ†é’Ÿ
    # =======================================================================
    
    def __init__(self, api_key: str, model_name: str = None, base_url: Optional[str] = None):
        # ä¿å­˜ API Key
        self.api_key = api_key
        self.base_url = base_url

        # è·å–ä¼˜å…ˆçº§æ¨¡å‹åˆ—è¡¨
        self.priority_models = self._get_priority_models()

        # å¦‚æœä¼ å…¥äº† model_nameï¼Œåˆ™æ·»åŠ åˆ°ä¼˜å…ˆçº§åˆ—è¡¨æœ€å‰é¢
        if model_name and model_name not in self.priority_models:
            self.priority_models.insert(0, model_name)

        # å¦‚æœæ²¡æœ‰é…ç½®ä»»ä½•æ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not self.priority_models:
            self.priority_models = ['ep-20260212000000-gd5tq']

        # å½“å‰é€‰ä¸­çš„æ¨¡å‹å’Œé€‚é…å™¨
        self.selected_model: Optional[str] = None
        self.selected_adapter: Optional[DoubaoAdapter] = None

        # ã€P0 ä¿®å¤ã€‘è®°å½• 429 é”™è¯¯çš„æ¨¡å‹ï¼ˆé…é¢è€—å°½ï¼‰- å®ä¾‹çº§åˆ«ï¼ˆå‘åå…¼å®¹ï¼‰
        self.exhausted_models: set = set()

        # ã€P0-DOUBAO-2 ä¿®å¤ã€‘æ¸…ç†è¿‡æœŸç¼“å­˜
        self._cleanup_expired_cache()

        # å°è¯•åˆå§‹åŒ–é€‚é…å™¨ï¼ˆé€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ¨¡å‹ï¼‰
        self._init_adapter()

        # å¦‚æœæˆåŠŸåˆå§‹åŒ–ï¼Œè°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        if self.selected_adapter:
            super().__init__(AIPlatformType.DOUBAO, self.selected_model, api_key)
            # å¤åˆ¶é€‚é…å™¨å±æ€§
            self.session = self.selected_adapter.session
            self.latency_history = self.selected_adapter.latency_history
            self.circuit_breaker = self.selected_adapter.circuit_breaker
        else:
            # å¦‚æœæ‰€æœ‰æ¨¡å‹éƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹åˆ›å»ºé€‚é…å™¨ï¼ˆå¯èƒ½ä¼šå¤±è´¥ï¼‰
            super().__init__(AIPlatformType.DOUBAO, self.priority_models[0], api_key)
    
    def _cleanup_expired_cache(self):
        """
        æ¸…ç†è¿‡æœŸçš„é…é¢è€—å°½ç¼“å­˜
        
        ç§»é™¤è¶…è¿‡ CACHE_TTL æ—¶é—´çš„è®°å½•ï¼Œé¿å…é•¿æœŸå½±å“
        """
        current_time = time.time()
        expired_models = []
        
        for model_id, timestamp in self.exhausted_timestamps.items():
            if current_time - timestamp > self.CACHE_TTL:
                expired_models.append(model_id)
        
        for model_id in expired_models:
            self.exhausted_models_cache.discard(model_id)
            del self.exhausted_timestamps[model_id]
        
        if expired_models:
            api_logger.info(
                f"[DoubaoPriority] æ¸…ç†è¿‡æœŸç¼“å­˜ï¼š{len(expired_models)} ä¸ªæ¨¡å‹ "
                f"({', '.join(expired_models)})"
            )
    
    def _mark_model_exhausted(self, model_id: str):
        """
        æ ‡è®°æ¨¡å‹ä¸ºé…é¢è€—å°½
        
        Args:
            model_id: æ¨¡å‹ ID
        """
        self.exhausted_models_cache.add(model_id)
        self.exhausted_timestamps[model_id] = time.time()
        self.exhausted_models.add(model_id)  # åŒæ—¶æ›´æ–°å®ä¾‹ç¼“å­˜ï¼ˆå‘åå…¼å®¹ï¼‰
        api_logger.warning(
            f"[DoubaoPriority] ğŸ”’ æ¨¡å‹ {model_id} é…é¢è€—å°½ (429)ï¼Œå·²åŠ å…¥ç¼“å­˜ "
            f"(TTL={self.CACHE_TTL}s)"
        )
    
    def _is_model_exhausted(self, model_id: str) -> bool:
        """
        æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²é…é¢è€—å°½
        
        Args:
            model_id: æ¨¡å‹ ID
            
        Returns:
            bool: æ˜¯å¦å·²é…é¢è€—å°½
        """
        # å…ˆæ£€æŸ¥æ˜¯å¦åœ¨ç¼“å­˜ä¸­
        if model_id not in self.exhausted_models_cache:
            return False
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸï¼ˆåŒé‡æ£€æŸ¥ï¼Œé˜²æ­¢æ¸…ç†é—æ¼ï¼‰
        if model_id in self.exhausted_timestamps:
            if time.time() - self.exhausted_timestamps[model_id] > self.CACHE_TTL:
                # å·²è¿‡æœŸï¼Œä»ç¼“å­˜ä¸­ç§»é™¤
                self.exhausted_models_cache.discard(model_id)
                del self.exhausted_timestamps[model_id]
                api_logger.info(f"[DoubaoPriority] æ¨¡å‹ {model_id} ç¼“å­˜å·²è¿‡æœŸï¼Œæ¢å¤å¯ç”¨")
                return False
        
        return True
    
    def _get_priority_models(self) -> List[str]:
        """
        è·å–ä¼˜å…ˆçº§æ¨¡å‹åˆ—è¡¨
        
        Returns:
            æŒ‰ä¼˜å…ˆçº§æ’åºçš„æ¨¡å‹åˆ—è¡¨
        """
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨è‡ªåŠ¨é€‰æ‹©
        if not Config.is_doubao_auto_select():
            # å¦‚æœä¸å¯ç”¨è‡ªåŠ¨é€‰æ‹©ï¼Œåªä½¿ç”¨ç¬¬ä¸€ä¸ªä¼˜å…ˆçº§æ¨¡å‹
            model_id = os.getenv('DOUBAO_MODEL_PRIORITY_1', '')
            if model_id:
                return [model_id]
            return []
        
        # æ”¶é›†æ‰€æœ‰ä¼˜å…ˆçº§æ¨¡å‹é…ç½®
        priority_models = []
        
        # æŒ‰ä¼˜å…ˆçº§é¡ºåºæ·»åŠ æ¨¡å‹ï¼ˆä¼˜å…ˆçº§ 1-10ï¼‰
        for i in range(1, 11):
            model_key = f'DOUBAO_MODEL_PRIORITY_{i}'
            model_id = os.getenv(model_key, '')
            if model_id and model_id.strip():
                priority_models.append(model_id.strip())
        
        return priority_models
    
    def _init_adapter(self) -> bool:
        """
        åˆå§‹åŒ–é€‚é…å™¨ï¼ˆé€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ¨¡å‹ï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆå§‹åŒ–
        """
        api_logger.info(f"[DoubaoPriority] å°è¯•åˆå§‹åŒ–é€‚é…å™¨ï¼Œä¼˜å…ˆçº§æ¨¡å‹åˆ—è¡¨ï¼š{self.priority_models}")

        for i, model_id in enumerate(self.priority_models):
            # P1-1 ä¿®å¤ï¼šè·³è¿‡å·²é…é¢ç”¨å°½çš„æ¨¡å‹ï¼ˆä½¿ç”¨ç±»çº§åˆ«ç¼“å­˜ï¼‰
            if self._is_model_exhausted(model_id):
                api_logger.info(f"[DoubaoPriority] ğŸ”’ è·³è¿‡é…é¢ç”¨å°½æ¨¡å‹ï¼š{model_id} (ç¼“å­˜ä¸­)")
                continue

            try:
                api_logger.info(f"[DoubaoPriority] å°è¯•æ¨¡å‹ {i+1}/{len(self.priority_models)}: {model_id}")

                # åˆ›å»ºé€‚é…å™¨å®ä¾‹
                adapter = DoubaoAdapter(
                    api_key=self.api_key,
                    model_name=model_id,
                    base_url=self.base_url
                )

                # æ‰§è¡Œå¥åº·æ£€æŸ¥
                if hasattr(adapter, '_health_check'):
                    adapter._health_check()

                # æˆåŠŸï¼Œä¿å­˜é€‚é…å™¨å’Œæ¨¡å‹
                self.selected_adapter = adapter
                self.selected_model = model_id

                api_logger.info(f"[DoubaoPriority] âœ… æ¨¡å‹ {model_id} å¯ç”¨ï¼Œå·²é€‰ä¸­")
                return True

            except Exception as e:
                error_str = str(e)
                # P0-DOUBAO-2 ä¿®å¤ï¼šæ£€æµ‹ 429 é…é¢ç”¨å°½é”™è¯¯ï¼ŒåŠ å…¥ç¼“å­˜
                is_quota_exceeded = (
                    '429' in error_str or
                    'SetLimitExceeded' in error_str or
                    'Too Many Requests' in error_str or
                    'inference limit' in error_str
                )

                if is_quota_exceeded:
                    self._mark_model_exhausted(model_id)
                else:
                    api_logger.warning(f"[DoubaoPriority] âŒ æ¨¡å‹ {model_id} ä¸å¯ç”¨ï¼š{str(e)}")
                # ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
                continue

        # æ‰€æœ‰æ¨¡å‹éƒ½ä¸å¯ç”¨
        api_logger.error(f"[DoubaoPriority] âŒ æ‰€æœ‰ {len(self.priority_models)} ä¸ªæ¨¡å‹éƒ½ä¸å¯ç”¨")
        return False
    
    def _retry_with_next_model(self, failed_model: str) -> bool:
        """
        å½“å½“å‰æ¨¡å‹å¤±è´¥æ—¶ï¼Œå°è¯•ä¸‹ä¸€ä¸ªä¼˜å…ˆçº§çš„æ¨¡å‹

        Args:
            failed_model: å¤±è´¥çš„æ¨¡å‹ ID

        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ‡æ¢åˆ°æ–°æ¨¡å‹
        """
        if failed_model not in self.priority_models:
            return False

        # è·å–å¤±è´¥æ¨¡å‹çš„ç´¢å¼•
        failed_index = self.priority_models.index(failed_model)

        # å°è¯•ä¸‹ä¸€ä¸ªä¼˜å…ˆçº§çš„æ¨¡å‹
        for i in range(failed_index + 1, len(self.priority_models)):
            next_model = self.priority_models[i]

            # P0-DOUBAO-2 ä¿®å¤ï¼šè·³è¿‡å·²é…é¢ç”¨å°½çš„æ¨¡å‹ï¼ˆä½¿ç”¨ç±»çº§åˆ«ç¼“å­˜ï¼‰
            if self._is_model_exhausted(next_model):
                api_logger.info(f"[DoubaoPriority] ğŸ”’ è·³è¿‡é…é¢ç”¨å°½æ¨¡å‹ï¼š{next_model} (ç¼“å­˜ä¸­)")
                continue

            try:
                api_logger.info(f"[DoubaoPriority] åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªä¼˜å…ˆçº§æ¨¡å‹ï¼š{next_model}")

                # åˆ›å»ºæ–°é€‚é…å™¨
                adapter = DoubaoAdapter(
                    api_key=self.api_key,
                    model_name=next_model,
                    base_url=self.base_url
                )

                # æ‰§è¡Œå¥åº·æ£€æŸ¥
                if hasattr(adapter, '_health_check'):
                    adapter._health_check()

                # æˆåŠŸï¼Œæ›´æ–°é€‚é…å™¨å’Œæ¨¡å‹
                self.selected_adapter = adapter
                self.selected_model = next_model

                # æ›´æ–°çˆ¶ç±»å±æ€§
                self.model_name = next_model
                self.session = adapter.session
                self.circuit_breaker = adapter.circuit_breaker

                api_logger.info(f"[DoubaoPriority] âœ… æˆåŠŸåˆ‡æ¢åˆ°æ¨¡å‹ {next_model}")
                return True

            except Exception as e:
                error_str = str(e)
                # æ£€æµ‹ 429 é…é¢ç”¨å°½é”™è¯¯ï¼ŒåŠ å…¥ç¼“å­˜
                is_quota_exceeded = (
                    '429' in error_str or
                    'SetLimitExceeded' in error_str or
                    'Too Many Requests' in error_str or
                    'inference limit' in error_str
                )

                if is_quota_exceeded:
                    self._mark_model_exhausted(next_model)
                else:
                    api_logger.warning(f"[DoubaoPriority] âŒ åˆ‡æ¢æ¨¡å‹ {next_model} å¤±è´¥ï¼š{str(e)}")
                continue

        return False
    
    @classmethod
    def clear_exhausted_cache(cls):
        """
        æ¸…ç©ºé…é¢è€—å°½ç¼“å­˜ï¼ˆç”¨äºæµ‹è¯•æˆ–æ‰‹åŠ¨å¹²é¢„ï¼‰
        
        æ³¨æ„ï¼šç”Ÿäº§ç¯å¢ƒæ…ç”¨ï¼Œå¯èƒ½å¯¼è‡´å†æ¬¡è§¦å‘ 429 é”™è¯¯
        """
        cls.exhausted_models_cache.clear()
        cls.exhausted_timestamps.clear()
        api_logger.info("[DoubaoPriority] ğŸ—‘ï¸ å·²æ¸…ç©ºé…é¢è€—å°½ç¼“å­˜")
    
    @classmethod
    def get_exhausted_cache_info(cls) -> Dict[str, Any]:
        """
        è·å–ç¼“å­˜ä¿¡æ¯ï¼ˆç”¨äºç›‘æ§å’Œè°ƒè¯•ï¼‰
        
        Returns:
            åŒ…å«ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        current_time = time.time()
        expired_count = sum(
            1 for ts in cls.exhausted_timestamps.values()
            if current_time - ts > cls.CACHE_TTL
        )
        
        return {
            'total_cached': len(cls.exhausted_models_cache),
            'expired_count': expired_count,
            'active_count': len(cls.exhausted_models_cache) - expired_count,
            'cache_ttl_seconds': cls.CACHE_TTL,
            'cached_models': list(cls.exhausted_models_cache),
            'timestamps': dict(cls.exhausted_timestamps)
        }
    
    def send_prompt(self, prompt: str, **kwargs) -> AIResponse:
        """
        å‘é€æç¤ºè¯ï¼Œæ”¯æŒè‡ªåŠ¨æ•…éšœè½¬ç§»

        Args:
            prompt: æç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            AIResponse: AI å“åº”
        """
        if not self.selected_adapter:
            return AIResponse(
                success=False,
                error_message="æœªæ‰¾åˆ°å¯ç”¨çš„è±†åŒ…æ¨¡å‹",
                error_type=AIErrorType.SERVICE_UNAVAILABLE
            )

        try:
            # ä½¿ç”¨å½“å‰é€‚é…å™¨å‘é€è¯·æ±‚
            response = self.selected_adapter.send_prompt(prompt, **kwargs)

            # å¦‚æœæˆåŠŸï¼Œè¿”å›å“åº”
            if response.success:
                return response

            # å¦‚æœå¤±è´¥ä¸”é”™è¯¯ç±»å‹æ˜¯å¯æ¢å¤é”™è¯¯ï¼ˆæœåŠ¡ä¸å¯ç”¨ã€æœåŠ¡å™¨é”™è¯¯ã€é¢‘ç‡é™åˆ¶ã€é…é¢ç”¨å°½ï¼‰ï¼Œå°è¯•åˆ‡æ¢æ¨¡å‹
            # P0-2 ä¿®å¤ï¼šæ·»åŠ  INSUFFICIENT_QUOTA åˆ°æ•…éšœè½¬ç§»è§¦å‘åˆ—è¡¨
            if response.error_type in [
                AIErrorType.SERVICE_UNAVAILABLE,
                AIErrorType.SERVER_ERROR,
                AIErrorType.RATE_LIMIT_EXCEEDED,
                AIErrorType.INSUFFICIENT_QUOTA  # æ–°å¢ï¼šé…é¢ç”¨å°½æ—¶åˆ‡æ¢
            ]:
                api_logger.warning(f"[DoubaoPriority] æ¨¡å‹ {self.selected_model} è°ƒç”¨å¤±è´¥ ({response.error_type})ï¼Œå°è¯•åˆ‡æ¢æ¨¡å‹")

                # è®°å½•é…é¢ç”¨å°½çš„æ¨¡å‹ï¼ˆä½¿ç”¨ç±»çº§åˆ«ç¼“å­˜ï¼‰
                if response.error_type == AIErrorType.INSUFFICIENT_QUOTA:
                    self._mark_model_exhausted(self.selected_model)

                if self._retry_with_next_model(self.selected_model):
                    # åˆ‡æ¢æˆåŠŸï¼Œä½¿ç”¨æ–°æ¨¡å‹é‡è¯•
                    api_logger.info(f"[DoubaoPriority] ä½¿ç”¨æ–°æ¨¡å‹ {self.selected_model} é‡è¯•")
                    return self.selected_adapter.send_prompt(prompt, **kwargs)
                else:
                    api_logger.error(f"[DoubaoPriority] æ‰€æœ‰æ¨¡å‹éƒ½å·²å°è¯•ï¼Œæ— æ³•åˆ‡æ¢")

            # è¿”å›å¤±è´¥å“åº”
            return response

        except Exception as e:
            api_logger.error(f"[DoubaoPriority] å‘é€è¯·æ±‚å¼‚å¸¸ï¼š{str(e)}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯ 429 é”™è¯¯ï¼ˆé…é¢ç”¨å°½ï¼‰
            error_str = str(e)
            is_quota_exceeded = (
                '429' in error_str or
                'SetLimitExceeded' in error_str or
                'Too Many Requests' in error_str or
                'inference limit' in error_str
            )

            # P0-DOUBAO-2 ä¿®å¤ï¼šé…é¢ç”¨å°½æ—¶è®°å½•åˆ°ç¼“å­˜
            if is_quota_exceeded and self.selected_model:
                self._mark_model_exhausted(self.selected_model)

            # å°è¯•åˆ‡æ¢æ¨¡å‹ï¼ˆå¦‚æœæ˜¯ 429 é”™è¯¯æˆ–å½“å‰æ¨¡å‹å¤±è´¥ï¼‰
            if is_quota_exceeded:
                api_logger.warning(f"[DoubaoPriority] æ£€æµ‹åˆ°é…é¢ç”¨å°½ï¼ˆ429ï¼‰ï¼Œå°è¯•åˆ‡æ¢æ¨¡å‹")
                if self._retry_with_next_model(self.selected_model):
                    # åˆ‡æ¢æˆåŠŸï¼Œä½¿ç”¨æ–°æ¨¡å‹é‡è¯•
                    api_logger.info(f"[DoubaoPriority] ä½¿ç”¨æ–°æ¨¡å‹ {self.selected_model} é‡è¯•")
                    return self.selected_adapter.send_prompt(prompt, **kwargs)
                else:
                    api_logger.error(f"[DoubaoPriority] æ‰€æœ‰æ¨¡å‹éƒ½å·²å°è¯•ï¼Œæ— æ³•åˆ‡æ¢")

            # è¿”å›é”™è¯¯å“åº”
            return AIResponse(
                success=False,
                error_message=str(e),
                error_type=AIErrorType.RATE_LIMIT_EXCEEDED if is_quota_exceeded else AIErrorType.UNKNOWN_ERROR,
                model=self.selected_model,
                platform='doubao'
            )

    def generate_response(self, prompt: str, **kwargs) -> AIResponse:
        """
        ç”Ÿæˆå“åº”ï¼ˆå…¼å®¹ NXM æ‰§è¡Œå¼•æ“çš„è°ƒç”¨æ¥å£ï¼‰
        
        Args:
            prompt: æç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            AIResponse: AI å“åº”
        """
        # ç›´æ¥è°ƒç”¨ send_prompt æ–¹æ³•
        return self.send_prompt(prompt, **kwargs)

    def get_selected_model(self) -> Optional[str]:
        """
        è·å–å½“å‰é€‰ä¸­çš„æ¨¡å‹ ID
        
        Returns:
            æ¨¡å‹ ID
        """
        return self.selected_model
    
    def get_priority_models(self) -> List[str]:
        """
        è·å–ä¼˜å…ˆçº§æ¨¡å‹åˆ—è¡¨
        
        Returns:
            æ¨¡å‹åˆ—è¡¨
        """
        return self.priority_models
