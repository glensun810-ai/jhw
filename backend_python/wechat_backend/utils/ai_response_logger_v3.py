#!/usr/bin/env python3
"""
AI å“åº”æ—¥å¿—è®°å½•æ¨¡å— V3 - æ—¥å¿—è½®è½¬å¢å¼ºç‰ˆ
ç”¨äºä¿å­˜ AI æœç´¢å¹³å°çš„å®Œæ•´åé¦ˆç»“æœï¼Œæ”¯æŒæ—¥å¿—è½®è½¬ã€å¤‡ä»½å’Œè‡ªåŠ¨æ¸…ç†

å¢å¼ºç‰¹æ€§ï¼š
- è¿½åŠ æ¨¡å¼å†™å…¥ï¼ˆä¸è¦†ç›–å·²æœ‰å†…å®¹ï¼‰âœ…
- è‡ªåŠ¨æ—¥å¿—è½®è½¬ï¼ˆå½“æ–‡ä»¶è¾¾åˆ°æŒ‡å®šå¤§å°ï¼‰
- è‡ªåŠ¨å¤‡ä»½ï¼ˆgzip å‹ç¼©ï¼‰
- è‡ªåŠ¨æ¸…ç†ï¼ˆä¿ç•™æœ€è¿‘ N ä¸ªæ–‡ä»¶ï¼‰
- çº¿ç¨‹å®‰å…¨
"""

import json
import os
import gzip
import shutil
import platform
import socket
import sys
import time
import traceback
import threading
from datetime import datetime
from typing import Dict, Any, Optional, List
from pathlib import Path
import uuid

# é»˜è®¤æ—¥å¿—æ–‡ä»¶è·¯å¾„
DEFAULT_LOG_DIR = Path(__file__).parent.parent / "data" / "ai_responses"
DEFAULT_LOG_FILE = DEFAULT_LOG_DIR / "ai_responses.jsonl"

# æ—¥å¿—è½®è½¬é…ç½®
LOG_ROTATION_CONFIG = {
    'max_file_size_mb': 10,      # å•ä¸ªæ–‡ä»¶æœ€å¤§ 10MB
    'max_backup_count': 10,      # æœ€å¤šä¿ç•™ 10 ä¸ªå¤‡ä»½æ–‡ä»¶
    'backup_compression': True,  # å¯ç”¨ gzip å‹ç¼©
}

# ã€ä»»åŠ¡ 1ã€‘å…¨å±€æ–‡ä»¶é”ï¼Œç”¨äºä¿æŠ¤ JSONL æ–‡ä»¶å†™å…¥
_file_lock = threading.Lock()
# è½®è½¬é”ï¼ˆç‹¬ç«‹äºå†™å…¥é”ï¼Œé¿å…æ­»é”ï¼‰
_rotation_lock = threading.Lock()


class AIResponseLogger:
    """
    AI å“åº”è®°å½•å™¨ - V3 æ—¥å¿—è½®è½¬å¢å¼ºç‰ˆ
    è®°å½•æ¯æ¬¡ AI è°ƒç”¨çš„å®Œæ•´ä¿¡æ¯ï¼Œæ”¯æŒæ—¥å¿—è½®è½¬ã€å¤‡ä»½å’Œè‡ªåŠ¨æ¸…ç†
    """

    def __init__(
        self, 
        log_file: Optional[str] = None,
        max_file_size_mb: int = None,
        max_backup_count: int = None,
        enable_compression: bool = None
    ):
        """
        åˆå§‹åŒ–è®°å½•å™¨

        Args:
            log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º data/ai_responses/ai_responses.jsonl
            max_file_size_mb: å•ä¸ªæ–‡ä»¶æœ€å¤§å¤§å° (MB)ï¼Œé»˜è®¤ 10MB
            max_backup_count: æœ€å¤šä¿ç•™å¤‡ä»½æ–‡ä»¶æ•°ï¼Œé»˜è®¤ 10 ä¸ª
            enable_compression: æ˜¯å¦å¯ç”¨ gzip å‹ç¼©å¤‡ä»½ï¼Œé»˜è®¤ True
        """
        if log_file:
            self.log_file = Path(log_file)
        else:
            self.log_file = DEFAULT_LOG_FILE

        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        self.log_file.parent.mkdir(parents=True, exist_ok=True)

        # åŠ è½½è½®è½¬é…ç½®
        self.max_file_size = (max_file_size_mb or LOG_ROTATION_CONFIG['max_file_size_mb']) * 1024 * 1024
        self.max_backup_count = max_backup_count or LOG_ROTATION_CONFIG['max_backup_count']
        self.enable_compression = enable_compression if enable_compression is not None else LOG_ROTATION_CONFIG['backup_compression']

        # ç³»ç»Ÿä¿¡æ¯ï¼ˆåªè·å–ä¸€æ¬¡ï¼‰
        self.system_info = self._get_system_info()
        
        # æ£€æŸ¥å¹¶æ‰§è¡Œæ—¥å¿—è½®è½¬
        self._check_and_rotate()
        
        print(f"[AIResponseLogger V3] åˆå§‹åŒ–å®Œæˆï¼Œæ—¥å¿—æ–‡ä»¶ï¼š{self.log_file}")
        print(f"  - æœ€å¤§æ–‡ä»¶å¤§å°ï¼š{self.max_file_size / 1024 / 1024:.1f}MB")
        print(f"  - æœ€å¤§å¤‡ä»½æ•°é‡ï¼š{self.max_backup_count}")
        print(f"  - å‹ç¼©å¤‡ä»½ï¼š{'æ˜¯' if self.enable_compression else 'å¦'}")

    def _get_system_info(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        return {
            "hostname": socket.gethostname(),
            "platform": platform.system(),
            "platform_version": platform.version(),
            "python_version": platform.python_version(),
            "machine": platform.machine(),
            "processor": platform.processor()
        }

    def _check_and_rotate(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦æ—¥å¿—è½®è½¬"""
        if not self.log_file.exists():
            return
        
        try:
            file_size = self.log_file.stat().st_size
            if file_size >= self.max_file_size:
                self._rotate_log()
        except Exception as e:
            print(f"[AIResponseLogger] æ£€æŸ¥æ—¥å¿—è½®è½¬å¤±è´¥ï¼š{e}")

    def _rotate_log(self):
        """æ‰§è¡Œæ—¥å¿—è½®è½¬"""
        with _rotation_lock:  # ç¡®ä¿åŒä¸€æ—¶é—´åªæœ‰ä¸€ä¸ªçº¿ç¨‹åœ¨æ‰§è¡Œè½®è½¬
            try:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                backup_name = f"ai_responses_{timestamp}.jsonl"
                backup_path = self.log_file.parent / backup_name
                
                # ç§»åŠ¨å½“å‰æ—¥å¿—æ–‡ä»¶åˆ°å¤‡ä»½
                shutil.move(str(self.log_file), str(backup_path))
                print(f"[AIResponseLogger] æ—¥å¿—è½®è½¬ï¼š{self.log_file.name} â†’ {backup_name}")
                
                # å‹ç¼©å¤‡ä»½ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if self.enable_compression:
                    compressed_path = self._compress_backup(backup_path)
                    if compressed_path:
                        backup_path = compressed_path
                
                # æ¸…ç†æ—§å¤‡ä»½
                self._cleanup_old_backups()
                
                print(f"[AIResponseLogger] æ—¥å¿—è½®è½¬å®Œæˆ")
                
            except Exception as e:
                print(f"[AIResponseLogger] æ—¥å¿—è½®è½¬å¤±è´¥ï¼š{e}")

    def _compress_backup(self, backup_path: Path) -> Optional[Path]:
        """å‹ç¼©å¤‡ä»½æ–‡ä»¶"""
        try:
            compressed_path = backup_path.with_suffix('.jsonl.gz')
            with open(backup_path, 'rb') as f_in:
                with gzip.open(compressed_path, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
            
            # åˆ é™¤æœªå‹ç¼©æ–‡ä»¶
            backup_path.unlink()
            
            # è®¡ç®—å‹ç¼©ç‡
            original_size = backup_path.stat().st_size if backup_path.exists() else 0
            compressed_size = compressed_path.stat().st_size
            compression_ratio = (1 - compressed_size / original_size) * 100 if original_size > 0 else 0
            
            print(f"[AIResponseLogger] å‹ç¼©å¤‡ä»½ï¼š{compressed_path.name} (å‹ç¼©ç‡ï¼š{compression_ratio:.1f}%)")
            return compressed_path
            
        except Exception as e:
            print(f"[AIResponseLogger] å‹ç¼©å¤‡ä»½å¤±è´¥ï¼š{e}")
            return None

    def _cleanup_old_backups(self):
        """æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶"""
        try:
            # è·å–æ‰€æœ‰å¤‡ä»½æ–‡ä»¶ï¼ˆåŒ…æ‹¬å‹ç¼©å’Œæœªå‹ç¼©çš„ï¼‰
            backup_files = []
            for pattern in ['ai_responses_*.jsonl', 'ai_responses_*.jsonl.gz']:
                backup_files.extend(self.log_file.parent.glob(pattern))
            
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            backup_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)
            
            # åˆ é™¤è¶…å‡ºæ•°é‡çš„æ—§æ–‡ä»¶
            if len(backup_files) > self.max_backup_count:
                files_to_delete = backup_files[self.max_backup_count:]
                for file_path in files_to_delete:
                    file_path.unlink()
                    print(f"[AIResponseLogger] æ¸…ç†æ—§å¤‡ä»½ï¼š{file_path.name}")
            
            # ç»Ÿè®¡å½“å‰å¤‡ä»½æƒ…å†µ
            current_count = len(backup_files[:self.max_backup_count])
            total_size = sum(f.stat().st_size for f in backup_files[:self.max_backup_count])
            print(f"[AIResponseLogger] å½“å‰å¤‡ä»½ï¼š{current_count}/{self.max_backup_count} æ–‡ä»¶ï¼Œæ€»è®¡ {total_size / 1024 / 1024:.2f}MB")
            
        except Exception as e:
            print(f"[AIResponseLogger] æ¸…ç†æ—§å¤‡ä»½å¤±è´¥ï¼š{e}")

    def _calculate_text_stats(self, text: str) -> Dict[str, Any]:
        """è®¡ç®—æ–‡æœ¬ç»Ÿè®¡ä¿¡æ¯"""
        if not text:
            return {"length": 0, "lines": 0, "words": 0, "chars_no_spaces": 0}

        # ä¸­æ–‡å­—ç¬¦ç»Ÿè®¡
        chinese_chars = len([c for c in text if '\u4e00' <= c <= '\u9fff'])
        # è‹±æ–‡å•è¯ç»Ÿè®¡ï¼ˆç®€å•åˆ†è¯ï¼‰
        english_words = len([w for w in text.split() if w.isalpha()])

        return {
            "length": len(text),
            "lines": text.count('\n') + 1,
            "words": len(text.split()),
            "chars_no_spaces": len(text.replace(' ', '').replace('\n', '')),
            "chinese_chars": chinese_chars,
            "english_words": english_words,
            "has_code_blocks": '```' in text,
            "has_markdown": any(md in text for md in ['**', '*', '#', '[', ']'])
        }

    def log_response(
        self,
        # æ ¸å¿ƒå­—æ®µ
        question: str,
        response: str,
        platform_name: str,
        model: str,

        # ä¸šåŠ¡å­—æ®µ
        brand: Optional[str] = None,
        competitor: Optional[str] = None,
        industry: Optional[str] = None,
        question_category: Optional[str] = None,

        # æ€§èƒ½å­—æ®µ
        latency_ms: Optional[int] = None,
        tokens_used: Optional[int] = None,
        prompt_tokens: Optional[int] = None,
        completion_tokens: Optional[int] = None,

        # è´¨é‡å­—æ®µ
        success: bool = True,
        error_message: Optional[str] = None,
        error_type: Optional[str] = None,
        response_quality_score: Optional[float] = None,

        # ç½‘ç»œ/ç³»ç»Ÿå­—æ®µ
        http_status_code: Optional[int] = None,
        retry_count: Optional[int] = None,
        circuit_breaker_open: Optional[bool] = None,

        # è¯·æ±‚é…ç½®å­—æ®µ
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        timeout_seconds: Optional[int] = None,

        # ä¸Šä¸‹æ–‡å­—æ®µ
        execution_id: Optional[str] = None,
        question_index: Optional[int] = None,
        total_questions: Optional[int] = None,
        session_id: Optional[str] = None,
        user_id: Optional[str] = None,

        # åŸå§‹æ•°æ®ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        raw_request: Optional[Dict] = None,
        raw_response: Optional[Dict] = None,

        # æ‰©å±•å­—æ®µ
        metadata: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        è®°å½•ä¸€æ¬¡ AI å“åº” - V3 å®Œæ•´ç‰ˆ
        æ‰€æœ‰å‚æ•°éƒ½æ˜¯å¯é€‰çš„ï¼Œä½†å»ºè®®å°½å¯èƒ½å¡«å†™ä»¥è·å¾—æœ€å®Œæ•´çš„æ•°æ®
        """
        # ç”Ÿæˆå”¯ä¸€è®°å½• ID
        record_id = str(uuid.uuid4())

        # æ„å»ºå®Œæ•´è®°å½•
        record = {
            # åŸºç¡€æ ‡è¯†
            "record_id": record_id,
            "timestamp": datetime.now().isoformat(),
            "unix_timestamp": time.time(),
            "version": "3.0",  # V3 ç‰ˆæœ¬æ ‡è¯†

            # æ ¸å¿ƒå†…å®¹
            "question": {
                "text": question,
                "stats": self._calculate_text_stats(question)
            },
            "response": {
                "text": response,
                "stats": self._calculate_text_stats(response)
            },

            # å¹³å°ä¿¡æ¯
            "platform": {
                "name": platform_name,
                "model": model,
                "api_version": metadata.get("api_version") if metadata else None
            },

            # ä¸šåŠ¡ä¿¡æ¯
            "business": {
                "brand": brand,
                "competitor": competitor,
                "industry": industry,
                "question_category": question_category
            },

            # æ€§èƒ½æŒ‡æ ‡
            "performance": {
                "latency_ms": latency_ms,
                "tokens": {
                    "total": tokens_used,
                    "prompt": prompt_tokens,
                    "completion": completion_tokens
                },
                "throughput": round(tokens_used * 1000 / latency_ms, 2) if tokens_used and latency_ms else None
            },

            # æ‰§è¡ŒçŠ¶æ€
            "status": {
                "success": success,
                "error_message": error_message,
                "error_type": error_type,
                "http_status_code": http_status_code
            },

            # å¯é æ€§æŒ‡æ ‡
            "reliability": {
                "retry_count": retry_count or 0,
                "circuit_breaker_open": circuit_breaker_open or False
            },

            # è¯·æ±‚é…ç½®
            "request_config": {
                "temperature": temperature,
                "max_tokens": max_tokens,
                "timeout_seconds": timeout_seconds
            },

            # ä¸Šä¸‹æ–‡ä¿¡æ¯
            "context": {
                "execution_id": execution_id,
                "session_id": session_id,
                "user_id": user_id,
                "question_index": question_index,
                "total_questions": total_questions
            },

            # ç³»ç»Ÿä¿¡æ¯
            "system": self.system_info,

            # è´¨é‡è¯„ä¼°
            "quality": {
                "score": response_quality_score,
                "has_structured_data": self._has_structured_data(response),
                "completeness": self._assess_completeness(response)
            },

            # åŸå§‹æ•°æ®ï¼ˆè°ƒè¯•ç”¨ï¼Œå¯é€‰ï¼‰
            "raw": {
                "request": raw_request,
                "response": raw_response
            } if raw_request or raw_response else None,

            # æ‰©å±•å…ƒæ•°æ®
            "metadata": metadata or {}
        }

        # æ¸…ç† None å€¼
        record = self._clean_none_values(record)

        # æ£€æŸ¥å¹¶æ‰§è¡Œæ—¥å¿—è½®è½¬ï¼ˆå†™å…¥å‰æ£€æŸ¥ï¼‰
        self._check_and_rotate()

        # çº¿ç¨‹å®‰å…¨çš„æ–‡ä»¶å†™å…¥ - ä½¿ç”¨è¿½åŠ æ¨¡å¼ï¼ˆä¸è¦†ç›–å·²æœ‰å†…å®¹ï¼‰
        try:
            with _file_lock:  # çº¿ç¨‹å®‰å…¨é”
                with open(self.log_file, 'a', encoding='utf-8') as f:
                    f.write(json.dumps(record, ensure_ascii=False) + '\n')
                    f.flush()  # ç¡®ä¿ç«‹å³å†™å…¥ç£ç›˜
                    os.fsync(f.fileno())  # å¼ºåˆ¶åŒæ­¥åˆ°ç£ç›˜
        except Exception as e:
            # è®°å½•å¤±è´¥ä¸åº”å½±å“ä¸»æµç¨‹
            print(f"[AIResponseLogger] è­¦å‘Šï¼šå†™å…¥æ—¥å¿—å¤±è´¥ï¼š{e}")

        return record

    def _has_structured_data(self, text: str) -> bool:
        """æ£€æµ‹å“åº”æ˜¯å¦åŒ…å«ç»“æ„åŒ–æ•°æ®"""
        if not text:
            return False
        indicators = ['###', '##', '1.', '2.', '- ', '* ', '|', '```', 'ã€']
        return any(ind in text for ind in indicators)

    def _assess_completeness(self, text: str) -> Optional[float]:
        """è¯„ä¼°å“åº”å®Œæ•´æ€§ï¼ˆç®€å•å¯å‘å¼ï¼‰"""
        if not text:
            return 0.0

        score = 1.0

        # æ£€æŸ¥æ˜¯å¦ä»¥æ ‡ç‚¹ç¬¦å·ç»“å°¾
        if text and text[-1] not in 'ã€‚ï¼ï¼Ÿ.!?':
            score -= 0.1

        # æ£€æŸ¥é•¿åº¦
        if len(text) < 50:
            score -= 0.3
        elif len(text) < 100:
            score -= 0.1

        # æ£€æŸ¥æ˜¯å¦æœ‰ç»“è®ºæ€§å†…å®¹
        conclusion_words = ['æ€»ç»“', 'ç»“è®º', 'å»ºè®®', 'å› æ­¤', 'ç»¼ä¸Šæ‰€è¿°', 'æ€»ä¹‹', 'in conclusion']
        if not any(w in text.lower() for w in conclusion_words):
            score -= 0.1

        return max(0.0, round(score, 2))

    def _clean_none_values(self, obj):
        """é€’å½’æ¸…ç†å­—å…¸ä¸­çš„ None å€¼å’Œä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡"""
        if isinstance(obj, dict):
            return {k: self._clean_none_values(v) for k, v in obj.items() if v is not None}
        elif isinstance(obj, list):
            return [self._clean_none_values(item) for item in item in obj if item is not None]
        elif hasattr(obj, 'value'):
            return obj.value
        elif hasattr(obj, 'isoformat'):
            return obj.isoformat()
        return obj

    def get_stats(self) -> Dict[str, Any]:
        """è·å–æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯"""
        try:
            if not self.log_file.exists():
                return {"error": "æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨"}

            # ç»Ÿè®¡å½“å‰æ–‡ä»¶
            current_size = self.log_file.stat().st_size
            with open(self.log_file, 'r', encoding='utf-8') as f:
                line_count = sum(1 for _ in f)

            # ç»Ÿè®¡å¤‡ä»½æ–‡ä»¶
            backup_files = []
            for pattern in ['ai_responses_*.jsonl', 'ai_responses_*.jsonl.gz']:
                backup_files.extend(self.log_file.parent.glob(pattern))
            
            total_backup_size = sum(f.stat().st_size for f in backup_files)
            total_backup_count = len(backup_files)

            return {
                "current_file": str(self.log_file),
                "current_size_mb": round(current_size / 1024 / 1024, 2),
                "current_records": line_count,
                "backup_count": total_backup_count,
                "backup_size_mb": round(total_backup_size / 1024 / 1024, 2),
                "total_size_mb": round((current_size + total_backup_size) / 1024 / 1024, 2),
                "max_file_size_mb": round(self.max_file_size / 1024 / 1024, 2),
                "max_backup_count": self.max_backup_count
            }

        except Exception as e:
            return {"error": f"ç»Ÿè®¡å¤±è´¥ï¼š{e}"}


# å…¨å±€ logger å®ä¾‹
_default_logger: Optional[AIResponseLogger] = None


def get_logger(log_file: Optional[str] = None) -> AIResponseLogger:
    """è·å–å…¨å±€ logger å®ä¾‹"""
    global _default_logger
    if _default_logger is None:
        _default_logger = AIResponseLogger(log_file)
    return _default_logger


def log_ai_response(**kwargs) -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•°ï¼šè®°å½• AI å“åº”"""
    logger = get_logger()
    return logger.log_response(**kwargs)


def get_log_stats() -> Dict[str, Any]:
    """è·å–æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯"""
    logger = get_logger()
    return logger.get_stats()


# æ¼”ç¤ºç”¨æ³•
if __name__ == "__main__":
    print("=" * 60)
    print("AI Response Logger V3 - æ—¥å¿—è½®è½¬å¢å¼ºç‰ˆæ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»º loggerï¼ˆä½¿ç”¨å°æ–‡ä»¶é™åˆ¶æ¥æ¼”ç¤ºè½®è½¬ï¼‰
    logger = AIResponseLogger(
        max_file_size_mb=1,  # 1MB è§¦å‘è½®è½¬ï¼ˆæ¼”ç¤ºç”¨ï¼‰
        max_backup_count=5
    )
    
    # è®°å½•ä¸€æ¡æµ‹è¯•æ—¥å¿—
    record = logger.log_response(
        question="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        response="äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯...",
        platform_name="deepseek",
        model="deepseek-chat",
        brand="æµ‹è¯•å“ç‰Œ",
        latency_ms=1500,
        success=True
    )
    
    print(f"\nâœ… è®°å½•æˆåŠŸï¼š{record['record_id'][:8]}...")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    stats = logger.get_stats()
    print(f"\nğŸ“Š æ—¥å¿—ç»Ÿè®¡:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
