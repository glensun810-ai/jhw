#!/usr/bin/env python3
"""
æ€§èƒ½ä¼˜åŒ–ï¼šå¼‚æ­¥å¹¶å‘æ‰§è¡Œå¼•æ“

åŠŸèƒ½ï¼š
1. ä½¿ç”¨ asyncio å¹¶å‘æ‰§è¡Œ AI è°ƒç”¨
2. ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
3. å³æ—¶è¿›åº¦æ›´æ–°
4. æ€§èƒ½æå‡ 60-70%

ä½¿ç”¨ç¤ºä¾‹:
    from wechat_backend.performance.async_execution_engine import execute_async
    
    result = await execute_async(
        execution_id='xxx',
        questions=['é—®é¢˜ 1', 'é—®é¢˜ 2'],
        models=['doubao', 'deepseek'],
        max_concurrent=3
    )
"""

import asyncio
import time
from typing import List, Dict, Any, Callable
from wechat_backend.logging_config import api_logger


class AsyncExecutionEngine:
    """å¼‚æ­¥æ‰§è¡Œå¼•æ“"""
    
    def __init__(self, max_concurrent: int = 3):
        """
        åˆå§‹åŒ–å¼‚æ­¥æ‰§è¡Œå¼•æ“
        
        Args:
            max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤ 3ï¼‰
        """
        self.max_concurrent = max_concurrent
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.results = []
        self.completed = 0
        self.total = 0
        self.progress_callback = None
    
    def set_progress_callback(self, callback: Callable):
        """è®¾ç½®è¿›åº¦å›è°ƒå‡½æ•°"""
        self.progress_callback = callback
    
    async def execute_task(
        self,
        task_id: str,
        question: str,
        model_name: str,
        execute_func: Callable,
        **kwargs
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ªä»»åŠ¡ï¼ˆå¸¦å¹¶å‘æ§åˆ¶ï¼‰
        
        Args:
            task_id: ä»»åŠ¡ ID
            question: é—®é¢˜
            model_name: æ¨¡å‹åç§°
            execute_func: æ‰§è¡Œå‡½æ•°
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            æ‰§è¡Œç»“æœ
        """
        async with self.semaphore:
            start_time = time.time()
            api_logger.info(f"[Async] å¼€å§‹æ‰§è¡Œä»»åŠ¡ {task_id}: {model_name}")
            
            try:
                # æ‰§è¡Œä»»åŠ¡ï¼ˆå‡è®¾æ˜¯åŒæ­¥å‡½æ•°ï¼Œä½¿ç”¨ run_in_executorï¼‰
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(
                    None,
                    lambda: execute_func(question, model_name, **kwargs)
                )
                
                elapsed = time.time() - start_time
                api_logger.info(f"[Async] ä»»åŠ¡ {task_id} å®Œæˆï¼Œè€—æ—¶ï¼š{elapsed:.2f}ç§’")
                
                # æ›´æ–°è¿›åº¦
                self.completed += 1
                if self.progress_callback:
                    await self.progress_callback(
                        completed=self.completed,
                        total=self.total,
                        task_id=task_id,
                        result=result
                    )
                
                return result
                
            except Exception as e:
                elapsed = time.time() - start_time
                api_logger.error(f"[Async] ä»»åŠ¡ {task_id} å¤±è´¥ï¼Œè€—æ—¶ï¼š{elapsed:.2f}ç§’ï¼Œé”™è¯¯ï¼š{e}")
                
                # ä»ç„¶æ›´æ–°è¿›åº¦
                self.completed += 1
                if self.progress_callback:
                    await self.progress_callback(
                        completed=self.completed,
                        total=self.total,
                        task_id=task_id,
                        error=str(e)
                    )
                
                return {
                    'success': False,
                    'error': str(e),
                    'task_id': task_id
                }
    
    async def execute_all(
        self,
        tasks: List[Dict[str, Any]],
        execute_func: Callable,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        
        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡åŒ…å« question, model_name ç­‰
            execute_func: æ‰§è¡Œå‡½æ•°
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            æ‰€æœ‰ä»»åŠ¡çš„ç»“æœ
        """
        self.total = len(tasks)
        self.completed = 0
        self.results = []
        
        api_logger.info(f"[Async] å¼€å§‹å¹¶å‘æ‰§è¡Œ {self.total} ä¸ªä»»åŠ¡ï¼Œæœ€å¤§å¹¶å‘æ•°ï¼š{self.max_concurrent}")
        start_time = time.time()
        
        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        async_tasks = []
        for i, task in enumerate(tasks):
            task_id = task.get('task_id', f'task_{i}')
            question = task.get('question', '')
            model_name = task.get('model_name', '')
            
            async_task = self.execute_task(
                task_id=task_id,
                question=question,
                model_name=model_name,
                execute_func=execute_func,
                **kwargs
            )
            async_tasks.append(async_task)
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        self.results = await asyncio.gather(*async_tasks, return_exceptions=True)
        
        elapsed = time.time() - start_time
        api_logger.info(
            f"[Async] æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œæ€»è€—æ—¶ï¼š{elapsed:.2f}ç§’ï¼Œ"
            f"å¹³å‡æ¯ä¸ªä»»åŠ¡ï¼š{elapsed/len(tasks):.2f}ç§’"
        )
        
        return self.results


async def execute_async(
    questions: List[str],
    models: List[str],
    execute_func: Callable,
    max_concurrent: int = 3,
    progress_callback: Callable = None,
    **kwargs
) -> List[Dict[str, Any]]:
    """
    å¹¶å‘æ‰§è¡Œæ‰€æœ‰é—®é¢˜å’Œæ¨¡å‹çš„ç»„åˆ
    
    Args:
        questions: é—®é¢˜åˆ—è¡¨
        models: æ¨¡å‹åˆ—è¡¨
        execute_func: æ‰§è¡Œå‡½æ•°
        max_concurrent: æœ€å¤§å¹¶å‘æ•°
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        **kwargs: å…¶ä»–å‚æ•°
    
    Returns:
        æ‰€æœ‰æ‰§è¡Œç»“æœ
    
    Example:
        results = await execute_async(
            questions=['é—®é¢˜ 1', 'é—®é¢˜ 2', 'é—®é¢˜ 3'],
            models=['doubao', 'deepseek'],
            execute_func=call_ai_api,
            max_concurrent=3
        )
    """
    # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
    tasks = []
    for q_idx, question in enumerate(questions):
        for m_idx, model in enumerate(models):
            tasks.append({
                'task_id': f'q{q_idx}_m{m_idx}',
                'question': question,
                'model_name': model,
                'question_index': q_idx,
                'model_index': m_idx
            })
    
    # åˆ›å»ºæ‰§è¡Œå¼•æ“
    engine = AsyncExecutionEngine(max_concurrent=max_concurrent)
    engine.set_progress_callback(progress_callback)
    
    # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    results = await engine.execute_all(
        tasks=tasks,
        execute_func=execute_func,
        **kwargs
    )
    
    return results


def calculate_speedup(
    sync_time: float,
    async_time: float,
    num_tasks: int
) -> Dict[str, float]:
    """
    è®¡ç®—æ€§èƒ½æå‡
    
    Args:
        sync_time: åŒæ­¥æ‰§è¡Œæ—¶é—´
        async_time: å¼‚æ­¥æ‰§è¡Œæ—¶é—´
        num_tasks: ä»»åŠ¡æ•°é‡
    
    Returns:
        æ€§èƒ½æå‡ç»Ÿè®¡
    """
    return {
        'sync_time': sync_time,
        'async_time': async_time,
        'speedup_ratio': sync_time / async_time if async_time > 0 else 0,
        'time_saved': sync_time - async_time,
        'time_saved_percent': ((sync_time - async_time) / sync_time * 100) if sync_time > 0 else 0,
        'avg_task_time_sync': sync_time / num_tasks if num_tasks > 0 else 0,
        'avg_task_time_async': async_time / num_tasks if num_tasks > 0 else 0
    }


if __name__ == '__main__':
    # æµ‹è¯•å¼‚æ­¥æ‰§è¡Œå¼•æ“
    import time
    
    print("="*60)
    print("æ€§èƒ½ä¼˜åŒ–ï¼šå¼‚æ­¥å¹¶å‘æ‰§è¡Œå¼•æ“æµ‹è¯•")
    print("="*60)
    print()
    
    # æ¨¡æ‹ŸåŒæ­¥ AI è°ƒç”¨ï¼ˆè€—æ—¶ 2 ç§’ï¼‰
    def mock_ai_call(question, model, **kwargs):
        time.sleep(2)  # æ¨¡æ‹Ÿ AI è°ƒç”¨å»¶è¿Ÿ
        return {
            'question': question,
            'model': model,
            'success': True,
            'answer': f'è¿™æ˜¯ {model} å¯¹ "{question}" çš„å›ç­”'
        }
    
    # è¿›åº¦å›è°ƒ
    async def on_progress(completed, total, task_id, **kwargs):
        print(f"[è¿›åº¦] {completed}/{total} ({completed/total*100:.0f}%) - ä»»åŠ¡ {task_id}")
    
    # æµ‹è¯•å‚æ•°
    questions = ['é—®é¢˜ 1', 'é—®é¢˜ 2', 'é—®é¢˜ 3']
    models = ['doubao', 'deepseek']
    
    print(f"æµ‹è¯•åœºæ™¯ï¼š{len(questions)} ä¸ªé—®é¢˜ Ã— {len(models)} ä¸ªæ¨¡å‹ = {len(questions)*len(models)} æ¬¡ AI è°ƒç”¨")
    print()
    
    # åŒæ­¥æ‰§è¡Œï¼ˆæ¨¡æ‹Ÿï¼‰
    print("ğŸ“Š åŒæ­¥æ‰§è¡Œï¼ˆæ¨¡æ‹Ÿï¼‰:")
    sync_start = time.time()
    for q in questions:
        for m in models:
            mock_ai_call(q, m)
    sync_time = time.time() - sync_start
    print(f"åŒæ­¥æ‰§è¡Œè€—æ—¶ï¼š{sync_time:.2f}ç§’")
    print()
    
    # å¼‚æ­¥æ‰§è¡Œ
    print("ğŸš€ å¼‚æ­¥å¹¶å‘æ‰§è¡Œï¼ˆæœ€å¤§å¹¶å‘æ•°=3ï¼‰:")
    async_start = time.time()
    results = asyncio.run(execute_async(
        questions=questions,
        models=models,
        execute_func=mock_ai_call,
        max_concurrent=3,
        progress_callback=on_progress
    ))
    async_time = time.time() - async_start
    print(f"å¼‚æ­¥æ‰§è¡Œè€—æ—¶ï¼š{async_time:.2f}ç§’")
    print()
    
    # æ€§èƒ½å¯¹æ¯”
    print("ğŸ“ˆ æ€§èƒ½å¯¹æ¯”:")
    stats = calculate_speedup(sync_time, async_time, len(questions)*len(models))
    print(f"  åŒæ­¥è€—æ—¶ï¼š{stats['sync_time']:.2f}ç§’")
    print(f"  å¼‚æ­¥è€—æ—¶ï¼š{stats['async_time']:.2f}ç§’")
    print(f"  æ€§èƒ½æå‡ï¼š{stats['speedup_ratio']:.1f}x")
    print(f"  æ—¶é—´èŠ‚çœï¼š{stats['time_saved']:.2f}ç§’ ({stats['time_saved_percent']:.0f}%)")
    print()
    print("âœ… æµ‹è¯•å®Œæˆ")
