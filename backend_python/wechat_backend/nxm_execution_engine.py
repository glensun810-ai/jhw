"""
NxM æ‰§è¡Œå¼•æ“ - ä¸»å…¥å£

é‡æ„ç‰ˆæœ¬ï¼šæ¨¡å—åŒ–
- ç†”æ–­å™¨ â†’ nxm_circuit_breaker.py
- ä»»åŠ¡è°ƒåº¦ â†’ nxm_scheduler.py
- ç»“æœèšåˆ â†’ nxm_result_aggregator.py
- å®¹é”™æœºåˆ¶ â†’ fault_tolerant_executor.py

è¾“å…¥ï¼šNxM æ‰§è¡Œå‚æ•°
è¾“å‡ºï¼šæ‰§è¡Œç»“æœ

æ ¸å¿ƒåŸåˆ™ï¼š
1. ç»“æœäº§å‡ºç»å¯¹ä¼˜å…ˆ - ä»»ä½•é”™è¯¯éƒ½ä¸èƒ½é˜»æ­¢è¿”å›ç»“æœ
2. ä¼˜é›…é™çº§ - éƒ¨åˆ†å¤±è´¥æ—¶è¿”å›å¯ç”¨ç»“æœ
3. é”™è¯¯é€æ˜åŒ– - æ˜ç¡®æ ‡æ³¨å¤±è´¥åŸå› å’Œè§£å†³å»ºè®®
4. ç”¨æˆ·ç¬¬ä¸€ - ç”¨æˆ·ä½“éªŒä¼˜å…ˆäºæŠ€æœ¯å®Œç¾æ€§

æ”¹é€ è®°å½•:
- M001: ä¿®å¤ AI è°ƒç”¨æ–¹æ³• (generate_response â†’ send_prompt)
- M002: æ·»åŠ å®¹é”™åŒ…è£¹ (å¼•å…¥ FaultTolerantExecutor)
- M003: å®æ—¶æŒä¹…åŒ– (save_dimension_result)
"""

import time
import threading
import os
import asyncio
import json
import traceback
import pickle
from typing import List, Dict, Any, Optional
from datetime import datetime

from wechat_backend.ai_adapters.factory import AIAdapterFactory
from wechat_backend.ai_adapters.base_adapter import GEO_PROMPT_TEMPLATE, OBJECTIVE_QUESTION_TEMPLATE
from wechat_backend.logging_config import api_logger
from wechat_backend.database import save_test_record

# å®¹é”™æ‰§è¡Œå™¨ï¼ˆæ–°å¢ï¼‰
from wechat_backend.fault_tolerant_executor import FaultTolerantExecutor, safe_json_serialize

# BUG-NEW-002 ä¿®å¤ï¼šå¼‚æ­¥æ‰§è¡Œå¼•æ“
from wechat_backend.performance.async_execution_engine import execute_async

# å¯¼å…¥æ¨¡å—
from wechat_backend.nxm_circuit_breaker import get_circuit_breaker
from wechat_backend.nxm_scheduler import NxMScheduler, create_scheduler
from wechat_backend.nxm_result_aggregator import (
    parse_geo_with_validation,
    verify_completion,
    deduplicate_results,
    aggregate_results_by_brand
)
# P2-011 æ–°å¢ï¼šä½¿ç”¨ç‹¬ç«‹çš„è´¨é‡è¯„åˆ†æœåŠ¡
from wechat_backend.services.quality_scorer import get_quality_scorer
# P1-014 æ–°å¢ï¼šAI è¶…æ—¶ä¿æŠ¤
from wechat_backend.ai_timeout import get_timeout_manager, AITimeoutError
# ã€é‡æ„ã€‘å•æ¨¡å‹è°ƒç”¨ä¸ä¼˜å…ˆçº§è¯„ä¼°
from wechat_backend.multi_model_executor import get_single_model_executor, get_priority_evaluator

# é…ç½®å¯¼å…¥
from legacy_config import Config


# ==================== P0-001 ä¿®å¤ï¼šå¼‚æ­¥æ‰§è¡Œè¾…åŠ©å‡½æ•° ====================

def run_async_in_thread(coro):
    """
    åœ¨çº¿ç¨‹ä¸­å®‰å…¨è¿è¡Œå¼‚æ­¥ä»£ç 

    é—®é¢˜ï¼šasyncio.run() åœ¨å·²æœ‰äº‹ä»¶å¾ªç¯çš„çº¿ç¨‹ä¸­ä¼šæŠ›å‡º RuntimeError
    è§£å†³ï¼šåˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯å¹¶åœ¨çº¿ç¨‹ä¸­è¿è¡Œ

    å‚æ•°:
        coro: å¼‚æ­¥åç¨‹å¯¹è±¡

    è¿”å›:
        åç¨‹æ‰§è¡Œç»“æœ
    """
    loop = asyncio.new_event_loop()
    try:
        asyncio.set_event_loop(loop)
        return loop.run_until_complete(coro)
    finally:
        loop.close()


# ==================== P0-004 ä¿®å¤ï¼šé¢„å†™æ—¥å¿—ï¼ˆWALï¼‰æœºåˆ¶ ====================

WAL_DIR = '/tmp/nxm_wal'
os.makedirs(WAL_DIR, exist_ok=True)


def write_wal(execution_id: str, results: List[Dict], completed: int, total: int, brand: str = None, model: str = None):
    """
    é¢„å†™æ—¥å¿— - åœ¨å†…å­˜æŒä¹…åŒ–å‰å†™å…¥ç£ç›˜
    
    é—®é¢˜ï¼šå®æ—¶æŒä¹…åŒ–æ˜¯"æœ€ä½³åŠªåŠ›"æ¨¡å¼ï¼Œå¤±è´¥æ—¶åªè®°å½•æ—¥å¿—
    è§£å†³ï¼šæ¯æ¬¡ AI è°ƒç”¨æˆåŠŸåç«‹å³å†™å…¥ WALï¼ŒæœåŠ¡é‡å¯åå¯æ¢å¤
    
    å‚æ•°:
        execution_id: æ‰§è¡Œ ID
        results: ç»“æœåˆ—è¡¨
        completed: å·²å®Œæˆä»»åŠ¡æ•°
        total: æ€»ä»»åŠ¡æ•°
        brand: å½“å‰å“ç‰Œï¼ˆå¯é€‰ï¼‰
        model: å½“å‰æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
    """
    try:
        wal_path = os.path.join(WAL_DIR, f'nxm_wal_{execution_id}.pkl')
        wal_data = {
            'execution_id': execution_id,
            'results': results,
            'completed': completed,
            'total': total,
            'brand': brand,
            'model': model,
            'timestamp': time.time(),
            'last_updated': datetime.now().isoformat()
        }
        with open(wal_path, 'wb') as f:
            pickle.dump(wal_data, f)
        api_logger.info(f"[WAL] âœ… å·²å†™å…¥ï¼š{wal_path} (å®Œæˆï¼š{completed}/{total})")
    except Exception as e:
        api_logger.error(f"[WAL] âš ï¸ å†™å…¥å¤±è´¥ï¼š{e}")


def read_wal(execution_id: str) -> Optional[Dict]:
    """
    è¯»å–é¢„å†™æ—¥å¿—
    
    å‚æ•°:
        execution_id: æ‰§è¡Œ ID
    
    è¿”å›:
        WAL æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
    """
    try:
        wal_path = os.path.join(WAL_DIR, f'nxm_wal_{execution_id}.pkl')
        if os.path.exists(wal_path):
            with open(wal_path, 'rb') as f:
                data = pickle.load(f)
            api_logger.info(f"[WAL] âœ… å·²è¯»å–ï¼š{wal_path}")
            return data
    except Exception as e:
        api_logger.error(f"[WAL] âš ï¸ è¯»å–å¤±è´¥ï¼š{e}")
    return None


def cleanup_expired_wal(max_age_hours: int = 24):
    """
    æ¸…ç†è¿‡æœŸ WAL æ–‡ä»¶
    
    å‚æ•°:
        max_age_hours: æœ€å¤§ä¿ç•™å°æ—¶æ•°
    """
    try:
        import glob
        now = time.time()
        wal_files = glob.glob(os.path.join(WAL_DIR, 'nxm_wal_*.pkl'))
        cleaned_count = 0
        for wal_file in wal_files:
            try:
                mtime = os.path.getmtime(wal_file)
                if (now - mtime) > (max_age_hours * 3600):
                    os.remove(wal_file)
                    cleaned_count += 1
                    api_logger.info(f"[WAL] ğŸ—‘ï¸ æ¸…ç†è¿‡æœŸæ–‡ä»¶ï¼š{wal_file}")
            except Exception:
                pass
        if cleaned_count > 0:
            api_logger.info(f"[WAL] æ¸…ç†å®Œæˆï¼Œå…±æ¸…ç† {cleaned_count} ä¸ªæ–‡ä»¶")
    except Exception as e:
        api_logger.error(f"[WAL] æ¸…ç†å¤±è´¥ï¼š{e}")


def recover_from_wal(execution_id: str) -> Optional[Dict]:
    """
    ä» WAL æ¢å¤æœªå®Œæˆçš„æ‰§è¡Œ
    
    å‚æ•°:
        execution_id: æ‰§è¡Œ ID
    
    è¿”å›:
        æ¢å¤çš„æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–å·²å®Œæˆåˆ™è¿”å› None
    """
    wal_data = read_wal(execution_id)
    if wal_data:
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸï¼ˆè¶…è¿‡ 24 å°æ—¶ï¼‰
        wal_age_hours = (time.time() - wal_data.get('timestamp', 0)) / 3600
        if wal_age_hours > 24:
            api_logger.warning(f"[WAL] âš ï¸ WAL æ–‡ä»¶å·²è¿‡ {wal_age_hours:.1f} å°æ—¶ï¼Œå¿½ç•¥")
            return None
        
        # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
        if wal_data.get('completed', 0) >= wal_data.get('total', 0):
            api_logger.info(f"[WAL] âœ… æ‰§è¡Œå·²å®Œæˆï¼Œæ— éœ€æ¢å¤")
            return None
        
        api_logger.info(f"[WAL] ğŸ”„ æ¢å¤æ‰§è¡Œï¼š{execution_id}, è¿›åº¦ï¼š{wal_data.get('completed')}/{wal_data.get('total')}")
        return wal_data
    return None


# ==================== å•æ¨¡å‹è°ƒç”¨è¾…åŠ©å‡½æ•°ï¼ˆç§»é™¤å¤šæ¨¡å‹å†—ä½™ï¼‰ ====================

async def _execute_single_model(
    prompt: str,
    model_name: str,
    timeout: int,
    execution_id: str = None,
    q_idx: int = None
):
    """
    æ‰§è¡Œå•æ¨¡å‹è°ƒç”¨ï¼ˆç”¨æˆ·é€‰æ‹©å“ªä¸ªæ¨¡å‹å°±ç”¨å“ªä¸ªï¼‰

    ç­–ç•¥ï¼š
    1. åªè°ƒç”¨ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹
    2. å¤±è´¥æ—¶ç›´æ¥è¿”å›é”™è¯¯ï¼Œä¸è‡ªåŠ¨å°è¯•å…¶ä»–æ¨¡å‹
    3. ç”±ä¸Šå±‚å†³å®šå¦‚ä½•å¤„ç†å¤±è´¥

    å‚æ•°ï¼š
        prompt: æç¤ºè¯
        model_name: æ¨¡å‹åç§°ï¼ˆç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹ï¼‰
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        execution_id: æ‰§è¡Œ ID
        q_idx: é—®é¢˜ç´¢å¼•

    è¿”å›ï¼š
        (AIResponse, model_name): AI å“åº”å’Œå®é™…ä½¿ç”¨çš„æ¨¡å‹åç§°
    """
    from wechat_backend.multi_model_executor import get_single_model_executor

    # è·å–å•æ¨¡å‹æ‰§è¡Œå™¨
    executor = get_single_model_executor(timeout=timeout)

    # æ‰§è¡Œå•æ¨¡å‹è°ƒç”¨
    result, actual_model = await executor.execute(
        prompt=prompt,
        model_name=model_name,
        execution_id=execution_id,
        q_idx=q_idx
    )

    return result, actual_model


def execute_nxm_test(
    execution_id: str,
    main_brand: str,
    competitor_brands: List[str],
    selected_models: List[Dict[str, Any]],
    raw_questions: List[str],
    user_id: str,
    user_level: str,
    execution_store: Dict[str, Any],
    timeout_seconds: int = 300
) -> Dict[str, Any]:
    """
    æ‰§è¡Œ NxM æµ‹è¯•ï¼ˆM001-M003 æ”¹é€ åç‰ˆæœ¬ï¼‰
    
    æ”¹é€ å†…å®¹:
    - M001: ä½¿ç”¨ send_prompt æ›¿ä»£ generate_response
    - M002: ä½¿ç”¨ FaultTolerantExecutor ç»Ÿä¸€åŒ…è£¹ AI è°ƒç”¨
    - M003: å®æ—¶æŒä¹…åŒ–ç»´åº¦ç»“æœåˆ°æ•°æ®åº“
    """

    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = create_scheduler(execution_id, execution_store)

    # P0 ä¿®å¤ï¼šå®¢è§‚æé—®æ¨¡å¼ä¸‹ï¼Œè¯·æ±‚æ¬¡æ•° = é—®é¢˜æ•° Ã— AI å¹³å°æ•°ï¼ˆä¸åŒ…å«å“ç‰Œéå†ï¼‰
    # åŸä»£ç ï¼štotal_tasks = (1 + len(competitor_brands or [])) * len(raw_questions) * len(selected_models)
    # ä¿®å¤åï¼šåªè®¡ç®—é—®é¢˜Ã—æ¨¡å‹çš„ç»„åˆæ•°
    total_tasks = len(raw_questions) * len(selected_models)
    scheduler.initialize_execution(total_tasks)

    # BUG-008 ä¿®å¤ï¼šç»Ÿä¸€è¶…æ—¶é…ç½®
    def on_timeout():
        scheduler.fail_execution(f"æ‰§è¡Œè¶…æ—¶ ({timeout_seconds}ç§’)")

    scheduler.start_timeout_timer(timeout_seconds, on_timeout)

    # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œ
    def run_execution():
        # ã€ä¿®å¤ P0-4ã€‘åœ¨ try å—å¤–å…ˆå¯¼å…¥ execution_storeï¼Œé¿å…ä½œç”¨åŸŸé—®é¢˜
        try:
            from wechat_backend.views.diagnosis_views import execution_store
        except ImportError:
            execution_store = {}
            api_logger.error(f"[NxM] æ— æ³•å¯¼å…¥ execution_storeï¼Œä½¿ç”¨ç©ºå­—å…¸")

        try:
            results = []
            completed = 0

            # P0 ä¿®å¤ï¼šåªéå†é—®é¢˜å’Œæ¨¡å‹ï¼Œä¸éå†å“ç‰Œï¼ˆè·å–å®¢è§‚å›ç­”ï¼‰
            # è¯·æ±‚æ¬¡æ•° = é—®é¢˜æ•° Ã— AI å¹³å°æ•°
            api_logger.info(f"[NxM] æ‰§è¡Œé—®é¢˜æ•°ï¼š{len(raw_questions)}, AI å¹³å°æ•°ï¼š{len(selected_models)}")

            # å¤–å±‚å¾ªç¯ï¼šéå†é—®é¢˜
            for q_idx, question in enumerate(raw_questions):
                # å†…å±‚å¾ªç¯ï¼šéå†æ¨¡å‹
                for model_info in selected_models:
                    model_name = model_info.get('name', '')

                    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨ï¼ˆç†”æ–­å™¨ï¼‰
                    if not scheduler.is_model_available(model_name):
                        api_logger.warning(f"[NxM] æ¨¡å‹ {model_name} å·²ç†”æ–­ï¼Œè·³è¿‡")
                        completed += 1
                        scheduler.update_progress(completed, total_tasks, 'ai_fetching')
                        continue

                    try:
                        # P0 ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨ Config ç±»è·å– API Keyï¼Œé¿å…å¾ªç¯ä¾èµ–
                        # åˆ›å»º AI å®¢æˆ·ç«¯
                        client = AIAdapterFactory.create(model_name)
                        api_key = Config.get_api_key(model_name)

                        if not api_key:
                            raise ValueError(f"æ¨¡å‹ {model_name} API Key æœªé…ç½®")

                        # P0 ä¿®å¤ï¼šæ„å»ºå®¢è§‚é—®é¢˜æç¤ºè¯ï¼ˆä¸å¸¦å“ç‰Œå€¾å‘ï¼‰
                        prompt = OBJECTIVE_QUESTION_TEMPLATE.format(
                            question=question
                        )

                        # P1-014 æ–°å¢ï¼šè·å–è¶…æ—¶é…ç½®
                        timeout_manager = get_timeout_manager()
                        timeout = timeout_manager.get_timeout(model_name)

                        # M002 æ”¹é€ ï¼šä½¿ç”¨ FaultTolerantExecutor ç»Ÿä¸€åŒ…è£¹ AI è°ƒç”¨
                        # åˆ›å»ºå®¹é”™æ‰§è¡Œå™¨å®ä¾‹ï¼ˆæ¯ä¸ªè°ƒç”¨ç‹¬ç«‹ï¼‰
                        ai_executor = FaultTolerantExecutor(timeout_seconds=timeout)

                        # ã€P1-2 æ–°å¢ã€‘å¤šæ¨¡å‹å†—ä½™è°ƒç”¨æœºåˆ¶
                        # ç­–ç•¥ï¼š
                        # 1. é¦–å…ˆå°è¯•ä¸»æ¨¡å‹
                        # 2. ä¸»æ¨¡å‹å¤±è´¥æ—¶ï¼Œè‡ªåŠ¨å°è¯•å¤‡ç”¨æ¨¡å‹
                        # 3. è¿”å›ç¬¬ä¸€ä¸ªæˆåŠŸçš„æœ‰æ•ˆç»“æœ
                        
                        # P0-001 ä¿®å¤ï¼šä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„å¼‚æ­¥æ‰§è¡Œæ–¹å¼
                        # åŸä»£ç é—®é¢˜ï¼šasyncio.run() åœ¨å·²æœ‰äº‹ä»¶å¾ªç¯çš„çº¿ç¨‹ä¸­ä¼šæŠ›å‡º RuntimeError
                        # ä¿®å¤æ–¹æ¡ˆï¼šä½¿ç”¨ run_async_in_thread() åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯

                        # ã€é‡æ„ã€‘ä½¿ç”¨å•æ¨¡å‹è°ƒç”¨ï¼ˆç”¨æˆ·é€‰æ‹©å“ªä¸ªæ¨¡å‹å°±ç”¨å“ªä¸ªï¼‰
                        api_logger.info(f"[NxM] ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹ï¼š{model_name}, Q{q_idx}")

                        ai_result, actual_model = run_async_in_thread(
                            _execute_single_model(
                                prompt=prompt,
                                model_name=model_name,
                                timeout=timeout,
                                execution_id=execution_id,
                                q_idx=q_idx
                            )
                        )

                        # ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹åº”è¯¥ä¸å®é™…ä½¿ç”¨çš„æ¨¡å‹ä¸€è‡´
                        if actual_model != model_name:
                            api_logger.warning(
                                f"[NxM] å®é™…ä½¿ç”¨æ¨¡å‹ä¸é€‰æ‹©ä¸åŒï¼šé€‰æ‹©={model_name}, å®é™…={actual_model}, Q{q_idx}"
                            )
                            model_name = actual_model  # æ›´æ–°æ¨¡å‹åä¸ºå®é™…ä½¿ç”¨çš„æ¨¡å‹
                        
                        # æ£€æŸ¥ AI è°ƒç”¨ç»“æœ
                        geo_data = None
                        parse_error = None

                        # P0-STATUS-1 ä¿®å¤ï¼šAIResponse ä½¿ç”¨ success å±æ€§è€Œé status å±æ€§
                        if ai_result.success:
                            # AI è°ƒç”¨æˆåŠŸï¼Œè§£æ GEO æ•°æ®
                            scheduler.record_model_success(model_name)

                            # è§£æ GEO æ•°æ®ï¼ˆä¿®å¤ï¼šä½¿ç”¨ content è€Œé dataï¼‰
                            geo_data, parse_error = parse_geo_with_validation(
                                ai_result.content,
                                execution_id,
                                q_idx,
                                model_name
                            )

                            # æ£€æŸ¥è§£æç»“æœ
                            if parse_error or geo_data.get('_error'):
                                # è§£æå¤±è´¥ï¼Œè®°å½•é”™è¯¯
                                api_logger.warning(f"[NxM] è§£æå¤±è´¥ï¼š{model_name}, Q{q_idx}: {parse_error or geo_data.get('_error')}")
                                # P0-4 ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨å­—å…¸æ”¶é›†ç»“æœ
                                # P3 ä¿®å¤ï¼šç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¯åºåˆ—åŒ–çš„
                                # ã€P0 å…³é”®ä¿®å¤ã€‘response æ”¹ä¸ºå­—å…¸æ ¼å¼ï¼Œå…¼å®¹å­˜å‚¨å±‚è¦æ±‚
                                result = {
                                    'question': question,
                                    'model': model_name,
                                    'response': {  # å­—å…¸æ ¼å¼ï¼š{content, latency, metadata}
                                        'content': str(ai_result.content) if hasattr(ai_result, 'content') else str(ai_result),
                                        'latency': None,
                                        'metadata': {}
                                    },
                                    'geo_data': geo_data,
                                    'error': str(parse_error or geo_data.get('_error', 'è§£æå¤±è´¥')),
                                    'error_type': str(ai_result.error_type.value) if hasattr(ai_result, 'error_type') and ai_result.error_type else 'parse_error',
                                    'is_objective': True  # æ ‡è®°ä¸ºå®¢è§‚å›ç­”
                                }
                                results.append(result)
                            else:
                                # è§£ææˆåŠŸï¼Œæ”¶é›†ç»“æœ
                                # P3 ä¿®å¤ï¼šç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¯åºåˆ—åŒ–çš„
                                # ã€P0 å…³é”®ä¿®å¤ã€‘response æ”¹ä¸ºå­—å…¸æ ¼å¼ï¼Œå…¼å®¹å­˜å‚¨å±‚è¦æ±‚
                                result = {
                                    'question': question,
                                    'model': model_name,
                                    'response': {  # å­—å…¸æ ¼å¼ï¼š{content, latency, metadata}
                                        'content': str(ai_result.content) if hasattr(ai_result, 'content') else str(ai_result),
                                        'latency': None,
                                        'metadata': {}
                                    },
                                    'geo_data': geo_data,
                                    'error': None,
                                    'error_type': None,
                                    'is_objective': True  # æ ‡è®°ä¸ºå®¢è§‚å›ç­”
                                }
                                results.append(result)
                        else:
                            # AI è°ƒç”¨å¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶ç»§ç»­ï¼ˆä¸ä¸­æ–­æµç¨‹ï¼‰
                            scheduler.record_model_failure(model_name)
                            api_logger.error(f"[NxM] AI è°ƒç”¨å¤±è´¥ï¼š{model_name}, Q{q_idx}: {ai_result.error_message}")

                            # P0-4 ä¿®å¤ï¼šæ”¶é›†å¤±è´¥ç»“æœï¼ˆä¿è¯æŠ¥å‘Šå®Œæ•´ï¼‰
                            # P3 ä¿®å¤ï¼šç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¯åºåˆ—åŒ–çš„
                            # ã€P0 å…³é”®ä¿®å¤ã€‘response æ”¹ä¸ºå­—å…¸æ ¼å¼ï¼Œå…¼å®¹å­˜å‚¨å±‚è¦æ±‚
                            result = {
                                'question': question,
                                'model': model_name,
                                'response': {  # å­—å…¸æ ¼å¼ï¼š{content, latency, metadata}
                                    'content': None,
                                    'latency': None,
                                    'metadata': {}
                                },
                                'geo_data': None,
                                'error': str(ai_result.error_message),
                                'error_type': str(ai_result.error_type.value) if hasattr(ai_result, 'error_type') and ai_result.error_type else 'unknown',
                                'is_objective': True  # æ ‡è®°ä¸ºå®¢è§‚å›ç­”
                            }
                            results.append(result)
                        
                        # M003 æ”¹é€ ï¼šå®æ—¶æŒä¹…åŒ–ç»´åº¦ç»“æœ
                        # åŸæœ‰é—®é¢˜ï¼šç»“æœä»…åœ¨å†…å­˜ä¸­ï¼ŒæœåŠ¡é‡å¯åä¸¢å¤±
                        # æ”¹é€ åï¼šæ¯ä¸ªç»´åº¦ç»“æœç«‹å³ä¿å­˜åˆ°æ•°æ®åº“ï¼Œæ”¯æŒè¿›åº¦æŸ¥è¯¢å’Œå†å²è¿½æº¯
                        try:
                            from wechat_backend.repositories import save_dimension_result, save_task_status

                            # P0-STATUS-1 ä¿®å¤ï¼šAIResponse ä½¿ç”¨ success å±æ€§è€Œé status å±æ€§
                            dim_status = "success" if (ai_result.success and geo_data and not geo_data.get('_error')) else "failed"
                            dim_score = None
                            if dim_status == "success" and geo_data:
                                # ä» GEO æ•°æ®ä¸­æå–æ’åä½œä¸ºåˆ†æ•°å‚è€ƒ
                                rank = geo_data.get("rank", -1)
                                if rank > 0:
                                    dim_score = max(0, 100 - (rank - 1) * 10)  # æ’åç¬¬ 1 å¾— 100 åˆ†ï¼Œæ¯é™ 1 åå‡ 10 åˆ†

                            # ä¿å­˜ç»´åº¦ç»“æœ
                            # æ­¤å¤„brandå‚æ•°åº”è°ƒæ•´ï¼Œå› ä¸ºæ”¹ä¸ºå®¢è§‚æé—®ï¼Œå“ç‰Œä¸åœ¨è¯·æ±‚ä¸­æŒ‡å®šã€‚
                            # å¯èƒ½éœ€è¦è°ƒæ•´æ•°æ®åº“ç»“æ„æˆ–åœ¨èšåˆé˜¶æ®µå¤„ç†ã€‚
                            # è¿™é‡Œæš‚æ—¶ä¿ç•™brandå˜é‡ï¼Œä½†P0ä¿®å¤è®¡åˆ’ä¸­æç¤ºè¯å·²ç§»é™¤brandå¼•ç”¨ã€‚
                            # éœ€è¦ä¸Šå±‚ä»£ç ç¡®ä¿brandå˜é‡çš„æ­£ç¡®ä¸Šä¸‹æ–‡æˆ–åœ¨æ­¤å¤„ä½¿ç”¨å ä½ã€‚
                            save_dimension_result(
                                execution_id=execution_id,
                                dimension_name=f"{main_brand}-{model_name}", # P0ä¿®å¤ï¼šä½¿ç”¨main_brandä½œä¸ºç»´åº¦ç»´åº¦æ ‡è¯†
                                dimension_type="ai_analysis",
                                source=model_name,
                                status=dim_status,
                                score=dim_score,
                                data=geo_data if dim_status == "success" else None,
                                error_message=ai_result.error_message if dim_status == "failed" else (parse_error if parse_error else None)
                            )

                            # å®æ—¶æ›´æ–°è¿›åº¦
                            save_task_status(
                                task_id=execution_id,
                                stage='ai_fetching',
                                progress=int((completed / total_tasks) * 100) if total_tasks > 0 else 0,
                                status_text=f'å·²å®Œæˆ {completed}/{total_tasks}',
                                completed_count=completed,
                                total_count=total_tasks
                            )

                            api_logger.info(f"[NxM] âœ… ç»´åº¦ç»“æœæŒä¹…åŒ–æˆåŠŸï¼š{main_brand}-{model_name}, çŠ¶æ€ï¼š{dim_status}")

                        except Exception as persist_err:
                            # æŒä¹…åŒ–å¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œä»…è®°å½•é”™è¯¯
                            api_logger.error(f"[NxM] âš ï¸ ç»´åº¦ç»“æœæŒä¹…åŒ–å¤±è´¥ï¼š{main_brand}-{model_name}, é”™è¯¯ï¼š{persist_err}")
                            
                            # P1-018 æ–°å¢ï¼šæ•°æ®åº“æŒä¹…åŒ–å‘Šè­¦æœºåˆ¶
                            try:
                                from wechat_backend.alert_system import record_persistence_error, check_persistence_alert
                                
                                # è®°å½•æŒä¹…åŒ–é”™è¯¯
                                alert_triggered = record_persistence_error(
                                    execution_id=execution_id,
                                    error_type='dimension_result',
                                    error_message=str(persist_err)
                                )
                                
                                # å¦‚æœè§¦å‘å‘Šè­¦ï¼Œè®°å½•è¯¦ç»†æ—¥å¿—
                                if alert_triggered:
                                    api_logger.error(
                                        f"[P1-018 å‘Šè­¦] æ•°æ®åº“æŒä¹…åŒ–å¤±è´¥è¾¾åˆ°é˜ˆå€¼ï¼"
                                        f"execution_id={execution_id}, é”™è¯¯ï¼š{persist_err}"
                                    )
                                    # å¯ä»¥æ·»åŠ é¢å¤–çš„å‘Šè­¦é€šçŸ¥é€»è¾‘ï¼ˆå¦‚å‘é€é‚®ä»¶ã€çŸ­ä¿¡ç­‰ï¼‰
                            except Exception as alert_err:
                                api_logger.error(f"[P1-018] å‘Šè­¦è®°å½•å¤±è´¥ï¼š{alert_err}")

                        # ã€P0-004 ä¿®å¤ã€‘å†™å…¥ WALï¼ˆé¢„å†™æ—¥å¿—ï¼‰ï¼Œç¡®ä¿æœåŠ¡é‡å¯åæ•°æ®ä¸ä¸¢å¤±
                        # WAL å†™å…¥åœ¨æ•°æ®åº“æŒä¹…åŒ–ä¹‹åï¼Œä½œä¸ºåŒé‡ä¿éšœ
                        try:
                            # WALå†™å…¥éœ€ä¼ å…¥brandä¿¡æ¯ä»¥ä½œä¿éšœï¼Œè¿™é‡Œbrandä¿¡æ¯éœ€è¦æ˜ç¡®ä¸Šä¸‹æ–‡ã€‚
                            # è¿™é‡Œæš‚æ—¶ä½¿ç”¨main_brandã€‚
                            write_wal(execution_id, results, completed, total_tasks, main_brand, model_name)
                        except Exception as wal_err:
                            api_logger.error(f"[WAL] âš ï¸ å†™å…¥å¤±è´¥ï¼š{wal_err}")

                        # æ›´æ–°è¿›åº¦
                        completed += 1
                        scheduler.update_progress(completed, total_tasks, 'ai_fetching')

                    except Exception as e:
                        # P1-2 ä¿®å¤ï¼šå®Œå–„é”™è¯¯å¤„ç†ï¼Œè®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
                        error_message = f"AI è°ƒç”¨å¤±è´¥ï¼š{model_name}, é—®é¢˜{q_idx+1}: {str(e)}"
                        api_logger.error(f"[NxM] {error_message}")

                        # è®°å½•æ¨¡å‹å¤±è´¥
                        scheduler.record_model_failure(model_name)

                        # æ›´æ–°è¿›åº¦ï¼ŒåŒ…å«é”™è¯¯ä¿¡æ¯
                        completed += 1
                        scheduler.update_progress(completed, total_tasks, 'ai_fetching')

                        # P1-2 ä¿®å¤ï¼šä½¿ç”¨æ•°æ®åº“å­˜å‚¨é”™è¯¯è¯¦æƒ…ï¼Œé¿å…å¯¼å…¥é—®é¢˜
                        try:
                            from wechat_backend.repositories import save_task_status
                            
                            # ç´¯ç§¯é”™è¯¯ä¿¡æ¯åˆ°æ•°æ®åº“
                            save_task_status(
                                task_id=execution_id,
                                stage='failed',
                                progress=int((completed / total_tasks) * 100) if total_tasks > 0 else 0,
                                status_text=f'{error_message}',
                                completed_count=completed,
                                total_count=total_tasks
                            )
                        except Exception as store_error:
                            api_logger.error(f"[NxM] æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥ï¼š{store_error}")

            # éªŒè¯æ‰§è¡Œå®Œæˆ
            verification = verify_completion(results, total_tasks)

            # å»é‡ç»“æœï¼ˆæ— è®ºæ˜¯å¦å®Œå…¨å®Œæˆéƒ½æ‰§è¡Œï¼‰
            deduplicated = deduplicate_results(results) if results else []

            # ã€å…³é”®ä¿®å¤ã€‘åŒºåˆ†"å®Œå…¨å®Œæˆ"ã€"éƒ¨åˆ†å®Œæˆ"å’Œ"å®Œå…¨å¤±è´¥"
            has_valid_results = len(deduplicated) > 0

            if has_valid_results:
                # æœ‰ç»“æœæ—¶ï¼ˆå®Œå…¨å®Œæˆæˆ–éƒ¨åˆ†å®Œæˆï¼‰ï¼Œä¿å­˜æ•°æ®å¹¶ç”Ÿæˆé«˜çº§åˆ†æ
                api_logger.info(f"[NxM] æ‰§è¡Œå®Œæˆï¼š{execution_id}, ç»“æœæ•°ï¼š{len(deduplicated)}/{total_tasks}, å®Œæˆç‡ï¼š{len(deduplicated)*100//max(total_tasks,1)}%")

                # å®Œæˆæ‰§è¡Œï¼ˆè®¾ç½®çŠ¶æ€ä¸º completedï¼‰
                scheduler.complete_execution()

                # ã€P2-011 ä¼˜åŒ–ã€‘ä½¿ç”¨ç‹¬ç«‹çš„è´¨é‡è¯„åˆ†æœåŠ¡
                scorer = get_quality_scorer()
                
                # è®¡ç®—å®Œæˆç‡
                completion_rate = int(len(deduplicated) * 100 / max(total_tasks, 1))
                
                # P3 ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•å calculate è€Œä¸æ˜¯ evaluate
                quality_score = scorer.calculate(deduplicated, completion_rate)

                # ã€P0 ä¿®å¤ã€‘åç½®å“ç‰ŒæåŠåˆ†æï¼ˆå®¢è§‚æé—®æ¨¡å¼çš„æ ¸å¿ƒï¼‰
                # ä» AI å®¢è§‚å›ç­”ä¸­æå–ç”¨æˆ·å“ç‰ŒæåŠæƒ…å†µå’Œç«å“å¯¹æ¯”
                aggregated = []
                brand_analysis = None
                try:
                    from wechat_backend.services.brand_analysis_service import get_brand_analysis_service

                    # æå–ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹åç§°åˆ—è¡¨
                    user_model_names = [m.get('name', '') for m in selected_models if m.get('name')]
                    
                    # è·å–å“ç‰Œåˆ†ææœåŠ¡ï¼ˆåŠ¨æ€é€‰æ‹©è£åˆ¤æ¨¡å‹ï¼Œä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹ï¼‰
                    analysis_service = get_brand_analysis_service(
                        judge_model=None,  # ä¸æŒ‡å®šï¼Œè®©æœåŠ¡è‡ªåŠ¨é€‰æ‹©
                        user_selected_models=user_model_names  # ä¼ å…¥ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹åˆ—è¡¨
                    )

                    # æ‰§è¡Œå“ç‰ŒæåŠåˆ†æ
                    brand_analysis = analysis_service.analyze_brand_mentions(
                        results=deduplicated,
                        user_brand=main_brand,
                        competitor_brands=competitor_brands  # å¯ä¸º Noneï¼Œè‡ªåŠ¨ä»å›ç­”ä¸­æå–
                    )
                    
                    # æ„å»ºèšåˆç»“æœï¼ˆåŸºäºå“ç‰Œåˆ†æï¼‰
                    if brand_analysis:
                        aggregated = [{
                            'brand': main_brand,
                            'is_user_brand': True,
                            'mention_rate': brand_analysis['user_brand_analysis']['mention_rate'],
                            'average_rank': brand_analysis['user_brand_analysis']['average_rank'],
                            'average_sentiment': brand_analysis['user_brand_analysis']['average_sentiment'],
                            'is_top3': brand_analysis['user_brand_analysis']['is_top3'],
                            'mentioned_count': brand_analysis['user_brand_analysis']['mentioned_count'],
                            'total_responses': brand_analysis['user_brand_analysis']['total_responses'],
                            'comparison': brand_analysis['comparison']
                        }]
                        
                        # æ·»åŠ ç«å“åˆ†æ
                        for comp in brand_analysis.get('competitor_analysis', []):
                            aggregated.append({
                                'brand': comp['brand'],
                                'is_user_brand': False,
                                'mention_rate': comp['mention_rate'],
                                'average_rank': comp['average_rank'],
                                'average_sentiment': comp['average_sentiment'],
                                'is_top3': comp['is_top3'],
                                'mentioned_count': comp['mentioned_count'],
                                'total_responses': len(comp['mentions']),
                                'comparison': None
                            })
                        
                        api_logger.info(
                            f"[P0 ä¿®å¤] âœ… å“ç‰Œåˆ†æå®Œæˆï¼š{main_brand}, "
                            f"æåŠç‡={brand_analysis['user_brand_analysis']['mention_rate']:.1%}, "
                            f"ç«å“æ•°={len(brand_analysis['competitor_analysis'])}"
                        )
                    
                except Exception as analysis_err:
                    api_logger.error(f"[P0 ä¿®å¤] âš ï¸ å“ç‰Œåˆ†æå¤±è´¥ï¼š{analysis_err}")
                    # é™çº§ï¼šè¿”å›ç©ºèšåˆç»“æœ
                    aggregated = []

                # P3 ä¿®å¤ï¼šä¿å­˜æµ‹è¯•æ±‡æ€»è®°å½•åˆ° test_records è¡¨
                # è¿™æ˜¯å†å²è®°å½•åŠŸèƒ½çš„æ•°æ®æº
                try:
                    from wechat_backend.database_repositories import save_test_record
                    import json
                    import gzip

                    # è®¡ç®—ç»¼åˆåˆ†æ•°
                    overall_score = quality_score.get('overall_score', 0) if quality_score else 0

                    # æ„å»ºç»“æœæ‘˜è¦
                    results_summary = {
                        'total_tasks': total_tasks,
                        'completed_tasks': len(deduplicated),
                        'success_rate': len(deduplicated) / total_tasks if total_tasks > 0 else 0,
                        'quality_score': overall_score,
                        # å“ç‰Œä¿¡æ¯éœ€è¦åç½®åˆ†æï¼Œæ­¤å¤„brandsç½®ç©ºã€‚
                        # å“ç‰Œä¿¡æ¯ï¼ˆæ¥è‡ªåç½®åˆ†æï¼‰
                        'brands': [main_brand] + [c['brand'] for c in brand_analysis.get('competitor_analysis', [])] if brand_analysis else [],
                        'models': list(set(r.get('model', '') for r in deduplicated if r.get('model'))),
                        'user_brand_analysis': brand_analysis.get('user_brand_analysis') if brand_analysis else None,
                        'comparison': brand_analysis.get('comparison') if brand_analysis else None,
                        'models': list(set(r.get('model', '') for r in deduplicated if r.get('model'))),
                    }

                    # ä¿å­˜æµ‹è¯•è®°å½•
                    save_test_record(
                        user_openid=user_id or 'anonymous',
                        brand_name=main_brand,
                        ai_models_used=','.join(m.get('name', '') for m in selected_models),
                        questions_used=';'.join(raw_questions),
                        overall_score=overall_score,
                        total_tests=len(deduplicated),  # ä¿®å¤ï¼šä½¿ç”¨ total_tests è€Œé total_tasks
                        results_summary=gzip.compress(json.dumps(results_summary, ensure_ascii=False).encode()).decode('latin-1'),
                        detailed_results=gzip.compress(json.dumps(deduplicated, ensure_ascii=False).encode()).decode('latin-1')
                    )

                    api_logger.info(f"[NxM] âœ… æµ‹è¯•æ±‡æ€»è®°å½•ä¿å­˜æˆåŠŸï¼š{execution_id}")

                except Exception as save_err:
                    api_logger.error(f"[NxM] âš ï¸ æµ‹è¯•æ±‡æ€»è®°å½•ä¿å­˜å¤±è´¥ï¼š{execution_id}, é”™è¯¯ï¼š{save_err}")

                # P2-020 æ–°å¢ï¼šè®°å½•ç›‘æ§æŒ‡æ ‡
                # quota_exhausted_models, partial_warning éœ€è¦å¤„ç†
                try:
                    from wechat_backend.services.diagnosis_monitor_service import record_diagnosis_metric
                    import time
                    
                    # è®¡ç®—æ‰§è¡Œæ—¶é•¿ï¼ˆä» scheduler è·å–æˆ–ä¼°ç®—ï¼‰
                    execution_duration = scheduler.get_execution_duration() if hasattr(scheduler, 'get_execution_duration') else 0
                    
                    # è®°å½•è¯Šæ–­æŒ‡æ ‡
                    record_diagnosis_metric(
                        execution_id=execution_id,
                        user_id=user_id or 'anonymous',
                        total_tasks=total_tasks,
                        completed_tasks=len(deduplicated),
                        success=True,
                        duration_seconds=execution_duration,
                         quota_exhausted_models=[],
                         error_type=None,
                         error_message=None
                    )
                    
                    api_logger.info(f"[P2-020 ç›‘æ§] è¯Šæ–­æŒ‡æ ‡å·²è®°å½•ï¼š{execution_id}")
                except Exception as monitor_err:
                    api_logger.error(f"[P2-020 ç›‘æ§] è®°å½•å¤±è´¥ï¼š{monitor_err}")

                # åç½®åˆ†æéœ€é…åˆæ–¹æ¡ˆä¸‰å®ç°ã€‚æ­¤å¤„è¿”å›æš‚æ—  aggregated çš„æ•°æ®ç»“æ„ã€‚
                return {
                    'success': True,
                    'execution_id': execution_id,
                    'formula': f"{len(raw_questions)} é—®é¢˜ Ã— {len(selected_models)} æ¨¡å‹ = {total_tasks} æ¬¡è¯·æ±‚",
                    'total_tasks': total_tasks,
                    'completed_tasks': len(deduplicated),
                    'completion_rate': completion_rate,
                    'results': deduplicated,
                    'aggregated': aggregated,
                    'brand_analysis': brand_analysis,
                    'quality_score': quality_score,
                    # P0-007, P1-016 ç›¸å…³å­—æ®µç½®ç©º
                    'quota_exhausted_models': [],
                    'partial_warning': None,
                    'has_partial_results': len(deduplicated) < total_tasks,
                    'quota_warnings': [],
                    'quota_recovery_suggestions': []
                }
            else:
                # å®Œå…¨å¤±è´¥ï¼ˆæ— ä»»ä½•ç»“æœï¼‰
                api_logger.error(f"[NxM] æ‰§è¡Œå®Œå…¨å¤±è´¥ï¼š{execution_id}, æ— æœ‰æ•ˆç»“æœ")
                scheduler.fail_execution("æœªè·å–ä»»ä½•æœ‰æ•ˆç»“æœ")

                # è¿”å›å¤±è´¥ç»“æœ
                return {
                    'success': False,
                    'execution_id': execution_id,
                    'error': 'æ‰€æœ‰ AI è°ƒç”¨å‡å¤±è´¥ï¼Œæœªè·å–ä»»ä½•æœ‰æ•ˆç»“æœ',
                    'formula': f"{len(raw_questions)} é—®é¢˜ Ã— {len(selected_models)} æ¨¡å‹ = {total_tasks} æ¬¡è¯·æ±‚",
                    'total_tasks': total_tasks,
                    'completed_tasks': 0,
                    'results': [],
                    'aggregated': [],
                    'quality_score': None
                }

        except Exception as e:
            # æ‰§è¡Œå™¨å´©æºƒï¼ˆæç½•è§æƒ…å†µï¼‰
            api_logger.error(f"[NxM] æ‰§è¡Œå™¨å´©æºƒï¼š{execution_id}, é”™è¯¯ï¼š{e}\n{traceback.format_exc()}")
            scheduler.fail_execution(f"æ‰§è¡Œå™¨å´©æºƒï¼š{str(e)}")

            # è¿”å›é”™è¯¯ç»“æœ
            return {
                'success': False,
                'execution_id': execution_id,
                'error': f'æ‰§è¡Œå™¨å´©æºƒï¼š{str(e)}',
                'traceback': traceback.format_exc()
            }
        
        # P3 ä¿®å¤ï¼šç¡®ä¿ run_execution æ€»æ˜¯è¿”å›ç»“æœ
        # å¦‚æœä¸Šé¢çš„ä»£ç éƒ½æ²¡æœ‰è¿”å›ï¼ˆç†è®ºä¸Šä¸åº”è¯¥ï¼‰ï¼Œè¿”å›ä¸€ä¸ªç©ºç»“æœ
        return {
            'success': False,
            'execution_id': execution_id,
            'error': 'æ‰§è¡Œæµç¨‹å¼‚å¸¸ï¼Œæœªè¿”å›ç»“æœ',
            'results': []
        }

    # å¯åŠ¨æ‰§è¡Œï¼ˆåŒæ­¥æ–¹å¼ï¼Œç”±ä¸Šå±‚è°ƒåº¦å™¨ç®¡ç†è¶…æ—¶ï¼‰
    # P3 ä¿®å¤ï¼šæ•è· run_execution çš„è¿”å›å€¼ï¼Œç¡®ä¿å®é™…ç»“æœè¢«è¿”å›
    execution_result = run_execution()

    # è¿”å›æ‰§è¡Œç»“æœï¼ˆä¸æ˜¯åˆå§‹ç»“æœï¼‰
    return execution_result if execution_result else {
        'success': True,
        'execution_id': execution_id,
        'formula': f"{len(raw_questions)} é—®é¢˜ Ã— {len(selected_models)} æ¨¡å‹ = {total_tasks} æ¬¡è¯·æ±‚",
        'total_tasks': total_tasks
    }


def verify_nxm_execution(result: Dict[str, Any]) -> bool:
    """
    éªŒè¯ NxM æ‰§è¡Œç»“æœ

    å‚æ•°ï¼š
        result: NxM æ‰§è¡Œç»“æœ

    è¿”å›ï¼š
        æ˜¯å¦éªŒè¯é€šè¿‡
    """
    if not result:
        return False

    if not result.get('success'):
        api_logger.warning(f"[NxM] éªŒè¯å¤±è´¥ï¼š{result.get('error')}")
        return False

    results = result.get('results', [])
    if not results:
        api_logger.warning(f"[NxM] éªŒè¯è­¦å‘Šï¼šç»“æœä¸ºç©º")

    return True


# å¯¼å‡ºç»™å…¶ä»–æ¨¡å—ä½¿ç”¨
__all__ = ['execute_nxm_test', 'verify_nxm_execution']


