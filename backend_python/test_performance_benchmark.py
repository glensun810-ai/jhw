#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬
éªŒè¯ P0-P1 ä¼˜åŒ–åçš„æ€§èƒ½æŒ‡æ ‡

æµ‹è¯•åœºæ™¯ï¼š
1. SSE è¿æ¥æ€§èƒ½
2. é…ç½®çƒ­æ›´æ–°æ€§èƒ½
3. API å“åº”æ—¶é—´
4. å¹¶å‘è¿æ¥æµ‹è¯•
"""

import sys
import time
import json
import requests
import statistics
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

BASE_URL = 'http://127.0.0.1:5001'

class TestColors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    END = '\033[0m'
    BOLD = '\033[1m'

def print_header(text):
    print(f"\n{TestColors.BOLD}{TestColors.BLUE}{'='*70}{TestColors.END}")
    print(f"{TestColors.BOLD}{TestColors.BLUE}  {text}{TestColors.END}")
    print(f"{TestColors.BOLD}{TestColors.BLUE}{'='*70}{TestColors.END}\n")

def print_metric(name, value, unit, target=None, success=True):
    status = f"{TestColors.GREEN}âœ…{TestColors.END}" if success else f"{TestColors.RED}âŒ{TestColors.END}"
    target_text = f" (ç›®æ ‡ï¼š{target}{unit})" if target else ""
    print(f"{status} {name}: {value}{unit}{target_text}")

class PerformanceBenchmarkTester:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨"""
    
    def __init__(self, base_url=BASE_URL):
        self.base_url = base_url
        self.session = requests.Session()
        self.results = {
            'metrics': [],
            'passed': 0,
            'failed': 0
        }
    
    def test_health_endpoint_latency(self):
        """æµ‹è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹å»¶è¿Ÿ"""
        print_header("1. å¥åº·æ£€æŸ¥ç«¯ç‚¹å»¶è¿Ÿæµ‹è¯•")
        
        latencies = []
        iterations = 10
        
        print(f"æ‰§è¡Œ {iterations} æ¬¡è¯·æ±‚æµ‹è¯•...")
        
        for i in range(iterations):
            try:
                start = time.time()
                response = self.session.get(f"{self.base_url}/health", timeout=5)
                latency = (time.time() - start) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                
                if response.status_code == 200:
                    latencies.append(latency)
            except Exception as e:
                print(f"è¯·æ±‚å¤±è´¥ï¼š{e}")
        
        if latencies:
            avg_latency = statistics.mean(latencies)
            p95_latency = sorted(latencies)[int(len(latencies) * 0.95)]
            min_latency = min(latencies)
            max_latency = max(latencies)
            
            print_metric("å¹³å‡å»¶è¿Ÿ", f"{avg_latency:.2f}", "ms", target="50ms", success=avg_latency < 50)
            print_metric("P95 å»¶è¿Ÿ", f"{p95_latency:.2f}", "ms", target="100ms", success=p95_latency < 100)
            print_metric("æœ€å°å»¶è¿Ÿ", f"{min_latency:.2f}", "ms")
            print_metric("æœ€å¤§å»¶è¿Ÿ", f"{max_latency:.2f}", "ms")
            
            self.results['metrics'].append({
                'name': 'å¥åº·æ£€æŸ¥å»¶è¿Ÿ',
                'avg_ms': avg_latency,
                'p95_ms': p95_latency,
                'min_ms': min_latency,
                'max_ms': max_latency,
                'iterations': iterations,
                'passed': avg_latency < 50 and p95_latency < 100
            })
            
            if avg_latency < 50 and p95_latency < 100:
                self.results['passed'] += 1
                return True
            else:
                self.results['failed'] += 1
                return False
        else:
            print_metric("æµ‹è¯•", "å¤±è´¥", "", success=False)
            self.results['failed'] += 1
            return False
    
    def test_sse_connection(self):
        """æµ‹è¯• SSE è¿æ¥æ€§èƒ½"""
        print_header("2. SSE è¿æ¥æ€§èƒ½æµ‹è¯•")
        
        try:
            # æµ‹è¯• SSE ç»Ÿè®¡ç«¯ç‚¹å“åº”æ—¶é—´
            start = time.time()
            response = self.session.get(f"{self.base_url}/sse/stats", timeout=5)
            latency = (time.time() - start) * 1000
            
            if response.status_code == 200:
                data = response.json()
                print_metric("SSE ç»Ÿè®¡ç«¯ç‚¹å»¶è¿Ÿ", f"{latency:.2f}", "ms", target="50ms", success=latency < 50)
                print_metric("å½“å‰è¿æ¥æ•°", data.get('total_connections', 0), "")
                print_metric("å·²å‘é€æ¶ˆæ¯", data.get('messages_sent', 0), "")
                
                self.results['metrics'].append({
                    'name': 'SSE è¿æ¥æ€§èƒ½',
                    'latency_ms': latency,
                    'connections': data.get('total_connections', 0),
                    'messages_sent': data.get('messages_sent', 0),
                    'passed': latency < 50
                })
                
                if latency < 50:
                    self.results['passed'] += 1
                    return True
                else:
                    self.results['failed'] += 1
                    return False
            else:
                print_metric("SSE ç»Ÿè®¡ç«¯ç‚¹", f"HTTP {response.status_code}", "", success=False)
                self.results['failed'] += 1
                return False
                
        except Exception as e:
            print_metric("SSE è¿æ¥æµ‹è¯•", str(e), "", success=False)
            self.results['failed'] += 1
            return False
    
    def test_concurrent_connections(self):
        """æµ‹è¯•å¹¶å‘è¿æ¥æ€§èƒ½"""
        print_header("3. å¹¶å‘è¿æ¥æµ‹è¯•")
        
        def make_request(i):
            try:
                start = time.time()
                response = requests.get(f"{self.base_url}/health", timeout=10)
                latency = (time.time() - start) * 1000
                return {
                    'success': response.status_code == 200,
                    'latency': latency,
                    'status_code': response.status_code
                }
            except Exception as e:
                return {
                    'success': False,
                    'error': str(e)
                }
        
        concurrent_users = 10
        print(f"æ¨¡æ‹Ÿ {concurrent_users} ä¸ªå¹¶å‘ç”¨æˆ·...")
        
        with ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = [executor.submit(make_request, i) for i in range(concurrent_users)]
            
            results = []
            for future in as_completed(futures):
                results.append(future.result())
        
        successful = sum(1 for r in results if r.get('success'))
        latencies = [r['latency'] for r in results if r.get('success') and 'latency' in r]
        
        if latencies:
            avg_latency = statistics.mean(latencies)
            
            print_metric("æˆåŠŸè¯·æ±‚", successful, f"/{concurrent_users}", success=successful == concurrent_users)
            print_metric("å¹³å‡å»¶è¿Ÿ", f"{avg_latency:.2f}", "ms", target="100ms", success=avg_latency < 100)
            
            self.results['metrics'].append({
                'name': 'å¹¶å‘è¿æ¥æµ‹è¯•',
                'concurrent_users': concurrent_users,
                'successful': successful,
                'total': concurrent_users,
                'avg_latency_ms': avg_latency,
                'passed': successful == concurrent_users and avg_latency < 100
            })
            
            if successful == concurrent_users and avg_latency < 100:
                self.results['passed'] += 1
                return True
            else:
                self.results['failed'] += 1
                return False
        else:
            print_metric("å¹¶å‘æµ‹è¯•", "å¤±è´¥", "", success=False)
            self.results['failed'] += 1
            return False
    
    def test_api_response_time(self):
        """æµ‹è¯• API å“åº”æ—¶é—´"""
        print_header("4. API å“åº”æ—¶é—´æµ‹è¯•")
        
        endpoints = [
            '/health',
            '/sse/stats',
            '/api/config'
        ]
        
        all_passed = True
        
        for endpoint in endpoints:
            try:
                start = time.time()
                response = self.session.get(f"{self.base_url}{endpoint}", timeout=5)
                latency = (time.time() - start) * 1000
                
                success = response.status_code == 200 and latency < 100
                print_metric(f"{endpoint}", f"{latency:.2f}", "ms", target="100ms", success=success)
                
                self.results['metrics'].append({
                    'name': f'API å“åº”æ—¶é—´ï¼š{endpoint}',
                    'latency_ms': latency,
                    'status_code': response.status_code,
                    'passed': success
                })
                
                if not success:
                    all_passed = False
                    
            except Exception as e:
                print_metric(f"{endpoint}", str(e), "", success=False)
                all_passed = False
        
        if all_passed:
            self.results['passed'] += 1
        else:
            self.results['failed'] += 1
        
        return all_passed
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æ€§èƒ½æµ‹è¯•"""
        print_header("âš¡ æ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶")
        print(f"æµ‹è¯•æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"æœåŠ¡å™¨åœ°å€ï¼š{self.base_url}")
        
        # é¦–å…ˆæ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦å¯ç”¨
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            if response.status_code != 200:
                print(f"{TestColors.RED}æœåŠ¡å™¨æœªå“åº”æˆ–è¿”å›é”™è¯¯çŠ¶æ€ç {TestColors.END}")
                return False
        except Exception as e:
            print(f"{TestColors.RED}æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼š{e}{TestColors.END}")
            return False
        
        # æ‰§è¡Œæµ‹è¯•
        self.test_health_endpoint_latency()
        self.test_sse_connection()
        self.test_concurrent_connections()
        self.test_api_response_time()
        
        # æ‰“å°æ±‡æ€»
        self.print_summary()
        
        return self.results['failed'] == 0
    
    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ±‡æ€»"""
        print_header("ğŸ“Š æ€§èƒ½æµ‹è¯•æ±‡æ€»æŠ¥å‘Š")
        
        total = self.results['passed'] + self.results['failed']
        pass_rate = (self.results['passed'] / total * 100) if total > 0 else 0
        
        print(f"æ€»æµ‹è¯•æ•°ï¼š{total}")
        print(f"{TestColors.GREEN}é€šè¿‡ï¼š{self.results['passed']}{TestColors.END}")
        print(f"{TestColors.RED}å¤±è´¥ï¼š{self.results['failed']}{TestColors.END}")
        print(f"é€šè¿‡ç‡ï¼š{pass_rate:.1f}%")
        
        # æ€§èƒ½æŒ‡æ ‡æ±‡æ€»
        print(f"\n{TestColors.BOLD}æ€§èƒ½æŒ‡æ ‡æ±‡æ€»:{TestColors.END}")
        
        for metric in self.results['metrics']:
            if 'avg_latency_ms' in metric or 'latency_ms' in metric:
                latency = metric.get('avg_latency_ms') or metric.get('latency_ms')
                name = metric['name']
                status = "âœ…" if metric.get('passed') else "âŒ"
                print(f"  {status} {name}: {latency:.2f}ms")
        
        if self.results['failed'] == 0:
            print(f"\n{TestColors.GREEN}{TestColors.BOLD}ğŸ‰ æ‰€æœ‰æ€§èƒ½æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿæ€§èƒ½ä¼˜ç§€ã€‚{TestColors.END}")
        else:
            print(f"\n{TestColors.RED}{TestColors.BOLD}âš ï¸  æœ‰ {self.results['failed']} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½ã€‚{TestColors.END}")
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        report = {
            'timestamp': datetime.now().isoformat(),
            'base_url': self.base_url,
            'summary': {
                'total': total,
                'passed': self.results['passed'],
                'failed': self.results['failed'],
                'pass_rate': pass_rate
            },
            'metrics': self.results['metrics']
        }
        
        report_file = f"performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\næµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°ï¼š{report_file}")


if __name__ == '__main__':
    tester = PerformanceBenchmarkTester()
    success = tester.run_all_tests()
    sys.exit(0 if success else 1)
