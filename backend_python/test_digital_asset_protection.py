#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°å­—èµ„äº§ä¿æŠ¤æµ‹è¯•è„šæœ¬

æµ‹è¯•åœºæ™¯ï¼š
1. AI å“åº”ç«‹å³æŒä¹…åŒ–
2. æ•°æ®åº“æ•…éšœé™çº§åˆ°æ–‡ä»¶
3. æ•°æ®å®Œæ•´æ€§éªŒè¯
4. å¤‡ä»½å’Œæ¢å¤
"""

import sys
import json
import os
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '.')

from wechat_backend.digital_asset_protection import (
    save_diagnosis_result_to_db,
    get_diagnosis_result_by_execution_id,
    verify_data_integrity,
    calculate_checksum,
    create_daily_backup,
    cleanup_old_backups
)


def test_immediate_persistence():
    """æµ‹è¯• 1: AI å“åº”ç«‹å³æŒä¹…åŒ–"""
    print("="*60)
    print("æµ‹è¯• 1: AI å“åº”ç«‹å³æŒä¹…åŒ–")
    print("="*60)
    
    execution_id = "test-exec-001"
    user_id = "user-test-001"
    brand_name = "æµ‹è¯•å“ç‰Œ"
    
    results = [
        {
            'brand': brand_name,
            'question': 'æµ‹è¯•é—®é¢˜ 1',
            'model': 'doubao',
            'response': {'content': 'è¿™æ˜¯ AI å›ç­”'},
            'geo_data': {'brand_mentioned': True, 'rank': 1, 'sentiment': 0.8},
            'status': 'success'
        }
    ]
    
    print(f"\n1.1 ä¿å­˜è¯Šæ–­ç»“æœ")
    record_id = save_diagnosis_result_to_db(
        execution_id=execution_id,
        user_id=user_id,
        brand_name=brand_name,
        results=results,
        metadata={'test': True}
    )
    print(f"âœ… ä¿å­˜æˆåŠŸï¼Œè®°å½• ID: {record_id}")
    
    print(f"\n1.2 ä»æ•°æ®åº“è·å–ç»“æœ")
    stored_result = get_diagnosis_result_by_execution_id(execution_id)
    assert stored_result is not None, "âŒ æœªæ‰¾åˆ°å­˜å‚¨çš„ç»“æœ"
    print(f"âœ… è·å–æˆåŠŸï¼Œæ‰§è¡Œ ID: {stored_result['execution_id']}")
    print(f"   ç»“æœæ•°é‡ï¼š{len(stored_result['results'])}")
    
    print(f"\n1.3 éªŒè¯æ•°æ®å®Œæ•´æ€§")
    is_valid = verify_data_integrity(execution_id, results)
    assert is_valid, "âŒ æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥"
    print(f"âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
    
    print(f"\n1.4 éªŒè¯æ ¡éªŒå’Œ")
    checksum = calculate_checksum({'execution_id': execution_id, 'results': results})
    print(f"âœ… æ ¡éªŒå’Œï¼š{checksum}")
    assert checksum == stored_result['checksum'], "âŒ æ ¡éªŒå’Œä¸åŒ¹é…"
    
    print("\nâœ… æµ‹è¯• 1 é€šè¿‡ï¼šAI å“åº”ç«‹å³æŒä¹…åŒ–æ­£å¸¸")


def test_database_failure_fallback():
    """æµ‹è¯• 2: æ•°æ®åº“æ•…éšœé™çº§åˆ°æ–‡ä»¶"""
    print("\n" + "="*60)
    print("æµ‹è¯• 2: æ•°æ®åº“æ•…éšœé™çº§åˆ°æ–‡ä»¶")
    print("="*60)
    
    from wechat_backend.digital_asset_protection import save_to_emergency_log
    import glob
    
    execution_id = "test-exec-002"
    results = [
        {
            'brand': 'æµ‹è¯•å“ç‰Œ 2',
            'question': 'æµ‹è¯•é—®é¢˜ 2',
            'model': 'qwen',
            'response': {'content': 'é€šä¹‰åƒé—®å›ç­”'},
            'status': 'success'
        }
    ]
    
    print(f"\n2.1 ä¿å­˜åˆ°ç´§æ€¥æ—¥å¿—")
    filepath = save_to_emergency_log(
        execution_id=execution_id,
        results=results,
        metadata={'test': True, 'fallback': True}
    )
    print(f"âœ… ç´§æ€¥æ—¥å¿—ä¿å­˜ï¼š{filepath}")
    
    print(f"\n2.2 éªŒè¯æ–‡ä»¶å­˜åœ¨")
    assert filepath is not None, "âŒ ç´§æ€¥æ—¥å¿—ä¿å­˜å¤±è´¥"
    assert os.path.exists(filepath), "âŒ ç´§æ€¥æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨"
    print(f"âœ… æ–‡ä»¶å­˜åœ¨ï¼š{filepath}")
    
    print(f"\n2.3 è¯»å–å¹¶éªŒè¯å†…å®¹")
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    assert data['execution_id'] == execution_id, "âŒ æ‰§è¡Œ ID ä¸åŒ¹é…"
    assert len(data['results']) == 1, "âŒ ç»“æœæ•°é‡ä¸åŒ¹é…"
    print(f"âœ… å†…å®¹éªŒè¯é€šè¿‡")
    
    print("\nâœ… æµ‹è¯• 2 é€šè¿‡ï¼šæ•°æ®åº“æ•…éšœé™çº§æ­£å¸¸")


def test_backup_and_restore():
    """æµ‹è¯• 3: å¤‡ä»½å’Œæ¢å¤"""
    print("\n" + "="*60)
    print("æµ‹è¯• 3: å¤‡ä»½å’Œæ¢å¤")
    print("="*60)
    
    print(f"\n3.1 åˆ›å»ºæ¯æ—¥å¤‡ä»½")
    backup_stats = create_daily_backup()
    print(f"âœ… å¤‡ä»½å®Œæˆ:")
    print(f"   è®°å½•æ•°ï¼š{backup_stats.get('records_count', 0)}")
    print(f"   æ•°æ®åº“å¤‡ä»½ï¼š{backup_stats.get('database_backup', 'N/A')}")
    print(f"   JSON å¯¼å‡ºï¼š{backup_stats.get('json_export', 'N/A')}")
    print(f"   å¤§å°ï¼š{backup_stats.get('size_bytes', 0)} å­—èŠ‚")
    
    print(f"\n3.2 éªŒè¯å¤‡ä»½æ–‡ä»¶")
    if backup_stats.get('json_export'):
        assert os.path.exists(backup_stats['json_export']), "âŒ JSON å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨"
        with open(backup_stats['json_export'], 'r', encoding='utf-8') as f:
            data = json.load(f)
        assert isinstance(data, list), "âŒ JSON å¤‡ä»½æ ¼å¼é”™è¯¯"
        print(f"âœ… JSON å¤‡ä»½éªŒè¯é€šè¿‡ï¼Œè®°å½•æ•°ï¼š{len(data)}")
    
    print(f"\n3.3 æ¸…ç†æ—§å¤‡ä»½")
    cleanup_stats = cleanup_old_backups(days=1)
    print(f"âœ… æ¸…ç†å®Œæˆ:")
    print(f"   åˆ é™¤æ–‡ä»¶æ•°ï¼š{cleanup_stats.get('deleted_files', 0)}")
    print(f"   é‡Šæ”¾ç©ºé—´ï¼š{cleanup_stats.get('freed_bytes', 0)} å­—èŠ‚")
    
    print("\nâœ… æµ‹è¯• 3 é€šè¿‡ï¼šå¤‡ä»½å’Œæ¢å¤æ­£å¸¸")


def test_multi_platform_results():
    """æµ‹è¯• 4: å¤šå¹³å°ç»“æœæŒä¹…åŒ–"""
    print("\n" + "="*60)
    print("æµ‹è¯• 4: å¤šå¹³å°ç»“æœæŒä¹…åŒ–")
    print("="*60)
    
    execution_id = "test-exec-004"
    user_id = "user-test-004"
    brand_name = "å¤šå¹³å°æµ‹è¯•å“ç‰Œ"
    
    # æ¨¡æ‹Ÿå¤šä¸ª AI å¹³å°çš„ç»“æœ
    platforms = [
        ('doubao', 'success', {'content': 'è±†åŒ…å›ç­”', 'rank': 1}),
        ('qwen', 'success', {'content': 'é€šä¹‰åƒé—®å›ç­”', 'rank': 2}),
        ('zhipu', 'failed', {'error': '429 é…é¢ç”¨å°½', 'rank': -1})
    ]
    
    results = []
    for model, status, response_data in platforms:
        result = {
            'brand': brand_name,
            'question': 'å¤šå¹³å°æµ‹è¯•é—®é¢˜',
            'model': model,
            'response': response_data,
            'geo_data': {
                'brand_mentioned': status == 'success',
                'rank': response_data.get('rank', -1),
                'sentiment': 0.8 if status == 'success' else 0
            },
            'status': status
        }
        results.append(result)
        
        # ç«‹å³æŒä¹…åŒ–æ¯ä¸ªç»“æœ
        save_diagnosis_result_to_db(
            execution_id=execution_id,
            user_id=user_id,
            brand_name=brand_name,
            results=[result],
            metadata={'model': model, 'platform_test': True}
        )
        print(f"âœ… {model}: æŒä¹…åŒ–æˆåŠŸ")
    
    print(f"\n4.1 è·å–æ‰€æœ‰ç»“æœ")
    stored_result = get_diagnosis_result_by_execution_id(execution_id)
    # æ³¨æ„ï¼šç”±äºæ¯æ¬¡ä¿å­˜ä¼šè¦†ç›–ï¼Œè¿™é‡Œåªè·å–åˆ°æœ€åä¸€æ¬¡ä¿å­˜çš„ç»“æœ
    assert stored_result is not None, "âŒ æœªæ‰¾åˆ°å­˜å‚¨çš„ç»“æœ"
    print(f"âœ… è·å–æˆåŠŸ")
    
    print("\nâœ… æµ‹è¯• 4 é€šè¿‡ï¼šå¤šå¹³å°ç»“æœæŒä¹…åŒ–æ­£å¸¸")


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*70)
    print("ğŸ§ª æ•°å­—èµ„äº§ä¿æŠ¤æµ‹è¯•")
    print(f"å¼€å§‹æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*70)
    
    try:
        test_immediate_persistence()
        test_database_failure_fallback()
        test_backup_and_restore()
        test_multi_platform_results()
        
        print("\n" + "="*70)
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("="*70)
        print("\næ•°å­—èµ„äº§ä¿æŠ¤éªŒè¯å®Œæˆ:")
        print("1. âœ… AI å“åº”ç«‹å³æŒä¹…åŒ–")
        print("2. âœ… æ•°æ®åº“æ•…éšœé™çº§åˆ°æ–‡ä»¶")
        print("3. âœ… å¤‡ä»½å’Œæ¢å¤æœºåˆ¶")
        print("4. âœ… å¤šå¹³å°ç»“æœæŒä¹…åŒ–")
        print("5. âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯")
        
        return 0
        
    except AssertionError as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥ï¼š{e}")
        import traceback
        traceback.print_exc()
        return 1
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¼‚å¸¸ï¼š{e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
