#!/usr/bin/env python3
"""
Unit Test Runner for reportAggregator.js logic
éªŒè¯èšåˆå¼•æ“çš„é€»è¾‘æ­£ç¡®æ€§
"""

import json

def test_aggregate_report():
    """æµ‹è¯•èšåˆæŠ¥å‘Šé€»è¾‘"""
    print("\n" + "="*60)
    print("GEO å“ç‰Œæˆ˜ç•¥èšåˆå¼•æ“ - é—­ç¯éªŒæ”¶æµ‹è¯•")
    print("="*60)
    
    # æµ‹è¯•æ•°æ® 1: æ­£å¸¸æ•°æ®ï¼ˆ3 é—®é¢˜Ã—4 æ¨¡å‹Ã—1 ä¸»å“ç‰Œï¼‰
    test1_results = [
        # é—®é¢˜ 1 - 4 ä¸ªæ¨¡å‹çš„å›ç­”
        {"question_id": 0, "question_text": "ä»‹ç»ä¸€ä¸‹ Tesla", "model": "doubao", "geo_data": {"brand_mentioned": True, "rank": 2, "sentiment": 0.7, "cited_sources": [{"url": "https://a.com", "site_name": "Site A", "attitude": "positive"}], "interception": ""}},
        {"question_id": 0, "question_text": "ä»‹ç»ä¸€ä¸‹ Tesla", "model": "qwen", "geo_data": {"brand_mentioned": True, "rank": 3, "sentiment": 0.5, "cited_sources": [], "interception": "BMW"}},
        {"question_id": 0, "question_text": "ä»‹ç»ä¸€ä¸‹ Tesla", "model": "deepseek", "geo_data": {"brand_mentioned": True, "rank": 1, "sentiment": 0.8, "cited_sources": [{"url": "https://b.com", "site_name": "Site B", "attitude": "negative"}], "interception": ""}},
        {"question_id": 0, "question_text": "ä»‹ç»ä¸€ä¸‹ Tesla", "model": "zhipu", "geo_data": {"brand_mentioned": True, "rank": 2, "sentiment": 0.6, "cited_sources": [], "interception": ""}},
        # é—®é¢˜ 2 - 4 ä¸ªæ¨¡å‹çš„å›ç­”
        {"question_id": 1, "question_text": "Tesla çš„ä¸»è¦äº§å“", "model": "doubao", "geo_data": {"brand_mentioned": True, "rank": 3, "sentiment": 0.4, "cited_sources": [], "interception": ""}},
        {"question_id": 1, "question_text": "Tesla çš„ä¸»è¦äº§å“", "model": "qwen", "geo_data": {"brand_mentioned": True, "rank": 4, "sentiment": 0.3, "cited_sources": [], "interception": "Mercedes"}},
        {"question_id": 1, "question_text": "Tesla çš„ä¸»è¦äº§å“", "model": "deepseek", "geo_data": {"brand_mentioned": False, "rank": -1, "sentiment": 0, "cited_sources": [], "interception": ""}},
        {"question_id": 1, "question_text": "Tesla çš„ä¸»è¦äº§å“", "model": "zhipu", "geo_data": {"brand_mentioned": True, "rank": 2, "sentiment": 0.5, "cited_sources": [], "interception": ""}},
        # é—®é¢˜ 3 - 4 ä¸ªæ¨¡å‹çš„å›ç­”
        {"question_id": 2, "question_text": "Tesla å’Œç«å“åŒºåˆ«", "model": "doubao", "geo_data": {"brand_mentioned": True, "rank": 1, "sentiment": 0.9, "cited_sources": [], "interception": ""}},
        {"question_id": 2, "question_text": "Tesla å’Œç«å“åŒºåˆ«", "model": "qwen", "geo_data": {"brand_mentioned": True, "rank": 2, "sentiment": 0.7, "cited_sources": [], "interception": ""}},
        {"question_id": 2, "question_text": "Tesla å’Œç«å“åŒºåˆ«", "model": "deepseek", "geo_data": {"brand_mentioned": True, "rank": 1, "sentiment": 0.8, "cited_sources": [], "interception": ""}},
        {"question_id": 2, "question_text": "Tesla å’Œç«å“åŒºåˆ«", "model": "zhipu", "geo_data": {"brand_mentioned": True, "rank": 3, "sentiment": 0.6, "cited_sources": [], "interception": "BMW"}}
    ]
    
    # æ‰‹åŠ¨è®¡ç®—æœŸæœ›å€¼
    total_results = len(test1_results)
    total_mentions = sum(1 for r in test1_results if r.get("geo_data", {}).get("brand_mentioned", False))
    sov = (total_mentions / total_results) * 100
    
    print(f"\næµ‹è¯• 1: æ­£å¸¸æ•°æ®ï¼ˆ3 é—®é¢˜Ã—4 æ¨¡å‹Ã—1 ä¸»å“ç‰Œï¼‰")
    print("-"*60)
    print(f"  æ€»ç»“æœæ•°ï¼š{total_results}")
    print(f"  æåŠæ•°ï¼š{total_mentions}")
    print(f"  SOV: {sov:.1f}% (æœŸæœ›ï¼š91.7%)")
    
    # éªŒè¯ SOV è®¡ç®—
    sov_match = abs(sov - 91.7) < 1
    print(f"  SOV éªŒè¯ï¼š{'âœ… é€šè¿‡' if sov_match else 'âŒ å¤±è´¥'}")
    
    # è®¡ç®—æ¯ä¸ªé—®é¢˜çš„å¹³å‡æ’å
    from collections import defaultdict
    question_map = defaultdict(list)
    for r in test1_results:
        qid = r["question_id"]
        geo = r.get("geo_data") or {}
        if geo.get("brand_mentioned"):
            rank = geo.get("rank", 10) if geo.get("rank", 10) > 0 else 10
            question_map[qid].append(rank)
    
    print(f"\n  QuestionCards éªŒè¯:")
    for qid in sorted(question_map.keys()):
        ranks = question_map[qid]
        avg_rank = sum(ranks) / len(ranks) if ranks else 0
        mention_count = len(ranks)
        print(f"    é—®é¢˜ {qid+1}: å¹³å‡æ’å={avg_rank:.1f}, æåŠç‡={mention_count}/4")
    
    # éªŒè¯é—®é¢˜ 1 çš„æ’åè®¡ç®—
    q1_ranks = [2, 3, 1, 2]  # 4 ä¸ªæ¨¡å‹çš„æ’å
    q1_avg = sum(q1_ranks) / len(q1_ranks)
    print(f"\n  é—®é¢˜ 1 æ’åéªŒè¯:")
    print(f"    åŸå§‹æ’åï¼š{q1_ranks}")
    print(f"    è®¡ç®—å¹³å‡ï¼š{q1_avg:.1f} (æœŸæœ›ï¼š2.0)")
    q1_match = abs(q1_avg - 2.0) < 0.1
    print(f"    æ’åéªŒè¯ï¼š{'âœ… é€šè¿‡' if q1_match else 'âŒ å¤±è´¥'}")
    
    # éªŒè¯ç«å“æ‹¦æˆª
    interceptions = []
    for r in test1_results:
        geo = r.get("geo_data") or {}
        if geo.get("interception"):
            interceptions.append(geo["interception"])
    
    print(f"\n  ç«å“æ‹¦æˆªéªŒè¯:")
    print(f"    æ‹¦æˆªè®°å½•ï¼š{interceptions}")
    print(f"    æ‹¦æˆªæ¬¡æ•°ï¼š{len(interceptions)} (BMW: {interceptions.count('BMW')}, Mercedes: {interceptions.count('Mercedes')})")
    
    # éªŒè¯è´Ÿé¢ä¿¡æº
    toxic_sources = []
    for r in test1_results:
        geo = r.get("geo_data") or {}
        for src in geo.get("cited_sources", []):
            if src.get("attitude") == "negative":
                toxic_sources.append(src)
    
    print(f"\n  è´Ÿé¢ä¿¡æºéªŒè¯:")
    print(f"    è´Ÿé¢ä¿¡æºæ•°ï¼š{len(toxic_sources)} (æœŸæœ›ï¼š1)")
    for src in toxic_sources:
        print(f"      - [{src.get('site_name')}] {src.get('url')}")
    
    # æµ‹è¯• 2: éƒ¨åˆ†æ•°æ®ç¼ºå¤±
    print(f"\n{'='*60}")
    print(f"æµ‹è¯• 2: éƒ¨åˆ†æ•°æ®ç¼ºå¤±")
    print("-"*60)
    
    test2_results = [
        {"question_id": 0, "geo_data": {"brand_mentioned": True, "rank": 5, "sentiment": 0.3}},
        {"question_id": 0, "geo_data": None},
        {"question_id": 0, "geo_data": {"brand_mentioned": False, "rank": -1, "sentiment": 0}},
        {"question_id": 1, "geo_data": None},
        {"question_id": 1, "geo_data": {"brand_mentioned": True, "rank": 8, "sentiment": -0.2}}
    ]
    
    total_t2 = len(test2_results)
    mentions_t2 = sum(1 for r in test2_results if r.get("geo_data") and r["geo_data"].get("brand_mentioned"))
    sov_t2 = (mentions_t2 / total_t2) * 100
    
    print(f"  æ€»ç»“æœæ•°ï¼š{total_t2}")
    print(f"  æåŠæ•°ï¼š{mentions_t2}")
    print(f"  SOV: {sov_t2:.1f}% (æœŸæœ›ï¼š40%)")
    sov_t2_match = abs(sov_t2 - 40) < 1
    print(f"  SOV éªŒè¯ï¼š{'âœ… é€šè¿‡' if sov_t2_match else 'âŒ å¤±è´¥'}")
    
    # æµ‹è¯• 3: å…¨ç©ºæ•°æ®
    print(f"\n{'='*60}")
    print(f"æµ‹è¯• 3: å…¨ç©ºæ•°æ®")
    print("-"*60)
    
    test3_results = []
    result_t3 = None if len(test3_results) == 0 else "æœ‰æ•°æ®"
    print(f"  ç»“æœæ•°ï¼š{len(test3_results)}")
    print(f"  è¿”å›å€¼ï¼š{result_t3} (æœŸæœ›ï¼šnull)")
    t3_pass = result_t3 is None
    print(f"  éªŒè¯ï¼š{'âœ… é€šè¿‡' if t3_pass else 'âŒ å¤±è´¥'}")
    
    # æ€»ç»“
    print(f"\n{'='*60}")
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    all_pass = sov_match and q1_match and sov_t2_match and t3_pass
    print(f"  SOV è®¡ç®—ï¼š{'âœ… é€šè¿‡' if sov_match else 'âŒ å¤±è´¥'}")
    print(f"  å¹³å‡æ’åï¼š{'âœ… é€šè¿‡' if q1_match else 'âŒ å¤±è´¥'}")
    print(f"  ç¼ºå¤±å¤„ç†ï¼š{'âœ… é€šè¿‡' if sov_t2_match else 'âŒ å¤±è´¥'}")
    print(f"  å…¨ç©ºå¤„ç†ï¼š{'âœ… é€šè¿‡' if t3_pass else 'âŒ å¤±è´¥'}")
    print(f"\n  æ€»ä½“ç»“æœï¼š{'ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼' if all_pass else 'âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥'}")
    
    return all_pass

if __name__ == '__main__':
    result = test_aggregate_report()
    exit(0 if result else 1)
